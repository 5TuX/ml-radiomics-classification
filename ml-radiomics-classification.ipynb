{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07663c35",
   "metadata": {},
   "source": [
    "# Introductory machine learning experiment with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f2aab3",
   "metadata": {},
   "source": [
    "## Google colab setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3182062a",
   "metadata": {},
   "source": [
    "This cell downloads and installs the notebook's requirements in the Google Colab runtime.\n",
    "You should comment or delete it if you are not running the notebook on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769c0c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable cell output\n",
    "%%capture\n",
    "\n",
    "# Download the repository from github\n",
    "!git clone https://github.com/5TuX/ml-radiomics-classification.git\n",
    "\n",
    "# Set working directory\n",
    "%cd ml-radiomics-classification\n",
    "\n",
    "# Install dependencies with uv\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "import os\n",
    "\n",
    "os.environ[\"PATH\"] = f\"/root/.cargo/bin:{os.environ['PATH']}\"\n",
    "!uv sync"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861c267a",
   "metadata": {},
   "source": [
    "## Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163caacf",
   "metadata": {},
   "source": [
    "### The goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc137b8",
   "metadata": {},
   "source": [
    "The purpose of this tutorial is to showcase a basic machine learning training pipeline that you can apply on your own tabular datasets. \n",
    "\n",
    "Let's imagine we have a reasonably sized tabular dataset (e.g. a CSV file) where each line is a sample and each column is a feature. We want to train a model to predict one of these columns (the target feature) using the other columns (the input features)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e522698c",
   "metadata": {},
   "source": [
    "### Training machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619e9418",
   "metadata": {},
   "source": [
    "There are a lot of general approaches to machine learning:\n",
    "- Supervised learning trains models on labelled data (most common)\n",
    "- Unsupervised learning searches patterns in unlabelled data\n",
    "- Self-supervised learning uses labels automatically generated from the data itself (e.g., contrastive learning)\n",
    "- Reinforcement learning learns by interacting in an environment to maximize a reward\n",
    "- Many more learning paradigms are listed on wikipedia: https://en.wikipedia.org/wiki/Machine_learning\n",
    "\n",
    "In this notebook, we'll focus on a supervised learning classification task, which consists in predicting a class label from a set of input variables. Another common supervised machine learning task is regression, which tries to predict a continuous value. It won't be addressed here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482ca1ce",
   "metadata": {},
   "source": [
    "The Python scikit-learn library provides lots of tools to experiment with machine learning methods on our dataset. In this tutorial, we will showcase some of these tools that will help us to:\n",
    "- Split the dataset in training and test subset (testing is crucial to avoid overfitting)\n",
    "- Create a preprocessing pipeline for the data (numerical variable normalization, categorical variable one-hot encoding)\n",
    "- Leverage cross-validation to quickly compare a bunch of different models\n",
    "- Do the final training and evaluation of one selected model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40985ac",
   "metadata": {},
   "source": [
    "### Spending time with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab95cd7f",
   "metadata": {},
   "source": [
    "Playing around with AI models is only 10% of the job. The other 90% is spending time with the data to understand it and make sure what we do has a meaning. This involves loading the dataset, visualizing and exploring the data, looking at feature distributions and correlations, selecting input and target features, handling missing values, possibly creating new features... In this tutorial, we'll hide most of this part to focus on scikit-learn tools, but keep in mind that in a real-world scenario your dataset will never be ready to use for training out-of-the box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc9f59",
   "metadata": {},
   "source": [
    "A widely used Python library for handling tabular data is Pandas. In this tutorial however, we prefered to briefly showcase a more recent library named [Polars](https://github.com/pola-rs/polars). Notably, Polars prefers to use [Altair](https://github.com/vega/altair) over Matplotlib for interactive plotting and visualization. Polars provides tools to convert to Pandas format, but scikit-learn is compatible with both libraries anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a0855",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af64998",
   "metadata": {},
   "source": [
    "- This notebook is heavily inspired by Aurelien Geron's [End-to-end machine learning project](https://github.com/ageron/handson-ml3/blob/main/02_end_to_end_machine_learning_project.ipynb) notebook from his book [Hand-on machine learning with scikit-learn and Pytorch](https://www.oreilly.com/library/view/hands-on-machine-learning/9798341607972/). In this tutorial we're looking at a classification task, but his example focuses on regression. Feel free to check it out if you are interested.\n",
    "- Andrej Karpathy provides a nifty [Recipe for Training Neural Networks](https://karpathy.github.io/2019/04/25/recipe/) which gives useful guidelines for any machine learning project and points at common mistakes to avoid.\n",
    "- The CNRS has a freely accessible program called [FIDLE](https://fidle.cnrs.fr), yearly revisited, wich provides a nice entry point for anyone curious about artifical intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bfe926",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2fc1f2",
   "metadata": {},
   "source": [
    "In this notebook, we are looking at a version of the [BraTS-2020-Openradiomics](https://openradiomics.org/?page_id=1087) dataset (see [publication](https://doi.org/10.1186/s12880-025-01855-2)). \n",
    "\n",
    "It contains information of 369 adult patients with brain tumors. Each line contains around 1500 [radiomic](https://en.wikipedia.org/wiki/Radiomics) features computed from tumor segmentations of the patient's MRI scans, as well as two target variables: \n",
    "- The category of brain tumor:\n",
    "    - \"LGG\" for low-grade glioma (less aggressive tumor)\n",
    "    - \"HGG\" for high-grade glioma (more aggressive tumor)\n",
    "- Survival information (in days, provided for 236 patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eee021",
   "metadata": {},
   "source": [
    "<figure style=\"max-width: 600px; margin: auto; text-align: left;\">\n",
    "    <img src=\"https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs12880-025-01855-2/MediaObjects/12880_2025_1855_Fig1_HTML.png\">\n",
    "    <figcaption>An example BraTS 2020 image (the FLAIR sequence) and its corresponding segmentation mask. The orange area is AT (active tumor), the green area is ED (peritumoral edematous/invaded tissue), and the gray parts are NETnNCR (Union of necrotic and non-enhancing tumor)</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe1fd6",
   "metadata": {},
   "source": [
    "We will ignore the survival information entirely and try to predict the class of the tumor (LGG or HGG) with a binary classifier. We'll drop most of the radiomic feature and keep only the original ones (107 input features)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea971a4a",
   "metadata": {},
   "source": [
    "## Python imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ed3a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import re\n",
    "from itertools import groupby\n",
    "\n",
    "# Data handling imports\n",
    "import polars as pl\n",
    "\n",
    "# Scikit-learn utility imports\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "\n",
    "# Scikit-learn model imports\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Other imports\n",
    "from tabulate import tabulate  # for pretty-printing tables\n",
    "import altair as alt  # for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b208cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"dataset-path\": \"data/Radiomics_binWidth-15_ZScore_NETnNCR_T1CE.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a990b71",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b39526",
   "metadata": {},
   "source": [
    "Here we decide what columns to keep, how to handle missing values, and we put a test set aside (20% of the data) for evaluating our final model. All further data pre-processing and model training will be done on the rest of the data without ever looking at the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155778fa",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1674bbc8",
   "metadata": {},
   "source": [
    "Use Polars (you can also use Pandas) to load the dataset from the CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20253ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (369, 1720)\n"
     ]
    }
   ],
   "source": [
    "df = pl.read_csv(settings[\"dataset-path\"])\n",
    "print(\"Dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480c740b",
   "metadata": {},
   "source": [
    "### First look at the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f9b7c1",
   "metadata": {},
   "source": [
    "Look at a few examples to get an idea of the data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d521e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 1_720)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Patient_ID</th><th>Group</th><th>Group_label</th><th>binWidth</th><th>Normalization</th><th>Age</th><th>Survival_days</th><th>Extent_of_Resection</th><th>Subregion</th><th>Sequence</th><th>diagnostics_Versions_PyRadiomics</th><th>diagnostics_Versions_Numpy</th><th>diagnostics_Versions_SimpleITK</th><th>diagnostics_Versions_PyWavelet</th><th>diagnostics_Versions_Python</th><th>diagnostics_Configuration_Settings</th><th>diagnostics_Configuration_EnabledImageTypes</th><th>diagnostics_Image-original_Hash</th><th>diagnostics_Image-original_Dimensionality</th><th>diagnostics_Image-original_Spacing</th><th>diagnostics_Image-original_Size</th><th>diagnostics_Image-original_Mean</th><th>diagnostics_Image-original_Minimum</th><th>diagnostics_Image-original_Maximum</th><th>diagnostics_Mask-original_Hash</th><th>diagnostics_Mask-original_Spacing</th><th>diagnostics_Mask-original_Size</th><th>diagnostics_Mask-original_BoundingBox</th><th>diagnostics_Mask-original_VoxelNum</th><th>diagnostics_Mask-original_VolumeNum</th><th>diagnostics_Mask-original_CenterOfMassIndex</th><th>diagnostics_Mask-original_CenterOfMass</th><th>original_shape_Elongation</th><th>original_shape_Flatness</th><th>original_shape_LeastAxisLength</th><th>original_shape_MajorAxisLength</th><th>original_shape_Maximum2DDiameterColumn</th><th>&hellip;</th><th>wavelet-LLL_glrlm_GrayLevelNonUniformity</th><th>wavelet-LLL_glrlm_GrayLevelNonUniformityNormalized</th><th>wavelet-LLL_glrlm_GrayLevelVariance</th><th>wavelet-LLL_glrlm_HighGrayLevelRunEmphasis</th><th>wavelet-LLL_glrlm_LongRunEmphasis</th><th>wavelet-LLL_glrlm_LongRunHighGrayLevelEmphasis</th><th>wavelet-LLL_glrlm_LongRunLowGrayLevelEmphasis</th><th>wavelet-LLL_glrlm_LowGrayLevelRunEmphasis</th><th>wavelet-LLL_glrlm_RunEntropy</th><th>wavelet-LLL_glrlm_RunLengthNonUniformity</th><th>wavelet-LLL_glrlm_RunLengthNonUniformityNormalized</th><th>wavelet-LLL_glrlm_RunPercentage</th><th>wavelet-LLL_glrlm_RunVariance</th><th>wavelet-LLL_glrlm_ShortRunEmphasis</th><th>wavelet-LLL_glrlm_ShortRunHighGrayLevelEmphasis</th><th>wavelet-LLL_glrlm_ShortRunLowGrayLevelEmphasis</th><th>wavelet-LLL_glszm_GrayLevelNonUniformity</th><th>wavelet-LLL_glszm_GrayLevelNonUniformityNormalized</th><th>wavelet-LLL_glszm_GrayLevelVariance</th><th>wavelet-LLL_glszm_HighGrayLevelZoneEmphasis</th><th>wavelet-LLL_glszm_LargeAreaEmphasis</th><th>wavelet-LLL_glszm_LargeAreaHighGrayLevelEmphasis</th><th>wavelet-LLL_glszm_LargeAreaLowGrayLevelEmphasis</th><th>wavelet-LLL_glszm_LowGrayLevelZoneEmphasis</th><th>wavelet-LLL_glszm_SizeZoneNonUniformity</th><th>wavelet-LLL_glszm_SizeZoneNonUniformityNormalized</th><th>wavelet-LLL_glszm_SmallAreaEmphasis</th><th>wavelet-LLL_glszm_SmallAreaHighGrayLevelEmphasis</th><th>wavelet-LLL_glszm_SmallAreaLowGrayLevelEmphasis</th><th>wavelet-LLL_glszm_ZoneEntropy</th><th>wavelet-LLL_glszm_ZonePercentage</th><th>wavelet-LLL_glszm_ZoneVariance</th><th>wavelet-LLL_ngtdm_Busyness</th><th>wavelet-LLL_ngtdm_Coarseness</th><th>wavelet-LLL_ngtdm_Complexity</th><th>wavelet-LLL_ngtdm_Contrast</th><th>wavelet-LLL_ngtdm_Strength</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;BraTS20_Training_001&quot;</td><td>&quot;HGG&quot;</td><td>1</td><td>&quot;binWidth-15&quot;</td><td>&quot;ZScore&quot;</td><td>60.463</td><td>&quot;289&quot;</td><td>&quot;GTR&quot;</td><td>&quot;NETnNCR&quot;</td><td>&quot;T1CE&quot;</td><td>&quot;v3.0.1&quot;</td><td>&quot;1.20.3&quot;</td><td>&quot;2.1.1&quot;</td><td>&quot;1.1.1&quot;</td><td>&quot;3.9.7&quot;</td><td>&quot;{&#x27;minimumROIDimensions&#x27;: 2, &#x27;m…</td><td>&quot;{&#x27;Original&#x27;: {}, &#x27;Exponential&#x27;…</td><td>&quot;fcf31c6f56b4067eb28299303a0674…</td><td>&quot;3D&quot;</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>-6.4336e-16</td><td>-0.404772</td><td>11.492377</td><td>&quot;f3599f6c7ce9538e47d18beaef7292…</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>&quot;(70, 102, 41, 50, 56, 37)&quot;</td><td>15443.0</td><td>34.0</td><td>&quot;(89.23389237842387, 122.326749…</td><td>&quot;(89.23389237842387, 122.326749…</td><td>0.731829</td><td>0.41979</td><td>21.139285</td><td>50.356792</td><td>50.358713</td><td>&hellip;</td><td>2837.692308</td><td>1.0</td><td>0.0</td><td>1.0</td><td>56.108317</td><td>56.108317</td><td>56.108317</td><td>1.0</td><td>3.683174</td><td>314.441224</td><td>0.108017</td><td>0.183753</td><td>23.691856</td><td>0.28482</td><td>0.28482</td><td>0.28482</td><td>34.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>6.3840e6</td><td>6.3840e6</td><td>6.3840e6</td><td>1.0</td><td>5.470588</td><td>0.1609</td><td>0.379267</td><td>0.379267</td><td>0.379267</td><td>3.133984</td><td>0.002202</td><td>6.1777e6</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;BraTS20_Training_002&quot;</td><td>&quot;HGG&quot;</td><td>1</td><td>&quot;binWidth-15&quot;</td><td>&quot;ZScore&quot;</td><td>52.263</td><td>&quot;616&quot;</td><td>&quot;GTR&quot;</td><td>&quot;NETnNCR&quot;</td><td>&quot;T1CE&quot;</td><td>&quot;v3.0.1&quot;</td><td>&quot;1.20.3&quot;</td><td>&quot;2.1.1&quot;</td><td>&quot;1.1.1&quot;</td><td>&quot;3.9.7&quot;</td><td>&quot;{&#x27;minimumROIDimensions&#x27;: 2, &#x27;m…</td><td>&quot;{&#x27;Original&#x27;: {}, &#x27;Exponential&#x27;…</td><td>&quot;58a926796869be2fcbfafa87f1e2d3…</td><td>&quot;3D&quot;</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>7.7498e-16</td><td>-0.438949</td><td>8.906679</td><td>&quot;f6ef775f5d12edcb4e8926782d7773…</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>&quot;(67, 86, 37, 28, 32, 34)&quot;</td><td>9160.0</td><td>9.0</td><td>&quot;(77.61626637554585, 101.946397…</td><td>&quot;(77.61626637554585, 101.946397…</td><td>0.805201</td><td>0.596898</td><td>17.919111</td><td>30.020387</td><td>34.132096</td><td>&hellip;</td><td>931.230769</td><td>1.0</td><td>0.0</td><td>1.0</td><td>148.738015</td><td>148.738015</td><td>148.738015</td><td>1.0</td><td>4.063811</td><td>65.188726</td><td>0.068125</td><td>0.101663</td><td>37.847387</td><td>0.148596</td><td>0.148596</td><td>0.148596</td><td>9.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>9.1449e6</td><td>9.1449e6</td><td>9.1449e6</td><td>1.0</td><td>1.0</td><td>0.111111</td><td>0.155282</td><td>0.155282</td><td>0.155282</td><td>3.169925</td><td>0.000983</td><td>8.1090e6</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;BraTS20_Training_003&quot;</td><td>&quot;HGG&quot;</td><td>1</td><td>&quot;binWidth-15&quot;</td><td>&quot;ZScore&quot;</td><td>54.301</td><td>&quot;464&quot;</td><td>&quot;GTR&quot;</td><td>&quot;NETnNCR&quot;</td><td>&quot;T1CE&quot;</td><td>&quot;v3.0.1&quot;</td><td>&quot;1.20.3&quot;</td><td>&quot;2.1.1&quot;</td><td>&quot;1.1.1&quot;</td><td>&quot;3.9.7&quot;</td><td>&quot;{&#x27;minimumROIDimensions&#x27;: 2, &#x27;m…</td><td>&quot;{&#x27;Original&#x27;: {}, &#x27;Exponential&#x27;…</td><td>&quot;923aabc1a6c23ad6accc67bcd26fe1…</td><td>&quot;3D&quot;</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>2.7571e-16</td><td>-0.389427</td><td>11.927897</td><td>&quot;27f9116fc7420ab3c6eedf267830db…</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>&quot;(160, 149, 61, 16, 19, 18)&quot;</td><td>733.0</td><td>7.0</td><td>&quot;(168.64529331514325, 158.99317…</td><td>&quot;(168.64529331514325, 158.99317…</td><td>0.768372</td><td>0.722447</td><td>11.550058</td><td>15.987407</td><td>18.681542</td><td>&hellip;</td><td>291.153846</td><td>1.0</td><td>0.0</td><td>1.0</td><td>10.77577</td><td>10.77577</td><td>10.77577</td><td>1.0</td><td>2.387787</td><td>77.714144</td><td>0.259495</td><td>0.397209</td><td>3.934461</td><td>0.500213</td><td>0.500213</td><td>0.500213</td><td>7.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>62367.571429</td><td>62367.571429</td><td>62367.571429</td><td>1.0</td><td>1.285714</td><td>0.183673</td><td>0.298127</td><td>0.298127</td><td>0.298127</td><td>2.521641</td><td>0.00955</td><td>51402.489796</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;BraTS20_Training_004&quot;</td><td>&quot;HGG&quot;</td><td>1</td><td>&quot;binWidth-15&quot;</td><td>&quot;ZScore&quot;</td><td>39.068</td><td>&quot;788&quot;</td><td>&quot;GTR&quot;</td><td>&quot;NETnNCR&quot;</td><td>&quot;T1CE&quot;</td><td>&quot;v3.0.1&quot;</td><td>&quot;1.20.3&quot;</td><td>&quot;2.1.1&quot;</td><td>&quot;1.1.1&quot;</td><td>&quot;3.9.7&quot;</td><td>&quot;{&#x27;minimumROIDimensions&#x27;: 2, &#x27;m…</td><td>&quot;{&#x27;Original&#x27;: {}, &#x27;Exponential&#x27;…</td><td>&quot;55fa7fba043c7c44a6e842b5a586a4…</td><td>&quot;3D&quot;</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>-5.9757e-16</td><td>-0.438407</td><td>11.005426</td><td>&quot;07742fbe85b3d48e3aa5ff6ad53873…</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>&quot;(149, 150, 64, 31, 44, 44)&quot;</td><td>10902.0</td><td>37.0</td><td>&quot;(162.29728490185286, 169.57576…</td><td>&quot;(162.29728490185286, 169.57576…</td><td>0.880563</td><td>0.556199</td><td>21.603687</td><td>38.841633</td><td>42.720019</td><td>&hellip;</td><td>2986.769231</td><td>1.0</td><td>0.0</td><td>1.0</td><td>27.455009</td><td>27.455009</td><td>27.455009</td><td>1.0</td><td>3.051311</td><td>557.843589</td><td>0.182311</td><td>0.273965</td><td>13.085883</td><td>0.40605</td><td>0.40605</td><td>0.40605</td><td>37.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>3.0228e6</td><td>3.0228e6</td><td>3.0228e6</td><td>1.0</td><td>5.594595</td><td>0.151205</td><td>0.360428</td><td>0.360428</td><td>0.360428</td><td>3.230669</td><td>0.003394</td><td>2.9360e6</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;BraTS20_Training_005&quot;</td><td>&quot;HGG&quot;</td><td>1</td><td>&quot;binWidth-15&quot;</td><td>&quot;ZScore&quot;</td><td>68.493</td><td>&quot;465&quot;</td><td>&quot;GTR&quot;</td><td>&quot;NETnNCR&quot;</td><td>&quot;T1CE&quot;</td><td>&quot;v3.0.1&quot;</td><td>&quot;1.20.3&quot;</td><td>&quot;2.1.1&quot;</td><td>&quot;1.1.1&quot;</td><td>&quot;3.9.7&quot;</td><td>&quot;{&#x27;minimumROIDimensions&#x27;: 2, &#x27;m…</td><td>&quot;{&#x27;Original&#x27;: {}, &#x27;Exponential&#x27;…</td><td>&quot;6c94ee5878e0aca66cb21e828c50fe…</td><td>&quot;3D&quot;</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>-4.8643e-17</td><td>-0.416155</td><td>12.239193</td><td>&quot;5fec5dd1de3d85905a292c12f948d4…</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>&quot;(123, 157, 84, 52, 34, 42)&quot;</td><td>3624.0</td><td>37.0</td><td>&quot;(155.71136865342163, 172.22599…</td><td>&quot;(155.71136865342163, 172.22599…</td><td>0.342747</td><td>0.309231</td><td>20.04694</td><td>64.828365</td><td>60.60528</td><td>&hellip;</td><td>1608.791873</td><td>0.985289</td><td>0.007356</td><td>1.022234</td><td>8.446223</td><td>8.469023</td><td>8.440523</td><td>0.994442</td><td>2.250301</td><td>508.396876</td><td>0.305674</td><td>0.450458</td><td>3.256455</td><td>0.552665</td><td>0.574758</td><td>0.547142</td><td>30.148936</td><td>0.641467</td><td>0.179267</td><td>1.702128</td><td>168949.234043</td><td>168950.12766</td><td>168949.010638</td><td>0.824468</td><td>17.851064</td><td>0.37981</td><td>0.634417</td><td>1.288673</td><td>0.470853</td><td>2.825271</td><td>0.012969</td><td>163003.839746</td><td>2.292387</td><td>0.220302</td><td>0.002505</td><td>0.000012</td><td>0.153538</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 1_720)\n",
       "┌────────────┬───────┬────────────┬────────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ Patient_ID ┆ Group ┆ Group_labe ┆ binWidth   ┆ … ┆ wavelet-L ┆ wavelet-L ┆ wavelet-L ┆ wavelet-L │\n",
       "│ ---        ┆ ---   ┆ l          ┆ ---        ┆   ┆ LL_ngtdm_ ┆ LL_ngtdm_ ┆ LL_ngtdm_ ┆ LL_ngtdm_ │\n",
       "│ str        ┆ str   ┆ ---        ┆ str        ┆   ┆ Coarsenes ┆ Complexit ┆ Contrast  ┆ Strength  │\n",
       "│            ┆       ┆ i64        ┆            ┆   ┆ s         ┆ y         ┆ ---       ┆ ---       │\n",
       "│            ┆       ┆            ┆            ┆   ┆ ---       ┆ ---       ┆ f64       ┆ f64       │\n",
       "│            ┆       ┆            ┆            ┆   ┆ f64       ┆ f64       ┆           ┆           │\n",
       "╞════════════╪═══════╪════════════╪════════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ BraTS20_Tr ┆ HGG   ┆ 1          ┆ binWidth-1 ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ aining_001 ┆       ┆            ┆ 5          ┆   ┆           ┆           ┆           ┆           │\n",
       "│ BraTS20_Tr ┆ HGG   ┆ 1          ┆ binWidth-1 ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ aining_002 ┆       ┆            ┆ 5          ┆   ┆           ┆           ┆           ┆           │\n",
       "│ BraTS20_Tr ┆ HGG   ┆ 1          ┆ binWidth-1 ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ aining_003 ┆       ┆            ┆ 5          ┆   ┆           ┆           ┆           ┆           │\n",
       "│ BraTS20_Tr ┆ HGG   ┆ 1          ┆ binWidth-1 ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ aining_004 ┆       ┆            ┆ 5          ┆   ┆           ┆           ┆           ┆           │\n",
       "│ BraTS20_Tr ┆ HGG   ┆ 1          ┆ binWidth-1 ┆ … ┆ 0.220302  ┆ 0.002505  ┆ 0.000012  ┆ 0.153538  │\n",
       "│ aining_005 ┆       ┆            ┆ 5          ┆   ┆           ┆           ┆           ┆           │\n",
       "└────────────┴───────┴────────────┴────────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f872b20a",
   "metadata": {},
   "source": [
    "Look at basic statistics: \n",
    "- number of defined and undefined values in each column\n",
    "- means, standard deviations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6551cf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 1_721)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>Patient_ID</th><th>Group</th><th>Group_label</th><th>binWidth</th><th>Normalization</th><th>Age</th><th>Survival_days</th><th>Extent_of_Resection</th><th>Subregion</th><th>Sequence</th><th>diagnostics_Versions_PyRadiomics</th><th>diagnostics_Versions_Numpy</th><th>diagnostics_Versions_SimpleITK</th><th>diagnostics_Versions_PyWavelet</th><th>diagnostics_Versions_Python</th><th>diagnostics_Configuration_Settings</th><th>diagnostics_Configuration_EnabledImageTypes</th><th>diagnostics_Image-original_Hash</th><th>diagnostics_Image-original_Dimensionality</th><th>diagnostics_Image-original_Spacing</th><th>diagnostics_Image-original_Size</th><th>diagnostics_Image-original_Mean</th><th>diagnostics_Image-original_Minimum</th><th>diagnostics_Image-original_Maximum</th><th>diagnostics_Mask-original_Hash</th><th>diagnostics_Mask-original_Spacing</th><th>diagnostics_Mask-original_Size</th><th>diagnostics_Mask-original_BoundingBox</th><th>diagnostics_Mask-original_VoxelNum</th><th>diagnostics_Mask-original_VolumeNum</th><th>diagnostics_Mask-original_CenterOfMassIndex</th><th>diagnostics_Mask-original_CenterOfMass</th><th>original_shape_Elongation</th><th>original_shape_Flatness</th><th>original_shape_LeastAxisLength</th><th>original_shape_MajorAxisLength</th><th>&hellip;</th><th>wavelet-LLL_glrlm_GrayLevelNonUniformity</th><th>wavelet-LLL_glrlm_GrayLevelNonUniformityNormalized</th><th>wavelet-LLL_glrlm_GrayLevelVariance</th><th>wavelet-LLL_glrlm_HighGrayLevelRunEmphasis</th><th>wavelet-LLL_glrlm_LongRunEmphasis</th><th>wavelet-LLL_glrlm_LongRunHighGrayLevelEmphasis</th><th>wavelet-LLL_glrlm_LongRunLowGrayLevelEmphasis</th><th>wavelet-LLL_glrlm_LowGrayLevelRunEmphasis</th><th>wavelet-LLL_glrlm_RunEntropy</th><th>wavelet-LLL_glrlm_RunLengthNonUniformity</th><th>wavelet-LLL_glrlm_RunLengthNonUniformityNormalized</th><th>wavelet-LLL_glrlm_RunPercentage</th><th>wavelet-LLL_glrlm_RunVariance</th><th>wavelet-LLL_glrlm_ShortRunEmphasis</th><th>wavelet-LLL_glrlm_ShortRunHighGrayLevelEmphasis</th><th>wavelet-LLL_glrlm_ShortRunLowGrayLevelEmphasis</th><th>wavelet-LLL_glszm_GrayLevelNonUniformity</th><th>wavelet-LLL_glszm_GrayLevelNonUniformityNormalized</th><th>wavelet-LLL_glszm_GrayLevelVariance</th><th>wavelet-LLL_glszm_HighGrayLevelZoneEmphasis</th><th>wavelet-LLL_glszm_LargeAreaEmphasis</th><th>wavelet-LLL_glszm_LargeAreaHighGrayLevelEmphasis</th><th>wavelet-LLL_glszm_LargeAreaLowGrayLevelEmphasis</th><th>wavelet-LLL_glszm_LowGrayLevelZoneEmphasis</th><th>wavelet-LLL_glszm_SizeZoneNonUniformity</th><th>wavelet-LLL_glszm_SizeZoneNonUniformityNormalized</th><th>wavelet-LLL_glszm_SmallAreaEmphasis</th><th>wavelet-LLL_glszm_SmallAreaHighGrayLevelEmphasis</th><th>wavelet-LLL_glszm_SmallAreaLowGrayLevelEmphasis</th><th>wavelet-LLL_glszm_ZoneEntropy</th><th>wavelet-LLL_glszm_ZonePercentage</th><th>wavelet-LLL_glszm_ZoneVariance</th><th>wavelet-LLL_ngtdm_Busyness</th><th>wavelet-LLL_ngtdm_Coarseness</th><th>wavelet-LLL_ngtdm_Complexity</th><th>wavelet-LLL_ngtdm_Contrast</th><th>wavelet-LLL_ngtdm_Strength</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;369&quot;</td><td>&quot;369&quot;</td><td>369.0</td><td>&quot;369&quot;</td><td>&quot;369&quot;</td><td>236.0</td><td>&quot;236&quot;</td><td>&quot;129&quot;</td><td>&quot;369&quot;</td><td>&quot;369&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>368.0</td><td>368.0</td><td>368.0</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>368.0</td><td>368.0</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>&hellip;</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>0.0</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>133.0</td><td>&quot;133&quot;</td><td>&quot;240&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>1.0</td><td>1.0</td><td>1.0</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>1.0</td><td>1.0</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>&hellip;</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>null</td><td>0.794038</td><td>null</td><td>null</td><td>61.223203</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-1.3152e-17</td><td>-0.419098</td><td>10.345853</td><td>null</td><td>null</td><td>null</td><td>null</td><td>22179.336957</td><td>33.103261</td><td>null</td><td>null</td><td>0.723042</td><td>0.555079</td><td>24.485618</td><td>45.730192</td><td>&hellip;</td><td>2963.677357</td><td>0.994174</td><td>0.002913</td><td>1.352574</td><td>101.552119</td><td>169.249656</td><td>84.627828</td><td>0.911909</td><td>3.333423</td><td>422.079383</td><td>0.182812</td><td>0.256798</td><td>38.762551</td><td>0.368986</td><td>0.469273</td><td>0.343959</td><td>33.113254</td><td>0.945609</td><td>0.030401</td><td>1.31665</td><td>3.7638e8</td><td>4.8846e8</td><td>3.4836e8</td><td>0.924942</td><td>9.287271</td><td>0.324657</td><td>0.428875</td><td>0.594118</td><td>0.38953</td><td>2.38682</td><td>0.009033</td><td>1.0555e8</td><td>9.729446</td><td>760869.714043</td><td>0.0013</td><td>0.000169</td><td>0.100075</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>null</td><td>0.404952</td><td>null</td><td>null</td><td>11.874114</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>4.3709e-16</td><td>0.024681</td><td>2.671905</td><td>null</td><td>null</td><td>null</td><td>null</td><td>29878.14703</td><td>35.848002</td><td>null</td><td>null</td><td>0.155188</td><td>0.147826</td><td>10.167512</td><td>19.301596</td><td>&hellip;</td><td>2666.229821</td><td>0.037481</td><td>0.018741</td><td>0.954343</td><td>144.981048</td><td>351.244154</td><td>128.949013</td><td>0.23844</td><td>1.007408</td><td>403.022144</td><td>0.133684</td><td>0.167152</td><td>49.280637</td><td>0.171601</td><td>0.335728</td><td>0.190336</td><td>35.204095</td><td>0.129886</td><td>0.082513</td><td>0.822908</td><td>2.0864e9</td><td>2.3183e9</td><td>2.0745e9</td><td>0.190537</td><td>10.806416</td><td>0.216648</td><td>0.185001</td><td>0.522212</td><td>0.186838</td><td>0.913765</td><td>0.022325</td><td>5.4160e8</td><td>120.791894</td><td>427133.013751</td><td>0.010525</td><td>0.002248</td><td>0.280222</td></tr><tr><td>&quot;min&quot;</td><td>&quot;BraTS20_Training_001&quot;</td><td>&quot;HGG&quot;</td><td>0.0</td><td>&quot;binWidth-15&quot;</td><td>&quot;ZScore&quot;</td><td>18.975</td><td>&quot;1020&quot;</td><td>&quot;GTR&quot;</td><td>&quot;NETnNCR&quot;</td><td>&quot;T1CE&quot;</td><td>&quot;v3.0.1&quot;</td><td>&quot;1.20.3&quot;</td><td>&quot;2.1.1&quot;</td><td>&quot;1.1.1&quot;</td><td>&quot;3.9.7&quot;</td><td>&quot;{&#x27;minimumROIDimensions&#x27;: 2, &#x27;m…</td><td>&quot;{&#x27;Original&#x27;: {}, &#x27;Exponential&#x27;…</td><td>&quot;00d17d31c60689868bffb781d60587…</td><td>&quot;3D&quot;</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>-1.0822e-15</td><td>-0.50596</td><td>5.281236</td><td>&quot;0025e0bf9a63fc731cbd4286d5090c…</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>&quot;(100, 122, 78, 57, 54, 40)&quot;</td><td>47.0</td><td>1.0</td><td>&quot;(100.07977976897334, 145.51592…</td><td>&quot;(100.07977976897334, 145.51592…</td><td>0.222498</td><td>0.124907</td><td>3.738339</td><td>7.287142</td><td>&hellip;</td><td>24.230769</td><td>0.51188</td><td>0.0</td><td>1.0</td><td>1.401858</td><td>1.401858</td><td>1.011264</td><td>0.249277</td><td>0.463787</td><td>10.058603</td><td>0.025891</td><td>0.042804</td><td>0.16028</td><td>0.049052</td><td>0.049052</td><td>0.021336</td><td>1.0</td><td>0.333333</td><td>0.0</td><td>1.0</td><td>46.769231</td><td>46.769231</td><td>46.769231</td><td>0.252768</td><td>1.0</td><td>0.080332</td><td>4.0048e-11</td><td>4.0048e-11</td><td>4.0048e-11</td><td>-3.2034e-16</td><td>0.000006</td><td>0.0</td><td>0.0</td><td>0.000213</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>54.279</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-3.4967e-16</td><td>-0.434824</td><td>8.488869</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3916.0</td><td>8.0</td><td>null</td><td>null</td><td>0.634073</td><td>0.464006</td><td>17.272473</td><td>33.002982</td><td>&hellip;</td><td>1073.153846</td><td>1.0</td><td>0.0</td><td>1.0</td><td>17.366738</td><td>17.480936</td><td>16.36676</td><td>1.0</td><td>2.708348</td><td>139.166628</td><td>0.090103</td><td>0.13737</td><td>7.674577</td><td>0.248304</td><td>0.279907</td><td>0.189201</td><td>8.285714</td><td>1.0</td><td>0.0</td><td>1.0</td><td>461810.015625</td><td>502626.625</td><td>442701.042373</td><td>1.0</td><td>2.142857</td><td>0.194471</td><td>0.337449</td><td>0.349895</td><td>0.284439</td><td>2.034941</td><td>0.000739</td><td>202644.637755</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>61.526</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-2.6079e-17</td><td>-0.419837</td><td>9.997395</td><td>null</td><td>null</td><td>null</td><td>null</td><td>10590.0</td><td>22.0</td><td>null</td><td>null</td><td>0.745096</td><td>0.575729</td><td>23.508105</td><td>43.981132</td><td>&hellip;</td><td>2347.154719</td><td>1.0</td><td>0.0</td><td>1.0</td><td>43.578971</td><td>46.046788</td><td>37.590433</td><td>1.0</td><td>3.366516</td><td>310.531785</td><td>0.15146</td><td>0.216342</td><td>20.198637</td><td>0.362393</td><td>0.393413</td><td>0.341103</td><td>22.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>4.2532e6</td><td>4.6091e6</td><td>3.8849e6</td><td>1.0</td><td>5.625</td><td>0.273288</td><td>0.471941</td><td>0.5</td><td>0.420159</td><td>2.535858</td><td>0.00305</td><td>2.0973e6</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>69.178</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3.1513e-16</td><td>-0.404016</td><td>12.003048</td><td>null</td><td>null</td><td>null</td><td>null</td><td>25394.0</td><td>46.0</td><td>null</td><td>null</td><td>0.841307</td><td>0.662864</td><td>30.729417</td><td>55.860815</td><td>&hellip;</td><td>4221.153846</td><td>1.0</td><td>0.0</td><td>1.0</td><td>112.832558</td><td>139.451056</td><td>98.480431</td><td>1.0</td><td>4.035562</td><td>568.203129</td><td>0.232698</td><td>0.327519</td><td>49.737264</td><td>0.472026</td><td>0.540567</td><td>0.469102</td><td>44.166667</td><td>1.0</td><td>0.0</td><td>1.0</td><td>2.9597e7</td><td>4.0328e7</td><td>2.7477e7</td><td>1.0</td><td>12.322034</td><td>0.346939</td><td>0.553092</td><td>0.610795</td><td>0.530467</td><td>2.977079</td><td>0.007737</td><td>1.5137e7</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;max&quot;</td><td>&quot;BraTS20_Training_369&quot;</td><td>&quot;LGG&quot;</td><td>1.0</td><td>&quot;binWidth-15&quot;</td><td>&quot;ZScore&quot;</td><td>86.652</td><td>&quot;ALIVE (361 days later)&quot;</td><td>&quot;STR&quot;</td><td>&quot;NETnNCR&quot;</td><td>&quot;T1CE&quot;</td><td>&quot;v3.0.1&quot;</td><td>&quot;1.20.3&quot;</td><td>&quot;2.1.1&quot;</td><td>&quot;1.1.1&quot;</td><td>&quot;3.9.7&quot;</td><td>&quot;{&#x27;minimumROIDimensions&#x27;: 2, &#x27;m…</td><td>&quot;{&#x27;Original&#x27;: {}, &#x27;Exponential&#x27;…</td><td>&quot;feca6e10bcc8b3b7a9097190e4cc2c…</td><td>&quot;3D&quot;</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>1.0307e-15</td><td>-0.331704</td><td>35.951043</td><td>&quot;fdf0ff3c0badd2e8a8a0881244d27f…</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>&quot;(99, 84, 72, 44, 51, 50)&quot;</td><td>189152.0</td><td>270.0</td><td>&quot;(99.95001372906317, 88.9456828…</td><td>&quot;(99.95001372906317, 88.9456828…</td><td>0.984177</td><td>0.878147</td><td>59.587263</td><td>171.979417</td><td>&hellip;</td><td>16845.846154</td><td>1.0</td><td>0.24406</td><td>4.058931</td><td>879.823903</td><td>2593.162303</td><td>879.823903</td><td>1.0</td><td>5.492313</td><td>3019.874758</td><td>0.835281</td><td>0.898687</td><td>299.155169</td><td>0.929974</td><td>2.792085</td><td>0.929974</td><td>269.00738</td><td>1.0</td><td>0.734375</td><td>6.375</td><td>2.4970e10</td><td>2.4970e10</td><td>2.4970e10</td><td>1.0</td><td>75.723247</td><td>1.0</td><td>0.805556</td><td>3.087144</td><td>0.805556</td><td>4.384792</td><td>0.216667</td><td>7.9505e9</td><td>1937.165966</td><td>1e6</td><td>0.163813</td><td>0.037715</td><td>1.833333</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 1_721)\n",
       "┌────────────┬────────────┬───────┬────────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ statistic  ┆ Patient_ID ┆ Group ┆ Group_labe ┆ … ┆ wavelet-L ┆ wavelet-L ┆ wavelet-L ┆ wavelet-L │\n",
       "│ ---        ┆ ---        ┆ ---   ┆ l          ┆   ┆ LL_ngtdm_ ┆ LL_ngtdm_ ┆ LL_ngtdm_ ┆ LL_ngtdm_ │\n",
       "│ str        ┆ str        ┆ str   ┆ ---        ┆   ┆ Coarsenes ┆ Complexit ┆ Contrast  ┆ Strength  │\n",
       "│            ┆            ┆       ┆ f64        ┆   ┆ s         ┆ y         ┆ ---       ┆ ---       │\n",
       "│            ┆            ┆       ┆            ┆   ┆ ---       ┆ ---       ┆ f64       ┆ f64       │\n",
       "│            ┆            ┆       ┆            ┆   ┆ f64       ┆ f64       ┆           ┆           │\n",
       "╞════════════╪════════════╪═══════╪════════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ count      ┆ 369        ┆ 369   ┆ 369.0      ┆ … ┆ 368.0     ┆ 368.0     ┆ 368.0     ┆ 368.0     │\n",
       "│ null_count ┆ 0          ┆ 0     ┆ 0.0        ┆ … ┆ 1.0       ┆ 1.0       ┆ 1.0       ┆ 1.0       │\n",
       "│ mean       ┆ null       ┆ null  ┆ 0.794038   ┆ … ┆ 760869.71 ┆ 0.0013    ┆ 0.000169  ┆ 0.100075  │\n",
       "│            ┆            ┆       ┆            ┆   ┆ 4043      ┆           ┆           ┆           │\n",
       "│ std        ┆ null       ┆ null  ┆ 0.404952   ┆ … ┆ 427133.01 ┆ 0.010525  ┆ 0.002248  ┆ 0.280222  │\n",
       "│            ┆            ┆       ┆            ┆   ┆ 3751      ┆           ┆           ┆           │\n",
       "│ min        ┆ BraTS20_Tr ┆ HGG   ┆ 0.0        ┆ … ┆ 0.000213  ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│            ┆ aining_001 ┆       ┆            ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 25%        ┆ null       ┆ null  ┆ 1.0        ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ 50%        ┆ null       ┆ null  ┆ 1.0        ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ 75%        ┆ null       ┆ null  ┆ 1.0        ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ max        ┆ BraTS20_Tr ┆ LGG   ┆ 1.0        ┆ … ┆ 1e6       ┆ 0.163813  ┆ 0.037715  ┆ 1.833333  │\n",
       "│            ┆ aining_369 ┆       ┆            ┆   ┆           ┆           ┆           ┆           │\n",
       "└────────────┴────────────┴───────┴────────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f8e771",
   "metadata": {},
   "source": [
    "### Choosing columns to keep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863b0dd7",
   "metadata": {},
   "source": [
    "#### Understanding the structure of the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac4741f",
   "metadata": {},
   "source": [
    "There is a huge number of columns. Let's quickly explore the structure of column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b5c22f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1720 columns in total.\n",
      "\n",
      "Patient\n",
      "\t-> ['Patient_ID']\n",
      "Group\n",
      "\t -> [''] \n",
      "\tlabel -> [''] \n",
      "binWidth\n",
      "\t-> ['binWidth']\n",
      "Normalization\n",
      "\t-> ['Normalization']\n",
      "Age\n",
      "\t-> ['Age']\n",
      "Survival\n",
      "\t-> ['Survival_days']\n",
      "Extent\n",
      "\t-> ['Extent_of_Resection']\n",
      "Subregion\n",
      "\t-> ['Subregion']\n",
      "Sequence\n",
      "\t-> ['Sequence']\n",
      "diagnostics\n",
      "\tVersions -> ['PyRadiomics', 'Numpy', 'SimpleITK'] ... (5 total)\n",
      "\tConfiguration -> ['Settings', 'EnabledImageTypes'] \n",
      "\tImage-original -> ['Hash', 'Dimensionality', 'Spacing'] ... (7 total)\n",
      "\tMask-original -> ['Hash', 'Spacing', 'Size'] ... (8 total)\n",
      "original\n",
      "\tshape -> ['Elongation', 'Flatness', 'LeastAxisLength'] ... (14 total)\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "exponential\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "gradient\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "lbp-2D\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "lbp-3D-m1\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "lbp-3D-m2\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "lbp-3D-k\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "logarithm\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "square\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "squareroot\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "wavelet-LLH\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "wavelet-LHL\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "wavelet-LHH\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "wavelet-HLL\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "wavelet-HLH\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "wavelet-HHL\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "wavelet-HHH\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "wavelet-LLL\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(df.columns)} columns in total.\\n\")\n",
    "\n",
    "\n",
    "def key(colname):\n",
    "    return colname.split(\"_\")[0]\n",
    "\n",
    "\n",
    "for column_group, columns in groupby(df.columns, key):\n",
    "    print(column_group)\n",
    "    columns = list(columns)\n",
    "    if len(columns) == 1:\n",
    "        print(f\"\\t-> {columns}\")\n",
    "        continue\n",
    "    columns = [colname[len(column_group) + 1 :] for colname in columns]\n",
    "    for column_subgroup, subcolumns in groupby(columns, key):\n",
    "        maxlen, suffix = 3, \"\"\n",
    "        subcolumns = [colname[len(column_subgroup) + 1 :] for colname in subcolumns]\n",
    "        if (lensubcols := len(subcolumns)) > maxlen:\n",
    "            subcolumns = subcolumns[:maxlen]\n",
    "            suffix = f\"... ({lensubcols} total)\"\n",
    "        print(f\"\\t{column_subgroup} -> {subcolumns} {suffix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5b1222",
   "metadata": {},
   "source": [
    "#### Selecting wanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e3e7575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can either specify columns to drop or to keep.\n",
    "# In this case, there are 1720 columns, so it's easier to specify which ones to keep.\n",
    "\n",
    "# Target variables: ignore Survival_days (too many missing values)\n",
    "targets = [\"Group\"]\n",
    "\n",
    "# Clinical inputs: ignore Age and Extent_of_Resection (too many missing values):\n",
    "inputs_clinical = []\n",
    "\n",
    "# Radiomic inputs: keep only basic radiomic features and ignore the rest:\n",
    "inputs_radiomics = [col for col in df.columns if col.startswith(\"original_\")]\n",
    "df = df.select(targets + inputs_clinical + inputs_radiomics).rename(\n",
    "    {col: col[9:] for col in inputs_radiomics}\n",
    ")\n",
    "\n",
    "# By doing this selection, we also dropped the following metadata columns:\n",
    "# Patient_ID, Group_label, binWidth, Normalization, Subregion, Sequence\n",
    "# As well as all diagnostics_... columns (give information about radiomic feature extraction process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8a2296",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d2fa9b",
   "metadata": {},
   "source": [
    "Handle missing values: in this case there is only one row with missing data (as shown by the `df.describe` output above).\n",
    "\n",
    "Generally, there are different strategies to handle missing data:\n",
    "- Dropping all rows with missing values (like we do here since there is only one)\n",
    "- Dropping columns with missing values (after checking there is almost no data in them)\n",
    "- Filling missing values, e.g. with the median (imputation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58638f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after dropping nulls: (368, 108)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_nulls()\n",
    "print(\"Dataset shape after dropping nulls:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b6712c",
   "metadata": {},
   "source": [
    "### Looking at the prepared data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957fd0ab",
   "metadata": {},
   "source": [
    "Look again at a few examples and basic statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9628e6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 108)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Group</th><th>shape_Elongation</th><th>shape_Flatness</th><th>shape_LeastAxisLength</th><th>shape_MajorAxisLength</th><th>shape_Maximum2DDiameterColumn</th><th>shape_Maximum2DDiameterRow</th><th>shape_Maximum2DDiameterSlice</th><th>shape_Maximum3DDiameter</th><th>shape_MeshVolume</th><th>shape_MinorAxisLength</th><th>shape_Sphericity</th><th>shape_SurfaceArea</th><th>shape_SurfaceVolumeRatio</th><th>shape_VoxelVolume</th><th>firstorder_10Percentile</th><th>firstorder_90Percentile</th><th>firstorder_Energy</th><th>firstorder_Entropy</th><th>firstorder_InterquartileRange</th><th>firstorder_Kurtosis</th><th>firstorder_Maximum</th><th>firstorder_MeanAbsoluteDeviation</th><th>firstorder_Mean</th><th>firstorder_Median</th><th>firstorder_Minimum</th><th>firstorder_Range</th><th>firstorder_RobustMeanAbsoluteDeviation</th><th>firstorder_RootMeanSquared</th><th>firstorder_Skewness</th><th>firstorder_TotalEnergy</th><th>firstorder_Uniformity</th><th>firstorder_Variance</th><th>glcm_Autocorrelation</th><th>glcm_ClusterProminence</th><th>glcm_ClusterShade</th><th>glcm_ClusterTendency</th><th>&hellip;</th><th>glrlm_GrayLevelNonUniformity</th><th>glrlm_GrayLevelNonUniformityNormalized</th><th>glrlm_GrayLevelVariance</th><th>glrlm_HighGrayLevelRunEmphasis</th><th>glrlm_LongRunEmphasis</th><th>glrlm_LongRunHighGrayLevelEmphasis</th><th>glrlm_LongRunLowGrayLevelEmphasis</th><th>glrlm_LowGrayLevelRunEmphasis</th><th>glrlm_RunEntropy</th><th>glrlm_RunLengthNonUniformity</th><th>glrlm_RunLengthNonUniformityNormalized</th><th>glrlm_RunPercentage</th><th>glrlm_RunVariance</th><th>glrlm_ShortRunEmphasis</th><th>glrlm_ShortRunHighGrayLevelEmphasis</th><th>glrlm_ShortRunLowGrayLevelEmphasis</th><th>glszm_GrayLevelNonUniformity</th><th>glszm_GrayLevelNonUniformityNormalized</th><th>glszm_GrayLevelVariance</th><th>glszm_HighGrayLevelZoneEmphasis</th><th>glszm_LargeAreaEmphasis</th><th>glszm_LargeAreaHighGrayLevelEmphasis</th><th>glszm_LargeAreaLowGrayLevelEmphasis</th><th>glszm_LowGrayLevelZoneEmphasis</th><th>glszm_SizeZoneNonUniformity</th><th>glszm_SizeZoneNonUniformityNormalized</th><th>glszm_SmallAreaEmphasis</th><th>glszm_SmallAreaHighGrayLevelEmphasis</th><th>glszm_SmallAreaLowGrayLevelEmphasis</th><th>glszm_ZoneEntropy</th><th>glszm_ZonePercentage</th><th>glszm_ZoneVariance</th><th>ngtdm_Busyness</th><th>ngtdm_Coarseness</th><th>ngtdm_Complexity</th><th>ngtdm_Contrast</th><th>ngtdm_Strength</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;HGG&quot;</td><td>0.731829</td><td>0.41979</td><td>21.139285</td><td>50.356792</td><td>50.358713</td><td>59.539903</td><td>50.990195</td><td>63.85922</td><td>15226.333333</td><td>36.852581</td><td>0.333812</td><td>8899.775397</td><td>0.584499</td><td>15443.0</td><td>0.891341</td><td>2.406696</td><td>43805.647206</td><td>0.000994</td><td>0.76735</td><td>3.905945</td><td>4.857057</td><td>0.476079</td><td>1.57019</td><td>1.471689</td><td>-0.037217</td><td>4.894274</td><td>0.322622</td><td>1.684222</td><td>0.845454</td><td>43805.647206</td><td>0.99987</td><td>0.371107</td><td>3.999682</td><td>0.000159</td><td>-0.000159</td><td>0.000159</td><td>&hellip;</td><td>2837.693033</td><td>0.999275</td><td>0.000362</td><td>3.998912</td><td>56.052892</td><td>224.210478</td><td>14.013495</td><td>0.250272</td><td>3.685716</td><td>315.192629</td><td>0.108203</td><td>0.183882</td><td>23.686554</td><td>0.285304</td><td>1.140127</td><td>0.071598</td><td>33.057143</td><td>0.94449</td><td>0.027755</td><td>3.914286</td><td>6.2008e6</td><td>2.4803e7</td><td>1.5502e6</td><td>0.271429</td><td>5.971429</td><td>0.170612</td><td>0.397002</td><td>1.502295</td><td>0.120679</td><td>3.231618</td><td>0.002266</td><td>6.0061e6</td><td>0.300826</td><td>0.831125</td><td>0.000156</td><td>9.2377e-9</td><td>0.90777</td></tr><tr><td>&quot;HGG&quot;</td><td>0.805201</td><td>0.596898</td><td>17.919111</td><td>30.020387</td><td>34.132096</td><td>34.525353</td><td>31.144823</td><td>35.496479</td><td>9073.541667</td><td>24.172434</td><td>0.73062</td><td>2879.455924</td><td>0.317346</td><td>9160.0</td><td>0.511066</td><td>1.20927</td><td>7040.180407</td><td>-3.2034e-16</td><td>0.263257</td><td>10.595436</td><td>3.429786</td><td>0.233776</td><td>0.801736</td><td>0.711371</td><td>0.013167</td><td>3.416619</td><td>0.120232</td><td>0.876686</td><td>2.380337</td><td>7040.180407</td><td>1.0</td><td>0.125799</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>931.230769</td><td>1.0</td><td>0.0</td><td>1.0</td><td>148.738015</td><td>148.738015</td><td>148.738015</td><td>1.0</td><td>4.063811</td><td>65.188726</td><td>0.068125</td><td>0.101663</td><td>37.847387</td><td>0.148596</td><td>0.148596</td><td>0.148596</td><td>9.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>9.1449e6</td><td>9.1449e6</td><td>9.1449e6</td><td>1.0</td><td>1.0</td><td>0.111111</td><td>0.155282</td><td>0.155282</td><td>0.155282</td><td>3.169925</td><td>0.000983</td><td>8.1090e6</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;HGG&quot;</td><td>0.768372</td><td>0.722447</td><td>11.550058</td><td>15.987407</td><td>18.681542</td><td>18.384776</td><td>18.681542</td><td>22.135944</td><td>684.083333</td><td>12.284284</td><td>0.406249</td><td>924.196735</td><td>1.351</td><td>733.0</td><td>1.441948</td><td>3.355092</td><td>4630.563368</td><td>-3.2034e-16</td><td>1.090258</td><td>2.45011</td><td>4.360985</td><td>0.592579</td><td>2.407835</td><td>2.420584</td><td>0.713811</td><td>3.647174</td><td>0.43292</td><td>2.513419</td><td>0.055125</td><td>4630.563368</td><td>1.0</td><td>0.519605</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>291.153846</td><td>1.0</td><td>0.0</td><td>1.0</td><td>10.77577</td><td>10.77577</td><td>10.77577</td><td>1.0</td><td>2.387787</td><td>77.714144</td><td>0.259495</td><td>0.397209</td><td>3.934461</td><td>0.500213</td><td>0.500213</td><td>0.500213</td><td>7.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>62367.571429</td><td>62367.571429</td><td>62367.571429</td><td>1.0</td><td>1.285714</td><td>0.183673</td><td>0.298127</td><td>0.298127</td><td>0.298127</td><td>2.521641</td><td>0.00955</td><td>51402.489796</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;HGG&quot;</td><td>0.880563</td><td>0.556199</td><td>21.603687</td><td>38.841633</td><td>42.720019</td><td>46.238512</td><td>44.384682</td><td>46.914816</td><td>10608.041667</td><td>34.202508</td><td>0.246069</td><td>9488.192833</td><td>0.894434</td><td>10902.0</td><td>0.862828</td><td>2.445411</td><td>32015.142395</td><td>-3.2034e-16</td><td>0.977685</td><td>2.574108</td><td>4.196802</td><td>0.524396</td><td>1.598139</td><td>1.523996</td><td>0.342334</td><td>3.854469</td><td>0.404497</td><td>1.71366</td><td>0.501066</td><td>32015.142395</td><td>1.0</td><td>0.382583</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>2986.769231</td><td>1.0</td><td>0.0</td><td>1.0</td><td>27.455009</td><td>27.455009</td><td>27.455009</td><td>1.0</td><td>3.051311</td><td>557.843589</td><td>0.182311</td><td>0.273965</td><td>13.085883</td><td>0.40605</td><td>0.40605</td><td>0.40605</td><td>37.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>3.0228e6</td><td>3.0228e6</td><td>3.0228e6</td><td>1.0</td><td>5.594595</td><td>0.151205</td><td>0.360428</td><td>0.360428</td><td>0.360428</td><td>3.230669</td><td>0.003394</td><td>2.9360e6</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;HGG&quot;</td><td>0.342747</td><td>0.309231</td><td>20.04694</td><td>64.828365</td><td>60.60528</td><td>32.280025</td><td>48.754487</td><td>61.43289</td><td>3209.833333</td><td>22.219752</td><td>0.201071</td><td>5233.470765</td><td>1.630449</td><td>3624.0</td><td>1.890351</td><td>3.694297</td><td>29902.191747</td><td>-3.2034e-16</td><td>0.940189</td><td>3.291029</td><td>5.82697</td><td>0.555445</td><td>2.785681</td><td>2.769665</td><td>0.639021</td><td>5.187949</td><td>0.391193</td><td>2.872483</td><td>0.463672</td><td>29902.191747</td><td>1.0</td><td>0.491141</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>1629.384615</td><td>1.0</td><td>0.0</td><td>1.0</td><td>8.473932</td><td>8.473932</td><td>8.473932</td><td>1.0</td><td>2.199209</td><td>505.603602</td><td>0.304522</td><td>0.449609</td><td>3.261904</td><td>0.551107</td><td>0.551107</td><td>0.551107</td><td>37.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>216977.945946</td><td>216977.945946</td><td>216977.945946</td><td>1.0</td><td>12.027027</td><td>0.325055</td><td>0.582357</td><td>0.582357</td><td>0.582357</td><td>2.332735</td><td>0.01021</td><td>207384.537619</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 108)\n",
       "┌───────┬────────────┬────────────┬────────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ Group ┆ shape_Elon ┆ shape_Flat ┆ shape_Leas ┆ … ┆ ngtdm_Coa ┆ ngtdm_Com ┆ ngtdm_Con ┆ ngtdm_Str │\n",
       "│ ---   ┆ gation     ┆ ness       ┆ tAxisLengt ┆   ┆ rseness   ┆ plexity   ┆ trast     ┆ ength     │\n",
       "│ str   ┆ ---        ┆ ---        ┆ h          ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│       ┆ f64        ┆ f64        ┆ ---        ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "│       ┆            ┆            ┆ f64        ┆   ┆           ┆           ┆           ┆           │\n",
       "╞═══════╪════════════╪════════════╪════════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ HGG   ┆ 0.731829   ┆ 0.41979    ┆ 21.139285  ┆ … ┆ 0.831125  ┆ 0.000156  ┆ 9.2377e-9 ┆ 0.90777   │\n",
       "│ HGG   ┆ 0.805201   ┆ 0.596898   ┆ 17.919111  ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ HGG   ┆ 0.768372   ┆ 0.722447   ┆ 11.550058  ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ HGG   ┆ 0.880563   ┆ 0.556199   ┆ 21.603687  ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ HGG   ┆ 0.342747   ┆ 0.309231   ┆ 20.04694   ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "└───────┴────────────┴────────────┴────────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac56c3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 109)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>Group</th><th>shape_Elongation</th><th>shape_Flatness</th><th>shape_LeastAxisLength</th><th>shape_MajorAxisLength</th><th>shape_Maximum2DDiameterColumn</th><th>shape_Maximum2DDiameterRow</th><th>shape_Maximum2DDiameterSlice</th><th>shape_Maximum3DDiameter</th><th>shape_MeshVolume</th><th>shape_MinorAxisLength</th><th>shape_Sphericity</th><th>shape_SurfaceArea</th><th>shape_SurfaceVolumeRatio</th><th>shape_VoxelVolume</th><th>firstorder_10Percentile</th><th>firstorder_90Percentile</th><th>firstorder_Energy</th><th>firstorder_Entropy</th><th>firstorder_InterquartileRange</th><th>firstorder_Kurtosis</th><th>firstorder_Maximum</th><th>firstorder_MeanAbsoluteDeviation</th><th>firstorder_Mean</th><th>firstorder_Median</th><th>firstorder_Minimum</th><th>firstorder_Range</th><th>firstorder_RobustMeanAbsoluteDeviation</th><th>firstorder_RootMeanSquared</th><th>firstorder_Skewness</th><th>firstorder_TotalEnergy</th><th>firstorder_Uniformity</th><th>firstorder_Variance</th><th>glcm_Autocorrelation</th><th>glcm_ClusterProminence</th><th>glcm_ClusterShade</th><th>&hellip;</th><th>glrlm_GrayLevelNonUniformity</th><th>glrlm_GrayLevelNonUniformityNormalized</th><th>glrlm_GrayLevelVariance</th><th>glrlm_HighGrayLevelRunEmphasis</th><th>glrlm_LongRunEmphasis</th><th>glrlm_LongRunHighGrayLevelEmphasis</th><th>glrlm_LongRunLowGrayLevelEmphasis</th><th>glrlm_LowGrayLevelRunEmphasis</th><th>glrlm_RunEntropy</th><th>glrlm_RunLengthNonUniformity</th><th>glrlm_RunLengthNonUniformityNormalized</th><th>glrlm_RunPercentage</th><th>glrlm_RunVariance</th><th>glrlm_ShortRunEmphasis</th><th>glrlm_ShortRunHighGrayLevelEmphasis</th><th>glrlm_ShortRunLowGrayLevelEmphasis</th><th>glszm_GrayLevelNonUniformity</th><th>glszm_GrayLevelNonUniformityNormalized</th><th>glszm_GrayLevelVariance</th><th>glszm_HighGrayLevelZoneEmphasis</th><th>glszm_LargeAreaEmphasis</th><th>glszm_LargeAreaHighGrayLevelEmphasis</th><th>glszm_LargeAreaLowGrayLevelEmphasis</th><th>glszm_LowGrayLevelZoneEmphasis</th><th>glszm_SizeZoneNonUniformity</th><th>glszm_SizeZoneNonUniformityNormalized</th><th>glszm_SmallAreaEmphasis</th><th>glszm_SmallAreaHighGrayLevelEmphasis</th><th>glszm_SmallAreaLowGrayLevelEmphasis</th><th>glszm_ZoneEntropy</th><th>glszm_ZonePercentage</th><th>glszm_ZoneVariance</th><th>ngtdm_Busyness</th><th>ngtdm_Coarseness</th><th>ngtdm_Complexity</th><th>ngtdm_Contrast</th><th>ngtdm_Strength</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;368&quot;</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>&hellip;</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>0.723042</td><td>0.555079</td><td>24.485618</td><td>45.730192</td><td>45.057</td><td>51.053797</td><td>49.333276</td><td>56.808197</td><td>21862.7851</td><td>32.004908</td><td>0.376242</td><td>9237.61258</td><td>0.923609</td><td>22179.336957</td><td>1.374584</td><td>2.522678</td><td>74696.113733</td><td>0.007873</td><td>0.626598</td><td>3.996735</td><td>4.162478</td><td>0.36554</td><td>1.920441</td><td>1.882498</td><td>0.571002</td><td>3.591476</td><td>0.261605</td><td>1.985013</td><td>0.372539</td><td>74696.113733</td><td>0.996985</td><td>0.23679</td><td>1.530893</td><td>0.006383</td><td>-0.003187</td><td>&hellip;</td><td>2971.81061</td><td>0.994031</td><td>0.002985</td><td>1.526069</td><td>100.816023</td><td>186.329359</td><td>79.43769</td><td>0.868483</td><td>3.329075</td><td>428.802215</td><td>0.183117</td><td>0.2571</td><td>38.653377</td><td>0.369848</td><td>0.53148</td><td>0.32944</td><td>34.180723</td><td>0.959979</td><td>0.02001</td><td>1.353266</td><td>3.3695e8</td><td>5.0550e8</td><td>2.9481e8</td><td>0.911684</td><td>9.541138</td><td>0.32483</td><td>0.43707</td><td>0.604474</td><td>0.395219</td><td>2.36478</td><td>0.008932</td><td>1.1143e8</td><td>14.646119</td><td>826087.014728</td><td>0.0014</td><td>0.000218</td><td>0.055786</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>0.155188</td><td>0.147826</td><td>10.167512</td><td>19.301596</td><td>16.080009</td><td>20.17874</td><td>19.738679</td><td>21.27765</td><td>29860.458179</td><td>12.507605</td><td>0.155833</td><td>8357.631322</td><td>0.910963</td><td>29878.14703</td><td>0.524901</td><td>0.51373</td><td>101634.496284</td><td>0.067677</td><td>0.276941</td><td>3.48061</td><td>1.281748</td><td>0.143954</td><td>0.490192</td><td>0.526195</td><td>0.592212</td><td>1.55996</td><td>0.111509</td><td>0.474185</td><td>0.726591</td><td>101634.496284</td><td>0.032312</td><td>0.185438</td><td>1.140018</td><td>0.065065</td><td>0.030067</td><td>&hellip;</td><td>2678.237799</td><td>0.03868</td><td>0.01934</td><td>1.1305</td><td>143.823868</td><td>380.737352</td><td>123.451225</td><td>0.282625</td><td>1.00734</td><td>424.904352</td><td>0.133404</td><td>0.166938</td><td>49.160277</td><td>0.170914</td><td>0.427127</td><td>0.195481</td><td>35.946525</td><td>0.10927</td><td>0.054635</td><td>0.870037</td><td>1.8943e9</td><td>2.7633e9</td><td>1.8311e9</td><td>0.217509</td><td>11.072411</td><td>0.214116</td><td>0.182395</td><td>0.521023</td><td>0.192639</td><td>0.912152</td><td>0.022245</td><td>5.8674e8</td><td>181.567308</td><td>379550.608458</td><td>0.013492</td><td>0.002967</td><td>0.199405</td></tr><tr><td>&quot;min&quot;</td><td>&quot;HGG&quot;</td><td>0.222498</td><td>0.124907</td><td>3.738339</td><td>7.287142</td><td>8.062258</td><td>7.28011</td><td>5.385165</td><td>9.0</td><td>22.083333</td><td>5.415523</td><td>0.096556</td><td>68.848149</td><td>0.131759</td><td>47.0</td><td>-0.190334</td><td>0.736837</td><td>370.774559</td><td>-3.2034e-16</td><td>0.153756</td><td>1.752027</td><td>1.681907</td><td>0.093379</td><td>0.203953</td><td>0.105943</td><td>-0.454909</td><td>0.528899</td><td>0.064838</td><td>0.431033</td><td>-3.62028</td><td>370.774559</td><td>0.534089</td><td>0.01326</td><td>1.0</td><td>0.0</td><td>-0.472291</td><td>&hellip;</td><td>24.230769</td><td>0.50779</td><td>0.0</td><td>1.0</td><td>1.401858</td><td>1.401858</td><td>0.70266</td><td>0.250107</td><td>0.463787</td><td>10.058603</td><td>0.025888</td><td>0.042804</td><td>0.16028</td><td>0.049052</td><td>0.049052</td><td>0.021305</td><td>1.0</td><td>0.5</td><td>0.0</td><td>1.0</td><td>46.769231</td><td>46.769231</td><td>46.769231</td><td>0.255952</td><td>1.0</td><td>0.080332</td><td>4.0048e-11</td><td>4.0048e-11</td><td>4.0048e-11</td><td>-3.2034e-16</td><td>0.000006</td><td>0.0</td><td>0.0</td><td>0.000141</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>0.634073</td><td>0.464006</td><td>17.272473</td><td>33.002982</td><td>33.615473</td><td>36.796739</td><td>35.171011</td><td>42.296572</td><td>3599.625</td><td>22.601235</td><td>0.255762</td><td>3351.436318</td><td>0.417864</td><td>3916.0</td><td>0.979455</td><td>2.190171</td><td>15821.058967</td><td>-3.2034e-16</td><td>0.434014</td><td>2.627947</td><td>3.155506</td><td>0.264655</td><td>1.598257</td><td>1.526641</td><td>0.12344</td><td>2.401487</td><td>0.185134</td><td>1.684222</td><td>-0.086409</td><td>15821.058967</td><td>1.0</td><td>0.118225</td><td>1.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>1073.153846</td><td>1.0</td><td>0.0</td><td>1.0</td><td>17.366738</td><td>17.68425</td><td>13.858298</td><td>1.0</td><td>2.709055</td><td>139.281601</td><td>0.09154</td><td>0.137531</td><td>7.674577</td><td>0.249261</td><td>0.285863</td><td>0.162384</td><td>9.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>461810.015625</td><td>518611.833333</td><td>358783.870588</td><td>1.0</td><td>2.166667</td><td>0.195924</td><td>0.346738</td><td>0.354169</td><td>0.277291</td><td>2.0</td><td>0.000764</td><td>206626.107085</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>0.745096</td><td>0.575729</td><td>23.508105</td><td>43.981132</td><td>44.407207</td><td>50.219518</td><td>49.406477</td><td>56.471232</td><td>10340.5</td><td>31.362378</td><td>0.34617</td><td>7331.645871</td><td>0.695517</td><td>10590.0</td><td>1.327203</td><td>2.508456</td><td>41385.619211</td><td>-3.2034e-16</td><td>0.586345</td><td>3.262533</td><td>3.778643</td><td>0.346395</td><td>1.901583</td><td>1.847197</td><td>0.505102</td><td>3.35169</td><td>0.242905</td><td>1.964811</td><td>0.387561</td><td>41385.619211</td><td>1.0</td><td>0.190868</td><td>1.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>2348.384615</td><td>1.0</td><td>0.0</td><td>1.0</td><td>43.578971</td><td>52.818404</td><td>33.627387</td><td>1.0</td><td>3.366516</td><td>310.531785</td><td>0.153595</td><td>0.216342</td><td>20.198637</td><td>0.364618</td><td>0.412441</td><td>0.32097</td><td>22.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>4.3332e6</td><td>4.9021e6</td><td>3.0420e6</td><td>1.0</td><td>5.769231</td><td>0.27388</td><td>0.478282</td><td>0.501914</td><td>0.432565</td><td>2.508817</td><td>0.002867</td><td>2.1113e6</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>0.841307</td><td>0.662864</td><td>30.729417</td><td>55.860815</td><td>55.713553</td><td>63.906181</td><td>61.188234</td><td>69.318107</td><td>25147.291667</td><td>39.560643</td><td>0.469189</td><td>12960.865504</td><td>1.102541</td><td>25394.0</td><td>1.757149</td><td>2.800596</td><td>90886.79294</td><td>-3.2034e-16</td><td>0.789395</td><td>4.172358</td><td>5.021085</td><td>0.461592</td><td>2.238754</td><td>2.250661</td><td>0.973464</td><td>4.641944</td><td>0.327086</td><td>2.290388</td><td>0.778114</td><td>90886.79294</td><td>1.0</td><td>0.312538</td><td>1.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>4221.153846</td><td>1.0</td><td>0.0</td><td>1.0</td><td>112.962502</td><td>171.722879</td><td>91.251669</td><td>1.0</td><td>4.035562</td><td>568.203129</td><td>0.232698</td><td>0.327519</td><td>49.737264</td><td>0.47274</td><td>0.609252</td><td>0.462379</td><td>46.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>3.0101e7</td><td>4.1876e7</td><td>2.0333272e7</td><td>1.0</td><td>12.742857</td><td>0.34375</td><td>0.559436</td><td>0.597117</td><td>0.535245</td><td>2.947703</td><td>0.00765</td><td>1.5384e7</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;max&quot;</td><td>&quot;LGG&quot;</td><td>0.984177</td><td>0.878147</td><td>59.587263</td><td>171.979417</td><td>105.475116</td><td>113.216607</td><td>117.885538</td><td>132.07195</td><td>188726.0</td><td>70.539774</td><td>0.831783</td><td>52815.73818</td><td>9.842839</td><td>189152.0</td><td>3.048159</td><td>4.654783</td><td>874135.428433</td><td>0.950246</td><td>2.081183</td><td>50.929231</td><td>8.818044</td><td>1.103804</td><td>3.364545</td><td>3.396505</td><td>2.232331</td><td>9.234909</td><td>0.839303</td><td>3.372971</td><td>4.427729</td><td>874135.428433</td><td>1.0</td><td>1.726145</td><td>4.0</td><td>0.914482</td><td>0.0</td><td>&hellip;</td><td>16845.846154</td><td>1.0</td><td>0.246105</td><td>3.99957</td><td>879.823903</td><td>2928.225613</td><td>879.823903</td><td>1.0</td><td>5.492323</td><td>3024.76271</td><td>0.835281</td><td>0.898687</td><td>299.155169</td><td>0.929974</td><td>2.972293</td><td>0.929974</td><td>267.116364</td><td>1.0</td><td>0.25</td><td>3.97619</td><td>2.4970e10</td><td>3.8177e10</td><td>2.4970e10</td><td>1.0</td><td>78.549091</td><td>1.0</td><td>0.857143</td><td>2.667181</td><td>0.857143</td><td>4.328883</td><td>0.216667</td><td>7.9505e9</td><td>3093.259142</td><td>1e6</td><td>0.199553</td><td>0.046437</td><td>1.236522</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 109)\n",
       "┌────────────┬───────┬────────────┬────────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ statistic  ┆ Group ┆ shape_Elon ┆ shape_Flat ┆ … ┆ ngtdm_Coa ┆ ngtdm_Com ┆ ngtdm_Con ┆ ngtdm_Str │\n",
       "│ ---        ┆ ---   ┆ gation     ┆ ness       ┆   ┆ rseness   ┆ plexity   ┆ trast     ┆ ength     │\n",
       "│ str        ┆ str   ┆ ---        ┆ ---        ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│            ┆       ┆ f64        ┆ f64        ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞════════════╪═══════╪════════════╪════════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ count      ┆ 368   ┆ 368.0      ┆ 368.0      ┆ … ┆ 368.0     ┆ 368.0     ┆ 368.0     ┆ 368.0     │\n",
       "│ null_count ┆ 0     ┆ 0.0        ┆ 0.0        ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ mean       ┆ null  ┆ 0.723042   ┆ 0.555079   ┆ … ┆ 826087.01 ┆ 0.0014    ┆ 0.000218  ┆ 0.055786  │\n",
       "│            ┆       ┆            ┆            ┆   ┆ 4728      ┆           ┆           ┆           │\n",
       "│ std        ┆ null  ┆ 0.155188   ┆ 0.147826   ┆ … ┆ 379550.60 ┆ 0.013492  ┆ 0.002967  ┆ 0.199405  │\n",
       "│            ┆       ┆            ┆            ┆   ┆ 8458      ┆           ┆           ┆           │\n",
       "│ min        ┆ HGG   ┆ 0.222498   ┆ 0.124907   ┆ … ┆ 0.000141  ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ 25%        ┆ null  ┆ 0.634073   ┆ 0.464006   ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ 50%        ┆ null  ┆ 0.745096   ┆ 0.575729   ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ 75%        ┆ null  ┆ 0.841307   ┆ 0.662864   ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ max        ┆ LGG   ┆ 0.984177   ┆ 0.878147   ┆ … ┆ 1e6       ┆ 0.199553  ┆ 0.046437  ┆ 1.236522  │\n",
       "└────────────┴───────┴────────────┴────────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f258c5",
   "metadata": {},
   "source": [
    "### Create a test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e252b0",
   "metadata": {},
   "source": [
    "This is important to make sure our final model performs as well on unseen data as it does on the training set.\n",
    "\n",
    "- Here we use a stratified split to make ensure that training and test sets have the same class distribution.\n",
    "- We also specify a random seed to ensure reproducibility of the sample shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "725aa59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split the data in Train and Test subsets.\n",
      "\n",
      "Check class proportions in training dataset:\n",
      "shape: (2, 3)\n",
      "┌───────┬───────┬────────────┐\n",
      "│ Group ┆ count ┆ proportion │\n",
      "│ ---   ┆ ---   ┆ ---        │\n",
      "│ str   ┆ u32   ┆ f64        │\n",
      "╞═══════╪═══════╪════════════╡\n",
      "│ HGG   ┆ 233   ┆ 0.792517   │\n",
      "│ LGG   ┆ 61    ┆ 0.207483   │\n",
      "└───────┴───────┴────────────┘\n",
      "\n",
      "Check class proportions in test dataset:\n",
      "shape: (2, 3)\n",
      "┌───────┬───────┬────────────┐\n",
      "│ Group ┆ count ┆ proportion │\n",
      "│ ---   ┆ ---   ┆ ---        │\n",
      "│ str   ┆ u32   ┆ f64        │\n",
      "╞═══════╪═══════╪════════════╡\n",
      "│ HGG   ┆ 59    ┆ 0.797297   │\n",
      "│ LGG   ┆ 15    ┆ 0.202703   │\n",
      "└───────┴───────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(\"Split the data in Train and Test subsets.\")\n",
    "\n",
    "training_data, test_data = train_test_split(\n",
    "    df,\n",
    "    test_size=0.20,\n",
    "    stratify=df[\"Group\"],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "def check_class_proportions(df: pl.DataFrame):\n",
    "    summary = (\n",
    "        df.group_by(\"Group\")\n",
    "        .agg(pl.len().alias(\"count\"))\n",
    "        .with_columns((pl.col(\"count\") / pl.col(\"count\").sum()).alias(\"proportion\"))\n",
    "        .sort(\"count\", descending=True)\n",
    "    )\n",
    "    return summary\n",
    "\n",
    "\n",
    "print(\"\\nCheck class proportions in training dataset:\")\n",
    "print(check_class_proportions(training_data))\n",
    "\n",
    "print(\"\\nCheck class proportions in test dataset:\")\n",
    "print(check_class_proportions(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5e71dc",
   "metadata": {},
   "source": [
    "Finaly we separate inputs from targets in the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64ece5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(training_inputs_df)=<class 'polars.dataframe.frame.DataFrame'>\n",
      "type(training_targets_df)=<class 'polars.dataframe.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "training_inputs_df = training_data.drop(\"Group\")\n",
    "training_targets_df = training_data.select(\"Group\")\n",
    "\n",
    "print(f\"{type(training_inputs_df)=}\")\n",
    "print(f\"{type(training_targets_df)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe434729",
   "metadata": {},
   "source": [
    "## Pre-processing the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdbdd38",
   "metadata": {},
   "source": [
    "### Encoding the target variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e639ea3",
   "metadata": {},
   "source": [
    "Each sample has a target class label to predict, either \"HGG\" or \"LGG\".\n",
    "Scikit-learn provides a label encoder to convert label strings to label integer IDs.\n",
    "The `LabelEncoder` class that can be fitted to the target data and later reused to convert the output of the model (class 0, class 1...) to a human-readable format (\"HGG\", \"LGG\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da8b9247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(y_train) = <class 'numpy.ndarray'>\n",
      "y_train.shape = (294,)\n",
      "y_train[:10] = array([0, 0, 0, 1, 0, 0, 1, 0, 0, 0])\n",
      "Class 0: HGG (support: 233)\n",
      "Class 1: LGG (support: 61)\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(training_targets_df.to_numpy().ravel())\n",
    "\n",
    "print(f\"{type(y_train) = }\")\n",
    "print(f\"{y_train.shape = }\")\n",
    "print(f\"{y_train[:10] = }\")\n",
    "\n",
    "for i, class_name in enumerate(label_encoder.classes_):\n",
    "    class_support = sum(y_train == i)\n",
    "    print(f\"Class {i}: {class_name} (support: {class_support})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965c2a20",
   "metadata": {},
   "source": [
    "### Preprocessing the input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd684e9",
   "metadata": {},
   "source": [
    "The input variables cannot be used in their raw form directly. Categorical inputs are strings that don't mean anything to the model, and numerical inputs can have widely different distributions, making learning difficult for some models: they need to be normalized first. Some models don't require normalization, like the powerful Random Forest, but it doesn't hurt to normalize the data anyways.\n",
    "\n",
    "Below, we use some of scikit-learn's [transformers](https://scikit-learn.org/stable/data_transforms.html) to preprocess the training data before training. \n",
    "\n",
    "Transformers (the name is unrelated to the famous deep learning [transformer](https://doi.org/10.48550/arXiv.1706.03762) architecture) are one of the three types of building blocks of the scikit-learn API, which are *Estimators*, *Transformers* and *Predictors*. These are detailed in the library's main [design principles](https://doi.org/10.48550/arXiv.1309.0238)\n",
    "\n",
    "Each of transformer has a `fit` and a `transform` method: `fit` is used a single time to record what preprocessing needs to be done, while `transform` can be used any number of times in downstream tasks to apply the pre-processing to new inputs. In the code, we use the shortcut `fit_transform` method that does both actions at the same time on our training dataset.\n",
    "\n",
    "We also use the `Pipeline` class to wrap each transformer object we define. Eventually, we'll define a `ColumnTransformer` object that applies each pipeline to the correct subset of features.\n",
    "\n",
    "This slightly complicated but powerful set of tools enables you to build virtually any pre-processing pipeline you can think of."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7834ebf3",
   "metadata": {},
   "source": [
    "**Warning**: since some transformers need to look at the data's statistics, it is important to use their `fit` method on *training data only* !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41818c2e",
   "metadata": {},
   "source": [
    "#### Handling categorical input features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2daadce",
   "metadata": {},
   "source": [
    "Similar to how we encoded target class labels, we also want to use a proper encoding for **categorical input features**: these are originally string values that cannot be understood as-is by AI models. They need to be converted to numbers first.\n",
    "\n",
    "In a lot of cases, categorical variables (\"Blue\", \"Red\", \"Green\") have no order, therefore a practical way of representing them is through **one-hot encoding**: we create a binary variable for each possible category, and set all values to zero except for the correct categories: \"Blue\" becomes (1, 0, 0), \"Red\" becomes (0, 1, 0), \"Green\" becomes (0, 0, 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a286d9",
   "metadata": {},
   "source": [
    "Scikit-learn provides a `OneHotEncoder` class that can be fitted to our data to convert categorical string data to binary numbers. In this notebook, there are no categorical input variables, but we still write a code to handle them in case the data changes at some point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "babe3c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical features: 0\n"
     ]
    }
   ],
   "source": [
    "# Handling categorical input variables (one-hot feature encoding):\n",
    "\n",
    "# There are no categorical variables in this dataset, so this part does nothing\n",
    "categorical_features = training_inputs_df.select(pl.col(pl.Utf8)).columns\n",
    "print(f\"Number of categorical features: {len(categorical_features)}\")\n",
    "categorical_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"onehot\", OneHotEncoder()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8ba12c",
   "metadata": {},
   "source": [
    "#### Handling numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ceb48c",
   "metadata": {},
   "source": [
    "Most machine learning models don't perform well on numerical features that have different scales. To prevent problems, it is a good practice to apply feature scaling methods such as *min-max scaling* and *standardization* (also known as *Z-Score normalization*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4bd530",
   "metadata": {},
   "source": [
    "Here, we'll go for the latter. Scikit-learn provides a `StandardScaler` class that can learn each of our numerical features' mean and variance and be used later to normalize them. Similarly, there is a `MinMaxScaler` class that exists for the other scaling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebac40f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numerical features: 107\n"
     ]
    }
   ],
   "source": [
    "# Handling numerical input variables (feature scaling):\n",
    "\n",
    "numerical_features = training_inputs_df.select(pl.col(pl.Float64)).columns\n",
    "print(f\"Number of numerical features: {len(numerical_features)}\")\n",
    "numerical_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8196553b",
   "metadata": {},
   "source": [
    "#### Defining a complete pre-processing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d7f694",
   "metadata": {},
   "source": [
    "Once all necessary transformations are defined and wrapped in their respective `Pipeline` objects, we wrap everything in a `ColumnTransformer` that will apply each transformation to the appropriate subset of features. Once that's done, we can fit this big pipeline to our training data and apply the transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "929f417f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(X_train) = <class 'numpy.ndarray'>, X_train.shape = (294, 107)\n"
     ]
    }
   ],
   "source": [
    "# Combine preprocessing for numerical and categorical features:\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_pipeline, numerical_features),\n",
    "        (\"cat\", categorical_pipeline, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train = preprocessor.fit_transform(training_inputs_df)\n",
    "print(f\"{type(X_train) = }, {X_train.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962ee4b7",
   "metadata": {},
   "source": [
    "Let's look at one feature distribution before and after pre-processing and see that the mean is now zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57749e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-cade8dee7491403bbfbd9aa2862b7d19.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-cade8dee7491403bbfbd9aa2862b7d19.vega-embed details,\n",
       "  #altair-viz-cade8dee7491403bbfbd9aa2862b7d19.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-cade8dee7491403bbfbd9aa2862b7d19\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-cade8dee7491403bbfbd9aa2862b7d19\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-cade8dee7491403bbfbd9aa2862b7d19\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-d36083baf6aa0863de475d3abc668130\"}, \"mark\": {\"type\": \"bar\", \"tooltip\": true}, \"encoding\": {\"x\": {\"bin\": true, \"field\": \"shape_Elongation\", \"type\": \"quantitative\"}, \"y\": {\"aggregate\": \"count\", \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"param_1\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-d36083baf6aa0863de475d3abc668130\": [{\"shape_Elongation\": 0.881837783555764}, {\"shape_Elongation\": 0.8806613902998159}, {\"shape_Elongation\": 0.5869907604495888}, {\"shape_Elongation\": 0.7196367612787553}, {\"shape_Elongation\": 0.7542247051706336}, {\"shape_Elongation\": 0.7937968041951489}, {\"shape_Elongation\": 0.6973740136913338}, {\"shape_Elongation\": 0.9355998957006624}, {\"shape_Elongation\": 0.8844004302129791}, {\"shape_Elongation\": 0.7393147712507019}, {\"shape_Elongation\": 0.5402751483745071}, {\"shape_Elongation\": 0.8444572916279666}, {\"shape_Elongation\": 0.8800615904315857}, {\"shape_Elongation\": 0.8324823946306883}, {\"shape_Elongation\": 0.5453090350025663}, {\"shape_Elongation\": 0.5660493491862587}, {\"shape_Elongation\": 0.7792886767717686}, {\"shape_Elongation\": 0.6121584896056944}, {\"shape_Elongation\": 0.644567708690273}, {\"shape_Elongation\": 0.7123975767522577}, {\"shape_Elongation\": 0.8330047986592265}, {\"shape_Elongation\": 0.4306502770201536}, {\"shape_Elongation\": 0.7456063616254065}, {\"shape_Elongation\": 0.6364633128027789}, {\"shape_Elongation\": 0.6477835184368431}, {\"shape_Elongation\": 0.8708246251266828}, {\"shape_Elongation\": 0.6048876409288843}, {\"shape_Elongation\": 0.6976819625789594}, {\"shape_Elongation\": 0.8396383303655445}, {\"shape_Elongation\": 0.5555056623751816}, {\"shape_Elongation\": 0.780405960269327}, {\"shape_Elongation\": 0.5492303083772235}, {\"shape_Elongation\": 0.7191600106391254}, {\"shape_Elongation\": 0.7281443206571913}, {\"shape_Elongation\": 0.2224975823301929}, {\"shape_Elongation\": 0.8734987729082657}, {\"shape_Elongation\": 0.6712758651483043}, {\"shape_Elongation\": 0.8871393638736774}, {\"shape_Elongation\": 0.3772206269962161}, {\"shape_Elongation\": 0.829356481488418}, {\"shape_Elongation\": 0.9282155540096664}, {\"shape_Elongation\": 0.8017422115900514}, {\"shape_Elongation\": 0.6883997848415926}, {\"shape_Elongation\": 0.5471649227795186}, {\"shape_Elongation\": 0.8250597262835374}, {\"shape_Elongation\": 0.2828832568027544}, {\"shape_Elongation\": 0.7639109556431466}, {\"shape_Elongation\": 0.8837549827479186}, {\"shape_Elongation\": 0.7408102054161212}, {\"shape_Elongation\": 0.8046089801457428}, {\"shape_Elongation\": 0.3935856350464809}, {\"shape_Elongation\": 0.4181380288368765}, {\"shape_Elongation\": 0.612029676607651}, {\"shape_Elongation\": 0.8342650778827113}, {\"shape_Elongation\": 0.725783622930287}, {\"shape_Elongation\": 0.4883217476939661}, {\"shape_Elongation\": 0.6086069710554626}, {\"shape_Elongation\": 0.2545581951304055}, {\"shape_Elongation\": 0.8999348479142685}, {\"shape_Elongation\": 0.902821139527775}, {\"shape_Elongation\": 0.8604321846124915}, {\"shape_Elongation\": 0.8038670745446767}, {\"shape_Elongation\": 0.8282424593702484}, {\"shape_Elongation\": 0.757725043459743}, {\"shape_Elongation\": 0.8055513835814794}, {\"shape_Elongation\": 0.6201079390243082}, {\"shape_Elongation\": 0.8926929286133561}, {\"shape_Elongation\": 0.8536566732405108}, {\"shape_Elongation\": 0.6569343253849869}, {\"shape_Elongation\": 0.8718920499511426}, {\"shape_Elongation\": 0.8668561109952235}, {\"shape_Elongation\": 0.5510317335514223}, {\"shape_Elongation\": 0.8012890209983241}, {\"shape_Elongation\": 0.8087390322911397}, {\"shape_Elongation\": 0.9660631525323566}, {\"shape_Elongation\": 0.8127651102731637}, {\"shape_Elongation\": 0.7683724678300983}, {\"shape_Elongation\": 0.8704789171967657}, {\"shape_Elongation\": 0.8268722759357687}, {\"shape_Elongation\": 0.8898982189759186}, {\"shape_Elongation\": 0.9220070153180806}, {\"shape_Elongation\": 0.7363234759339982}, {\"shape_Elongation\": 0.7128085829987428}, {\"shape_Elongation\": 0.6623126602755992}, {\"shape_Elongation\": 0.984176779420159}, {\"shape_Elongation\": 0.8273322269545608}, {\"shape_Elongation\": 0.7596336269628606}, {\"shape_Elongation\": 0.626749127126722}, {\"shape_Elongation\": 0.6078556548339429}, {\"shape_Elongation\": 0.5492968488274075}, {\"shape_Elongation\": 0.5299297284369422}, {\"shape_Elongation\": 0.5892309863119122}, {\"shape_Elongation\": 0.8051414727877837}, {\"shape_Elongation\": 0.8438870151652159}, {\"shape_Elongation\": 0.4052919411279712}, {\"shape_Elongation\": 0.4692598505328043}, {\"shape_Elongation\": 0.7907393682116409}, {\"shape_Elongation\": 0.8908306897247898}, {\"shape_Elongation\": 0.6631669232080514}, {\"shape_Elongation\": 0.6473462951267056}, {\"shape_Elongation\": 0.9061958302653312}, {\"shape_Elongation\": 0.3205142609386198}, {\"shape_Elongation\": 0.8805630989287804}, {\"shape_Elongation\": 0.3568049552667189}, {\"shape_Elongation\": 0.8540428940483642}, {\"shape_Elongation\": 0.699388898181262}, {\"shape_Elongation\": 0.2614605557878571}, {\"shape_Elongation\": 0.80342949561891}, {\"shape_Elongation\": 0.5329571072046094}, {\"shape_Elongation\": 0.5503797287733687}, {\"shape_Elongation\": 0.8169791290026692}, {\"shape_Elongation\": 0.916947888536499}, {\"shape_Elongation\": 0.742091209591504}, {\"shape_Elongation\": 0.9350061210525036}, {\"shape_Elongation\": 0.2503391880661045}, {\"shape_Elongation\": 0.8889931812251508}, {\"shape_Elongation\": 0.8320523269605771}, {\"shape_Elongation\": 0.5906322369535895}, {\"shape_Elongation\": 0.8959991603766461}, {\"shape_Elongation\": 0.9179499351946784}, {\"shape_Elongation\": 0.3456512803966546}, {\"shape_Elongation\": 0.5370474204618896}, {\"shape_Elongation\": 0.6561987709393482}, {\"shape_Elongation\": 0.7921656297083046}, {\"shape_Elongation\": 0.7087593227477021}, {\"shape_Elongation\": 0.5507847506145221}, {\"shape_Elongation\": 0.5171083683569021}, {\"shape_Elongation\": 0.7456591313800806}, {\"shape_Elongation\": 0.5740073641546587}, {\"shape_Elongation\": 0.6410503536159741}, {\"shape_Elongation\": 0.6461735263371358}, {\"shape_Elongation\": 0.9182609386928692}, {\"shape_Elongation\": 0.8787767026706522}, {\"shape_Elongation\": 0.7510938129277441}, {\"shape_Elongation\": 0.750070926944449}, {\"shape_Elongation\": 0.8808691736769337}, {\"shape_Elongation\": 0.7318294022132728}, {\"shape_Elongation\": 0.8530344205390946}, {\"shape_Elongation\": 0.7990538997668666}, {\"shape_Elongation\": 0.727318182675756}, {\"shape_Elongation\": 0.730071016470459}, {\"shape_Elongation\": 0.7606894830713818}, {\"shape_Elongation\": 0.7261159300201432}, {\"shape_Elongation\": 0.6744832850980027}, {\"shape_Elongation\": 0.8492188074936814}, {\"shape_Elongation\": 0.7680044283729054}, {\"shape_Elongation\": 0.794280574127227}, {\"shape_Elongation\": 0.8567486551275992}, {\"shape_Elongation\": 0.5953137150026709}, {\"shape_Elongation\": 0.7171306843307763}, {\"shape_Elongation\": 0.7382234643192925}, {\"shape_Elongation\": 0.6633073788790518}, {\"shape_Elongation\": 0.6805963218022485}, {\"shape_Elongation\": 0.7742922944387782}, {\"shape_Elongation\": 0.7563908175691489}, {\"shape_Elongation\": 0.5373028545487839}, {\"shape_Elongation\": 0.8789742446719768}, {\"shape_Elongation\": 0.7454716577950956}, {\"shape_Elongation\": 0.5310774113538386}, {\"shape_Elongation\": 0.8593773927727184}, {\"shape_Elongation\": 0.6759101480273696}, {\"shape_Elongation\": 0.7270836151162758}, {\"shape_Elongation\": 0.8731288708740391}, {\"shape_Elongation\": 0.8165423313839408}, {\"shape_Elongation\": 0.6006026919424912}, {\"shape_Elongation\": 0.70840589150041}, {\"shape_Elongation\": 0.6274311674461207}, {\"shape_Elongation\": 0.8739222087269443}, {\"shape_Elongation\": 0.7886327231497514}, {\"shape_Elongation\": 0.7333825825813226}, {\"shape_Elongation\": 0.9467395385874948}, {\"shape_Elongation\": 0.6878489382516565}, {\"shape_Elongation\": 0.5806831151048759}, {\"shape_Elongation\": 0.6897914815105209}, {\"shape_Elongation\": 0.6943811234508904}, {\"shape_Elongation\": 0.4849348829634273}, {\"shape_Elongation\": 0.9580510247543472}, {\"shape_Elongation\": 0.9632465775866866}, {\"shape_Elongation\": 0.7705221899156937}, {\"shape_Elongation\": 0.7394888935361913}, {\"shape_Elongation\": 0.4800131286125347}, {\"shape_Elongation\": 0.8662097424473064}, {\"shape_Elongation\": 0.7480175042124968}, {\"shape_Elongation\": 0.9169055398466196}, {\"shape_Elongation\": 0.8842983152192249}, {\"shape_Elongation\": 0.6932687337382145}, {\"shape_Elongation\": 0.8076208538448995}, {\"shape_Elongation\": 0.4054844939714093}, {\"shape_Elongation\": 0.4207885665452728}, {\"shape_Elongation\": 0.7558045213930945}, {\"shape_Elongation\": 0.7202880385168599}, {\"shape_Elongation\": 0.7228524613617275}, {\"shape_Elongation\": 0.853559715582559}, {\"shape_Elongation\": 0.6344670270513885}, {\"shape_Elongation\": 0.4707356156608409}, {\"shape_Elongation\": 0.6159244981937869}, {\"shape_Elongation\": 0.9147134450829124}, {\"shape_Elongation\": 0.8617390901355723}, {\"shape_Elongation\": 0.8413070229726414}, {\"shape_Elongation\": 0.7883167342456618}, {\"shape_Elongation\": 0.934135544733488}, {\"shape_Elongation\": 0.8198986909670758}, {\"shape_Elongation\": 0.5794306455763734}, {\"shape_Elongation\": 0.747756505654911}, {\"shape_Elongation\": 0.9430278870716252}, {\"shape_Elongation\": 0.7303951498370722}, {\"shape_Elongation\": 0.7034846042633596}, {\"shape_Elongation\": 0.7894114566701966}, {\"shape_Elongation\": 0.6282875863207688}, {\"shape_Elongation\": 0.8493705945161304}, {\"shape_Elongation\": 0.4324990747164314}, {\"shape_Elongation\": 0.7192009048142834}, {\"shape_Elongation\": 0.6324380786418368}, {\"shape_Elongation\": 0.3427473726296172}, {\"shape_Elongation\": 0.6265712294139628}, {\"shape_Elongation\": 0.4929374086905045}, {\"shape_Elongation\": 0.7021763612720763}, {\"shape_Elongation\": 0.6489348317935557}, {\"shape_Elongation\": 0.6431941213138064}, {\"shape_Elongation\": 0.739544927883696}, {\"shape_Elongation\": 0.704765829045325}, {\"shape_Elongation\": 0.7512943812807592}, {\"shape_Elongation\": 0.7070463837051796}, {\"shape_Elongation\": 0.726013690328234}, {\"shape_Elongation\": 0.8909876095026805}, {\"shape_Elongation\": 0.7762225471737592}, {\"shape_Elongation\": 0.6579938709567186}, {\"shape_Elongation\": 0.8208445478063242}, {\"shape_Elongation\": 0.8546412436709138}, {\"shape_Elongation\": 0.8118515367456458}, {\"shape_Elongation\": 0.645445018801302}, {\"shape_Elongation\": 0.8343015080914497}, {\"shape_Elongation\": 0.9246719351470568}, {\"shape_Elongation\": 0.569215364120855}, {\"shape_Elongation\": 0.8486140605540229}, {\"shape_Elongation\": 0.6651250927447889}, {\"shape_Elongation\": 0.8086339435845209}, {\"shape_Elongation\": 0.8240359823389349}, {\"shape_Elongation\": 0.8365524053916737}, {\"shape_Elongation\": 0.9010504862555436}, {\"shape_Elongation\": 0.7763963142549949}, {\"shape_Elongation\": 0.8664768216277147}, {\"shape_Elongation\": 0.5186926960559509}, {\"shape_Elongation\": 0.7740339771845458}, {\"shape_Elongation\": 0.6007327533597258}, {\"shape_Elongation\": 0.5878812188400308}, {\"shape_Elongation\": 0.8682148742612583}, {\"shape_Elongation\": 0.5714924873737244}, {\"shape_Elongation\": 0.7450435495432195}, {\"shape_Elongation\": 0.6461968651216959}, {\"shape_Elongation\": 0.9451504125976256}, {\"shape_Elongation\": 0.8384639717852981}, {\"shape_Elongation\": 0.7702031973497082}, {\"shape_Elongation\": 0.4700544393382458}, {\"shape_Elongation\": 0.729992848299595}, {\"shape_Elongation\": 0.5997380591268343}, {\"shape_Elongation\": 0.9175335049761394}, {\"shape_Elongation\": 0.7206347436497064}, {\"shape_Elongation\": 0.304373745891748}, {\"shape_Elongation\": 0.3263366775197226}, {\"shape_Elongation\": 0.8710537436344298}, {\"shape_Elongation\": 0.6340727671504491}, {\"shape_Elongation\": 0.8792558567537156}, {\"shape_Elongation\": 0.7312161139567237}, {\"shape_Elongation\": 0.8131545127312378}, {\"shape_Elongation\": 0.6756745281274947}, {\"shape_Elongation\": 0.5405335723478782}, {\"shape_Elongation\": 0.8232930540244885}, {\"shape_Elongation\": 0.736524603642708}, {\"shape_Elongation\": 0.6560369626421848}, {\"shape_Elongation\": 0.9416830811948684}, {\"shape_Elongation\": 0.7031462773448296}, {\"shape_Elongation\": 0.8631920701692956}, {\"shape_Elongation\": 0.727380087042932}, {\"shape_Elongation\": 0.656230373680076}, {\"shape_Elongation\": 0.7362227470156918}, {\"shape_Elongation\": 0.7056400643625397}, {\"shape_Elongation\": 0.7576637482268632}, {\"shape_Elongation\": 0.9334375193057862}, {\"shape_Elongation\": 0.733626485626721}, {\"shape_Elongation\": 0.8828377630870489}, {\"shape_Elongation\": 0.8477190589346183}, {\"shape_Elongation\": 0.6606412709276807}, {\"shape_Elongation\": 0.7466723921800149}, {\"shape_Elongation\": 0.7876113168265544}, {\"shape_Elongation\": 0.8418300929281762}, {\"shape_Elongation\": 0.92921818052429}, {\"shape_Elongation\": 0.8156483290080643}, {\"shape_Elongation\": 0.5980767782102054}, {\"shape_Elongation\": 0.8092672245775526}, {\"shape_Elongation\": 0.7777136992854954}, {\"shape_Elongation\": 0.8612879685665715}, {\"shape_Elongation\": 0.7399696025126145}, {\"shape_Elongation\": 0.6328062669050236}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After preprocessing:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-ea29d653b8764875b25e34a410628e79.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-ea29d653b8764875b25e34a410628e79.vega-embed details,\n",
       "  #altair-viz-ea29d653b8764875b25e34a410628e79.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-ea29d653b8764875b25e34a410628e79\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-ea29d653b8764875b25e34a410628e79\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-ea29d653b8764875b25e34a410628e79\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-b0398631462e88d5b98699bd7efde64b\"}, \"mark\": {\"type\": \"bar\", \"tooltip\": true}, \"encoding\": {\"x\": {\"bin\": true, \"field\": \"shape_Elongation\", \"type\": \"quantitative\"}, \"y\": {\"aggregate\": \"count\", \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"param_2\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-b0398631462e88d5b98699bd7efde64b\": [{\"shape_Elongation\": 1.0300718284260384}, {\"shape_Elongation\": 1.0224197924740324}, {\"shape_Elongation\": -0.8878072564315731}, {\"shape_Elongation\": -0.024990369219338605}, {\"shape_Elongation\": 0.1999923810883498}, {\"shape_Elongation\": 0.45739535658219554}, {\"shape_Elongation\": -0.16980193122722292}, {\"shape_Elongation\": 1.3797759880754306}, {\"shape_Elongation\": 1.0467409688296816}, {\"shape_Elongation\": 0.10300835825374004}, {\"shape_Elongation\": -1.1916763421399863}, {\"shape_Elongation\": 0.7869245078434755}, {\"shape_Elongation\": 1.0185182993870059}, {\"shape_Elongation\": 0.7090318967787406}, {\"shape_Elongation\": -1.1589326305779988}, {\"shape_Elongation\": -1.0240239773814044}, {\"shape_Elongation\": 0.3630249476405718}, {\"shape_Elongation\": -0.7240997824562484}, {\"shape_Elongation\": -0.5132888921712936}, {\"shape_Elongation\": -0.07207878967727566}, {\"shape_Elongation\": 0.7124299563881741}, {\"shape_Elongation\": -1.9047486524376898}, {\"shape_Elongation\": 0.14393300271179943}, {\"shape_Elongation\": -0.5660052167394879}, {\"shape_Elongation\": -0.4923711491706898}, {\"shape_Elongation\": 0.9584349979542851}, {\"shape_Elongation\": -0.7713941673868276}, {\"shape_Elongation\": -0.1677988289928493}, {\"shape_Elongation\": 0.7555788123076239}, {\"shape_Elongation\": -1.0926070554780483}, {\"shape_Elongation\": 0.3702924948223254}, {\"shape_Elongation\": -1.133426087856162}, {\"shape_Elongation\": -0.028091469141617528}, {\"shape_Elongation\": 0.030348396026430607}, {\"shape_Elongation\": -3.258710769460219}, {\"shape_Elongation\": 0.9758294150526372}, {\"shape_Elongation\": -0.33956146522855196}, {\"shape_Elongation\": 1.06455679592309}, {\"shape_Elongation\": -2.252290259650293}, {\"shape_Elongation\": 0.6886989004558208}, {\"shape_Elongation\": 1.3317433698878511}, {\"shape_Elongation\": 0.5090775153600688}, {\"shape_Elongation\": -0.22817622184180547}, {\"shape_Elongation\": -1.146860715068179}, {\"shape_Elongation\": 0.6607499767957501}, {\"shape_Elongation\": -2.8659226012912584}, {\"shape_Elongation\": 0.2629981289375837}, {\"shape_Elongation\": 1.042542553730988}, {\"shape_Elongation\": 0.11273564625015434}, {\"shape_Elongation\": 0.527724864742016}, {\"shape_Elongation\": -2.145841477049469}, {\"shape_Elongation\": -1.9861365492610992}, {\"shape_Elongation\": -0.7249376669707426}, {\"shape_Elongation\": 0.7206276418805988}, {\"shape_Elongation\": 0.014992864373427452}, {\"shape_Elongation\": -1.529615452064647}, {\"shape_Elongation\": -0.7472011964546549}, {\"shape_Elongation\": -3.0501674438757385}, {\"shape_Elongation\": 1.147787045167431}, {\"shape_Elongation\": 1.1665613853660455}, {\"shape_Elongation\": 0.8908357253117494}, {\"shape_Elongation\": 0.5228990224451072}, {\"shape_Elongation\": 0.6814525674320112}, {\"shape_Elongation\": 0.2227608849853413}, {\"shape_Elongation\": 0.5338548769085161}, {\"shape_Elongation\": -0.6723913316959955}, {\"shape_Elongation\": 1.1006808359368738}, {\"shape_Elongation\": 0.8467633402062794}, {\"shape_Elongation\": -0.4328482783934097}, {\"shape_Elongation\": 0.9653782315129024}, {\"shape_Elongation\": 0.932621170259824}, {\"shape_Elongation\": -1.121708432957921}, {\"shape_Elongation\": 0.5061296654948352}, {\"shape_Elongation\": 0.5545894419915404}, {\"shape_Elongation\": 1.5779290591787234}, {\"shape_Elongation\": 0.580777702854357}, {\"shape_Elongation\": 0.29201874043994464}, {\"shape_Elongation\": 0.95618628605863}, {\"shape_Elongation\": 0.6725399926204261}, {\"shape_Elongation\": 1.0825022051831172}, {\"shape_Elongation\": 1.291358948235292}, {\"shape_Elongation\": 0.08355100486383416}, {\"shape_Elongation\": -0.06940533455612335}, {\"shape_Elongation\": -0.39786404864132263}, {\"shape_Elongation\": 1.6957520095109055}, {\"shape_Elongation\": 0.6755318167525033}, {\"shape_Elongation\": 0.23517556817858293}, {\"shape_Elongation\": -0.6291926735374624}, {\"shape_Elongation\": -0.7520882516203703}, {\"shape_Elongation\": -1.1329932649761465}, {\"shape_Elongation\": -1.2589697620066664}, {\"shape_Elongation\": -0.8732353530715041}, {\"shape_Elongation\": 0.5311885473332528}, {\"shape_Elongation\": 0.7832150544158172}, {\"shape_Elongation\": -2.0696959580677605}, {\"shape_Elongation\": -1.653606576336348}, {\"shape_Elongation\": 0.4375077807664839}, {\"shape_Elongation\": 1.0885676086172829}, {\"shape_Elongation\": -0.39230736031576624}, {\"shape_Elongation\": -0.4952151373279757}, {\"shape_Elongation\": 1.1885125948957789}, {\"shape_Elongation\": -2.6211457844387533}, {\"shape_Elongation\": 1.0217804407086826}, {\"shape_Elongation\": -2.385087224669071}, {\"shape_Elongation\": 0.8492755745226225}, {\"shape_Elongation\": -0.1566957964562917}, {\"shape_Elongation\": -3.0052699475347175}, {\"shape_Elongation\": 0.5200527211297292}, {\"shape_Elongation\": -1.2392776981042264}, {\"shape_Elongation\": -1.125949501135862}, {\"shape_Elongation\": 0.6081884540275394}, {\"shape_Elongation\": 1.2584510581035868}, {\"shape_Elongation\": 0.12106814046935907}, {\"shape_Elongation\": 1.3759136869851043}, {\"shape_Elongation\": -3.077610642461385}, {\"shape_Elongation\": 1.0766152440229937}, {\"shape_Elongation\": 0.7062344536135005}, {\"shape_Elongation\": -0.8641206966981603}, {\"shape_Elongation\": 1.122186743243329}, {\"shape_Elongation\": 1.2649690290416271}, {\"shape_Elongation\": -2.457638066550541}, {\"shape_Elongation\": -1.2126716087362206}, {\"shape_Elongation\": -0.43763280859555603}, {\"shape_Elongation\": 0.4467851242009604}, {\"shape_Elongation\": -0.09574438815348546}, {\"shape_Elongation\": -1.1233149725254816}, {\"shape_Elongation\": -1.3423683260412855}, {\"shape_Elongation\": 0.14427625192536192}, {\"shape_Elongation\": -0.9722598106481283}, {\"shape_Elongation\": -0.5361680844383512}, {\"shape_Elongation\": -0.5028435973653009}, {\"shape_Elongation\": 1.2669920004734359}, {\"shape_Elongation\": 1.0101605437714898}, {\"shape_Elongation\": 0.17962699741812613}, {\"shape_Elongation\": 0.17297347379462552}, {\"shape_Elongation\": 1.023771352306508}, {\"shape_Elongation\": 0.05431859171620766}, {\"shape_Elongation\": 0.8427157991154121}, {\"shape_Elongation\": 0.4915909660134098}, {\"shape_Elongation\": 0.024974650892057543}, {\"shape_Elongation\": 0.0428808936050761}, {\"shape_Elongation\": 0.24204355119505983}, {\"shape_Elongation\": 0.01715440838588174}, {\"shape_Elongation\": -0.31869829498834745}, {\"shape_Elongation\": 0.8178965407128177}, {\"shape_Elongation\": 0.2896247695939226}, {\"shape_Elongation\": 0.46054211460213823}, {\"shape_Elongation\": 0.866875625314446}, {\"shape_Elongation\": -0.833669282463192}, {\"shape_Elongation\": -0.04129154300409794}, {\"shape_Elongation\": 0.09590977975408042}, {\"shape_Elongation\": -0.3913937441940111}, {\"shape_Elongation\": -0.27893508111381554}, {\"shape_Elongation\": 0.33052518869627456}, {\"shape_Elongation\": 0.21408220170379288}, {\"shape_Elongation\": -1.211010097327174}, {\"shape_Elongation\": 1.0114454869556877}, {\"shape_Elongation\": 0.1430568003473264}, {\"shape_Elongation\": -1.2515044769948815}, {\"shape_Elongation\": 0.8839746649996335}, {\"shape_Elongation\": -0.30941703943975074}, {\"shape_Elongation\": 0.023448869110122887}, {\"shape_Elongation\": 0.9734233287797769}, {\"shape_Elongation\": 0.6053472348473372}, {\"shape_Elongation\": -0.7992662956318729}, {\"shape_Elongation\": -0.09804333758826628}, {\"shape_Elongation\": -0.6247562344314339}, {\"shape_Elongation\": 0.9785837202915634}, {\"shape_Elongation\": 0.42380477484547263}, {\"shape_Elongation\": 0.06442149901882467}, {\"shape_Elongation\": 1.4522355567031435}, {\"shape_Elongation\": -0.23175929058936798}, {\"shape_Elongation\": -0.9288363329807637}, {\"shape_Elongation\": -0.2191237107949412}, {\"shape_Elongation\": -0.1892696590507926}, {\"shape_Elongation\": -1.5516458492567637}, {\"shape_Elongation\": 1.5258129071186854}, {\"shape_Elongation\": 1.559608202070089}, {\"shape_Elongation\": 0.30600194767326033}, {\"shape_Elongation\": 0.1041409641930155}, {\"shape_Elongation\": -1.5836601786908606}, {\"shape_Elongation\": 0.928416763832042}, {\"shape_Elongation\": 0.15961666093454072}, {\"shape_Elongation\": 1.2581755943538255}, {\"shape_Elongation\": 1.046076745705743}, {\"shape_Elongation\": -0.19650537383494235}, {\"shape_Elongation\": 0.5473160734745702}, {\"shape_Elongation\": -2.068443467649952}, {\"shape_Elongation\": -1.9688957076171627}, {\"shape_Elongation\": 0.2102685455178124}, {\"shape_Elongation\": -0.02075403344003946}, {\"shape_Elongation\": -0.004073339542947905}, {\"shape_Elongation\": 0.8461326637885785}, {\"shape_Elongation\": -0.5789903730746504}, {\"shape_Elongation\": -1.6440072287037815}, {\"shape_Elongation\": -0.6996031840900651}, {\"shape_Elongation\": 1.2439167673354976}, {\"shape_Elongation\": 0.8993366989427394}, {\"shape_Elongation\": 0.7664330872346433}, {\"shape_Elongation\": 0.4217493750526715}, {\"shape_Elongation\": 1.3702508856570712}, {\"shape_Elongation\": 0.6271792064845002}, {\"shape_Elongation\": -0.9369832190772583}, {\"shape_Elongation\": 0.15791895454599258}, {\"shape_Elongation\": 1.4280925325085159}, {\"shape_Elongation\": 0.044989270342215684}, {\"shape_Elongation\": -0.1300546286065138}, {\"shape_Elongation\": 0.4288701701674448}, {\"shape_Elongation\": -0.6191855224389533}, {\"shape_Elongation\": 0.8188838634018547}, {\"shape_Elongation\": -1.8927228554787452}, {\"shape_Elongation\": -0.027825466512858003}, {\"shape_Elongation\": -0.5921879888346476}, {\"shape_Elongation\": -2.4765269938053738}, {\"shape_Elongation\": -0.6303498373404086}, {\"shape_Elongation\": -1.4995921552553508}, {\"shape_Elongation\": -0.138564302010916}, {\"shape_Elongation\": -0.4848822493890524}, {\"shape_Elongation\": -0.5222236084617856}, {\"shape_Elongation\": 0.10450544846686269}, {\"shape_Elongation\": -0.12172069941690838}, {\"shape_Elongation\": 0.1809316259854406}, {\"shape_Elongation\": -0.10688647101625541}, {\"shape_Elongation\": 0.016489374143076357}, {\"shape_Elongation\": 1.0895883181257138}, {\"shape_Elongation\": 0.34308082283464614}, {\"shape_Elongation\": -0.42595629668007906}, {\"shape_Elongation\": 0.6333316818602167}, {\"shape_Elongation\": 0.8531676342572971}, {\"shape_Elongation\": 0.5748352193846319}, {\"shape_Elongation\": -0.5075822898283197}, {\"shape_Elongation\": 0.7208646079339107}, {\"shape_Elongation\": 1.308693340656732}, {\"shape_Elongation\": -1.0034301326091524}, {\"shape_Elongation\": 0.8139628686174238}, {\"shape_Elongation\": -0.3795701369259886}, {\"shape_Elongation\": 0.5539058758820516}, {\"shape_Elongation\": 0.6540908724272597}, {\"shape_Elongation\": 0.7355059253492394}, {\"shape_Elongation\": 1.155043891169998}, {\"shape_Elongation\": 0.34421111829168644}, {\"shape_Elongation\": 0.9301540225932452}, {\"shape_Elongation\": -1.3320628159989742}, {\"shape_Elongation\": 0.3288449232693728}, {\"shape_Elongation\": -0.7984202905773421}, {\"shape_Elongation\": -0.8820151290260687}, {\"shape_Elongation\": 0.9414594607799306}, {\"shape_Elongation\": -0.9886182243378304}, {\"shape_Elongation\": 0.1402721025278321}, {\"shape_Elongation\": -0.502691786550654}, {\"shape_Elongation\": 1.4418988354194546}, {\"shape_Elongation\": 0.7479400112254553}, {\"shape_Elongation\": 0.30392701008669964}, {\"shape_Elongation\": -1.6484380478059801}, {\"shape_Elongation\": 0.04237243637724876}, {\"shape_Elongation\": -0.8048904365024853}, {\"shape_Elongation\": 1.262260292836578}, {\"shape_Elongation\": -0.018498835080245735}, {\"shape_Elongation\": -2.7261343168007635}, {\"shape_Elongation\": -2.5832729551098845}, {\"shape_Elongation\": 0.9599253355175831}, {\"shape_Elongation\": -0.5815548989431626}, {\"shape_Elongation\": 1.0132772772716294}, {\"shape_Elongation\": 0.050329361274492626}, {\"shape_Elongation\": 0.5833106327176633}, {\"shape_Elongation\": -0.3109496663361855}, {\"shape_Elongation\": -1.1899953825415714}, {\"shape_Elongation\": 0.6492583777294507}, {\"shape_Elongation\": 0.08485927184871406}, {\"shape_Elongation\": -0.43868531625059975}, {\"shape_Elongation\": 1.419345030033998}, {\"shape_Elongation\": -0.1322553295464697}, {\"shape_Elongation\": 0.908787837326423}, {\"shape_Elongation\": 0.025377317637061338}, {\"shape_Elongation\": -0.43742724357126833}, {\"shape_Elongation\": 0.08289579768682105}, {\"shape_Elongation\": -0.1160340975565055}, {\"shape_Elongation\": 0.22236218045068745}, {\"shape_Elongation\": 1.3657104688864192}, {\"shape_Elongation\": 0.0660080049450999}, {\"shape_Elongation\": 1.0365763534103258}, {\"shape_Elongation\": 0.8081411890607283}, {\"shape_Elongation\": -0.40873586494544206}, {\"shape_Elongation\": 0.15086716702169783}, {\"shape_Elongation\": 0.41716087590505335}, {\"shape_Elongation\": 0.769835478471527}, {\"shape_Elongation\": 1.338265112593823}, {\"shape_Elongation\": 0.5995320550281764}, {\"shape_Elongation\": -0.8156965009168723}, {\"shape_Elongation\": 0.5580251522395954}, {\"shape_Elongation\": 0.35278025753577363}, {\"shape_Elongation\": 0.8964023073629978}, {\"shape_Elongation\": 0.10726781174288307}, {\"shape_Elongation\": -0.5897930500565076}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the preprocessed data back to a DataFrame for easier visualization\n",
    "feature_names = preprocessor.get_feature_names_out().tolist()\n",
    "simple_feature_names = [re.sub(r\"^.*?__\", \"\", name) for name in feature_names]\n",
    "X_train_df = pl.DataFrame(X_train, schema=simple_feature_names)\n",
    "\n",
    "# Look at some preprocessed input features distributions:\n",
    "max_features_to_plot = 1\n",
    "print(\"Before preprocessing:\")\n",
    "for feature in training_inputs_df.columns[:max_features_to_plot]:\n",
    "    training_inputs_df[feature].plot.hist().show()\n",
    "print(\"After preprocessing:\")\n",
    "for feature in X_train_df.columns[:max_features_to_plot]:\n",
    "    X_train_df[feature].plot.hist().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db25099d",
   "metadata": {},
   "source": [
    "## Cross-validating a few models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e7f727",
   "metadata": {},
   "source": [
    "Now that our data is correctly pre-processed, we can finally train our some models. Since our dataset is small, we can test multiple models in a reasonable amount of time and we can use cross-validation instead of using a regular train/validation split. What does this mean?\n",
    "\n",
    "In a normal train/validation split, we separate part of the data for validation to estimate how well the model will generalize to unseen data. This helps detect [overfitting](https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html), where a model performs well on training data but poorly on new data. However, a single split can give misleading results if the partition is unbalanced or too small. Cross-validation addresses this by training and evaluating the model multiple times on different folds of the data, ensuring every sample is used for validation once. This provides a more robust and reliable estimate of the model’s true performance while still guarding against overfitting. At the end, we obtain multiple values for our performance metric and typically look at their average.\n",
    "\n",
    "Once cross-validation is complete and a model is selected, we retrain it on the entire training data (both train and validation). Finally, we evaluate it on the test set that was set aside at the beginning and never used during training or model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94d8f5a",
   "metadata": {},
   "source": [
    "#### List classification models that we want to compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8463794",
   "metadata": {},
   "source": [
    "Here we instantiate some classification models we'd like to try on our training data. This list was essentially taken from scikit-learn documentation's [classifier comparison tutorial](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html).\n",
    "\n",
    "We set a random seed for reproducibility.\n",
    "\n",
    "In this tutorial, we defined two lists of models, one with default parameters and the other with slightly tweaked settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5bbf912",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_state = 42  # set to None for a different random state each time\n",
    "\n",
    "models1 = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=rnd_state),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=rnd_state),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=rnd_state),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=rnd_state),\n",
    "    \"Linear SVM\": SVC(random_state=rnd_state),\n",
    "    \"RBF SVM\": SVC(random_state=rnd_state),\n",
    "    \"Neural Net\": MLPClassifier(random_state=rnd_state),\n",
    "    \"Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "}\n",
    "\n",
    "models2 = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=rnd_state, C=0.5),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=3, random_state=rnd_state),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=50, max_depth=5, random_state=rnd_state\n",
    "    ),\n",
    "    \"AdaBoost\": AdaBoostClassifier(learning_rate=0.6, random_state=rnd_state),\n",
    "    \"Linear SVM\": SVC(kernel=\"linear\", C=0.025, random_state=rnd_state),\n",
    "    \"RBF SVM\": SVC(gamma=\"scale\", C=1, random_state=rnd_state),\n",
    "    \"Neural Net\": MLPClassifier(alpha=1, max_iter=1000, random_state=rnd_state),\n",
    "    \"Nearest Neighbors\": KNeighborsClassifier(n_neighbors=3),\n",
    "    \"Naive Bayes\": GaussianNB(var_smoothing=1e-10),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b91234",
   "metadata": {},
   "source": [
    "#### Decide on a performance metric for model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6b76c4",
   "metadata": {},
   "source": [
    "There are many performance metrics that we can use to evaluate and compare models. Some of the most commons are: accuracy, class recall, class precision, class f1-score. Scikit-learn's documentation lists a huge variety of other metrics that can be used:: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "Arbitrary performance metrics can be defined  with scikit learn's `make_scorer` method, but this notebook, we're going to keep things simple and use a *balanced accuracy score*, since we don't have the same number of samples in each class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76942510",
   "metadata": {},
   "source": [
    "#### Run cross-validation for each model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938caea9",
   "metadata": {},
   "source": [
    "Here we use scikit-learn's `cross-validate` method that returns training and validation scores for each validation split (5 total). We store the average and standard deviation of each score for later comparison. It is important that we do keep both training and validation scores, as the comparison between both allows us to spot oeverfitting issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31ca81cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying model: Logistic Regression\n",
      "Train balanced_accuracy: 0.9151 ± 0.0164\n",
      "Validation balanced_accuracy: 0.8256 ± 0.0553\n",
      "Train vs Val difference: 0.0895\n",
      "\n",
      "Trying model: Decision Tree\n",
      "Train balanced_accuracy: 1.0000 ± 0.0000\n",
      "Validation balanced_accuracy: 0.8020 ± 0.0734\n",
      "Train vs Val difference: 0.1980\n",
      "\n",
      "Trying model: Random Forest\n",
      "Train balanced_accuracy: 1.0000 ± 0.0000\n",
      "Validation balanced_accuracy: 0.8637 ± 0.0484\n",
      "Train vs Val difference: 0.1363\n",
      "\n",
      "Trying model: AdaBoost\n",
      "Train balanced_accuracy: 0.9959 ± 0.0051\n",
      "Validation balanced_accuracy: 0.8557 ± 0.0413\n",
      "Train vs Val difference: 0.1401\n",
      "\n",
      "Trying model: Linear SVM\n",
      "Train balanced_accuracy: 0.8773 ± 0.0133\n",
      "Validation balanced_accuracy: 0.7965 ± 0.0711\n",
      "Train vs Val difference: 0.0807\n",
      "\n",
      "Trying model: RBF SVM\n",
      "Train balanced_accuracy: 0.8773 ± 0.0133\n",
      "Validation balanced_accuracy: 0.7965 ± 0.0711\n",
      "Train vs Val difference: 0.0807\n",
      "\n",
      "Trying model: Neural Net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/Storage/klockenbring/Seafile/My Libraries/Dimitri/projets/ml-radiomics-classification/.venv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/media/Storage/klockenbring/Seafile/My Libraries/Dimitri/projets/ml-radiomics-classification/.venv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/media/Storage/klockenbring/Seafile/My Libraries/Dimitri/projets/ml-radiomics-classification/.venv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/media/Storage/klockenbring/Seafile/My Libraries/Dimitri/projets/ml-radiomics-classification/.venv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/media/Storage/klockenbring/Seafile/My Libraries/Dimitri/projets/ml-radiomics-classification/.venv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train balanced_accuracy: 0.9748 ± 0.0131\n",
      "Validation balanced_accuracy: 0.8458 ± 0.0632\n",
      "Train vs Val difference: 0.1290\n",
      "\n",
      "Trying model: Nearest Neighbors\n",
      "Train balanced_accuracy: 0.8470 ± 0.0189\n",
      "Validation balanced_accuracy: 0.7868 ± 0.0643\n",
      "Train vs Val difference: 0.0601\n",
      "\n",
      "Trying model: Naive Bayes\n",
      "Train balanced_accuracy: 0.7921 ± 0.0190\n",
      "Validation balanced_accuracy: 0.7961 ± 0.0365\n",
      "Train vs Val difference: -0.0040\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "Trying model: Logistic Regression\n",
      "Train balanced_accuracy: 0.8986 ± 0.0239\n",
      "Validation balanced_accuracy: 0.8256 ± 0.0553\n",
      "Train vs Val difference: 0.0730\n",
      "\n",
      "Trying model: Decision Tree\n",
      "Train balanced_accuracy: 0.9038 ± 0.0325\n",
      "Validation balanced_accuracy: 0.8408 ± 0.0702\n",
      "Train vs Val difference: 0.0630\n",
      "\n",
      "Trying model: Random Forest\n",
      "Train balanced_accuracy: 0.9262 ± 0.0122\n",
      "Validation balanced_accuracy: 0.8637 ± 0.0540\n",
      "Train vs Val difference: 0.0624\n",
      "\n",
      "Trying model: AdaBoost\n",
      "Train balanced_accuracy: 0.9399 ± 0.0055\n",
      "Validation balanced_accuracy: 0.8675 ± 0.0648\n",
      "Train vs Val difference: 0.0725\n",
      "\n",
      "Trying model: Linear SVM\n",
      "Train balanced_accuracy: 0.8667 ± 0.0205\n",
      "Validation balanced_accuracy: 0.8397 ± 0.0858\n",
      "Train vs Val difference: 0.0270\n",
      "\n",
      "Trying model: RBF SVM\n",
      "Train balanced_accuracy: 0.8773 ± 0.0133\n",
      "Validation balanced_accuracy: 0.7965 ± 0.0711\n",
      "Train vs Val difference: 0.0807\n",
      "\n",
      "Trying model: Neural Net\n",
      "Train balanced_accuracy: 0.9260 ± 0.0173\n",
      "Validation balanced_accuracy: 0.8564 ± 0.0567\n",
      "Train vs Val difference: 0.0696\n",
      "\n",
      "Trying model: Nearest Neighbors\n",
      "Train balanced_accuracy: 0.8708 ± 0.0279\n",
      "Validation balanced_accuracy: 0.8069 ± 0.0577\n",
      "Train vs Val difference: 0.0639\n",
      "\n",
      "Trying model: Naive Bayes\n",
      "Train balanced_accuracy: 0.7921 ± 0.0190\n",
      "Validation balanced_accuracy: 0.7961 ± 0.0365\n",
      "Train vs Val difference: -0.0040\n"
     ]
    }
   ],
   "source": [
    "def cross_validate_models(models, X_train, y_train):\n",
    "    results = []\n",
    "\n",
    "    scoring = \"balanced_accuracy\"\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nTrying model: {model_name}\")\n",
    "        cv_results = cross_validate(\n",
    "            model,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=5,\n",
    "            scoring=scoring,\n",
    "            return_train_score=True,\n",
    "        )\n",
    "\n",
    "        train_mean = cv_results[\"train_score\"].mean()\n",
    "        train_std = cv_results[\"train_score\"].std()\n",
    "        val_mean = cv_results[\"test_score\"].mean()\n",
    "        val_std = cv_results[\"test_score\"].std()\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"Model\": model_name,\n",
    "                \"Train Mean\": train_mean,\n",
    "                \"Train Std\": train_std,\n",
    "                \"Val Mean\": val_mean,\n",
    "                \"Val Std\": val_std,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(f\"Train {scoring}: {train_mean:.4f} ± {train_std:.4f}\")\n",
    "        print(f\"Validation {scoring}: {val_mean:.4f} ± {val_std:.4f}\")\n",
    "        print(f\"Train vs Val difference: {train_mean - val_mean:.4f}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "results1 = cross_validate_models(models1, X_train, y_train)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100 + \"\\n\")\n",
    "results2 = cross_validate_models(models2, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a76c9",
   "metadata": {},
   "source": [
    "#### Look at the results and compare the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4ded5d",
   "metadata": {},
   "source": [
    "We then sort the models by average validation score to see which ones perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b73b2a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for models1:\n",
      "╒═════════════════════╤═══════════════╤════════════════════╤══════════════════╕\n",
      "│ Model               │ Train Score   │ Validation Score   │   Train-val Diff │\n",
      "╞═════════════════════╪═══════════════╪════════════════════╪══════════════════╡\n",
      "│ Random Forest       │ 1.000 ± 0.000 │ 0.864 ± 0.048      │       0.136251   │\n",
      "├─────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ AdaBoost            │ 0.996 ± 0.005 │ 0.856 ± 0.041      │       0.140145   │\n",
      "├─────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ Neural Net          │ 0.975 ± 0.013 │ 0.846 ± 0.063      │       0.128959   │\n",
      "├─────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ Logistic Regression │ 0.915 ± 0.016 │ 0.826 ± 0.055      │       0.0894858  │\n",
      "├─────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ Decision Tree       │ 1.000 ± 0.000 │ 0.802 ± 0.073      │       0.198024   │\n",
      "├─────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ Linear SVM          │ 0.877 ± 0.013 │ 0.797 ± 0.071      │       0.0807303  │\n",
      "├─────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ RBF SVM             │ 0.877 ± 0.013 │ 0.797 ± 0.071      │       0.0807303  │\n",
      "├─────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ Naive Bayes         │ 0.792 ± 0.019 │ 0.796 ± 0.036      │      -0.00402415 │\n",
      "├─────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ Nearest Neighbors   │ 0.847 ± 0.019 │ 0.787 ± 0.064      │       0.0601102  │\n",
      "╘═════════════════════╧═══════════════╧════════════════════╧══════════════════╛\n",
      "\n",
      "Results for models2:\n",
      "╒═════════════════════╤═══════════════╤════════════════════╤══════════════════╕\n",
      "│ Model               │ Train Score   │ Validation Score   │   Train-val Diff │\n",
      "╞═════════════════════╪═══════════════╪════════════════════╪══════════════════╡\n",
      "│ AdaBoost            │ 0.940 ± 0.005 │ 0.867 ± 0.065      │       0.0724671  │\n",
      "├─────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ Random Forest       │ 0.926 ± 0.012 │ 0.864 ± 0.054      │       0.0624419  │\n",
      "├─────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ Neural Net          │ 0.926 ± 0.017 │ 0.856 ± 0.057      │       0.069583   │\n",
      "├─────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ Decision Tree       │ 0.904 ± 0.033 │ 0.841 ± 0.070      │       0.0629793  │\n",
      "├─────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ Linear SVM          │ 0.867 ± 0.021 │ 0.840 ± 0.086      │       0.0269912  │\n",
      "├─────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ Logistic Regression │ 0.899 ± 0.024 │ 0.826 ± 0.055      │       0.0730099  │\n",
      "├─────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ Nearest Neighbors   │ 0.871 ± 0.028 │ 0.807 ± 0.058      │       0.0639001  │\n",
      "├─────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ RBF SVM             │ 0.877 ± 0.013 │ 0.797 ± 0.071      │       0.0807303  │\n",
      "├─────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ Naive Bayes         │ 0.792 ± 0.019 │ 0.796 ± 0.036      │      -0.00402415 │\n",
      "╘═════════════════════╧═══════════════╧════════════════════╧══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "def list_results_sorted(results):\n",
    "    # Sort by validation mean\n",
    "    results = sorted(results, key=lambda x: x[\"Val Mean\"], reverse=True)\n",
    "\n",
    "    # Prepare table for tabulate (remove Val Mean from display)\n",
    "\n",
    "    table = []\n",
    "    for r in results:\n",
    "        train_val_diff = r[\"Train Mean\"] - r[\"Val Mean\"]\n",
    "        table.append(\n",
    "            [\n",
    "                r[\"Model\"],\n",
    "                f\"{r['Train Mean']:.3f} ± {r['Train Std']:.3f}\",\n",
    "                f\"{r['Val Mean']:.3f} ± {r['Val Std']:.3f}\",\n",
    "                train_val_diff,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        tabulate(\n",
    "            table,\n",
    "            headers=[\"Model\", \"Train Score\", \"Validation Score\", \"Train-val Diff\"],\n",
    "            tablefmt=\"fancy_grid\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"\\nResults for models1:\")\n",
    "list_results_sorted(results1)\n",
    "\n",
    "print(\"\\nResults for models2:\")\n",
    "list_results_sorted(results2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd19dbe9",
   "metadata": {},
   "source": [
    "We notice that some models from the first list have a bigger performance difference (above 0.1) between training and validation data, and sometimes a perfect train score. These are signs of overfitting. Ideally, train and validation score should be both high and close to each other.\n",
    "\n",
    "Results from the second models list with tweaked parameters are better, the difference between train and validation scores is lower.\n",
    "\n",
    "Overall, it seems that AdaBoost, Random Forest and Neural Net are the most promising models in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea090fb2",
   "metadata": {},
   "source": [
    "## Fine-tune a chosen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82aff6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (50, 5)\n",
      "┌─────────────────────┬────────────────────┬─────────────────┬────────────────┬─────────────────┐\n",
      "│ param_learning_rate ┆ param_n_estimators ┆ mean_test_score ┆ std_test_score ┆ rank_test_score │\n",
      "│ ---                 ┆ ---                ┆ ---             ┆ ---            ┆ ---             │\n",
      "│ f64                 ┆ i64                ┆ f64             ┆ f64            ┆ i32             │\n",
      "╞═════════════════════╪════════════════════╪═════════════════╪════════════════╪═════════════════╡\n",
      "│ 0.378379            ┆ 163                ┆ 0.86805         ┆ 0.044836       ┆ 1               │\n",
      "│ 0.639583            ┆ 53                 ┆ 0.867409        ┆ 0.055581       ┆ 2               │\n",
      "│ 0.716213            ┆ 264                ┆ 0.867363        ┆ 0.045587       ┆ 3               │\n",
      "│ 0.647485            ┆ 50                 ┆ 0.865922        ┆ 0.054522       ┆ 4               │\n",
      "│ 0.148144            ┆ 206                ┆ 0.865281        ┆ 0.048593       ┆ 5               │\n",
      "│ …                   ┆ …                  ┆ …               ┆ …              ┆ …               │\n",
      "│ 0.226849            ┆ 51                 ┆ 0.820819        ┆ 0.049047       ┆ 46              │\n",
      "│ 0.188982            ┆ 62                 ┆ 0.820819        ┆ 0.054341       ┆ 47              │\n",
      "│ 0.118571            ┆ 89                 ┆ 0.812485        ┆ 0.035541       ┆ 48              │\n",
      "│ 0.109893            ┆ 49                 ┆ 0.806372        ┆ 0.061036       ┆ 49              │\n",
      "│ 0.121891            ┆ 9                  ┆ 0.802117        ┆ 0.045747       ┆ 50              │\n",
      "└─────────────────────┴────────────────────┴─────────────────┴────────────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "a, b = 0.1, 1.5\n",
    "learning_rate_distrib = uniform(loc=a, scale=b - a)\n",
    "n_estimators_distrib = randint(1, 300)\n",
    "param_distributions = {\n",
    "    \"learning_rate\": learning_rate_distrib,\n",
    "    \"n_estimators\": n_estimators_distrib,\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    AdaBoostClassifier(random_state=rnd_state),\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    cv=5,\n",
    "    random_state=rnd_state,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "cv_res = pl.DataFrame(random_search.cv_results_)\n",
    "cv_res = cv_res.sort(\"mean_test_score\", descending=True).select(\n",
    "    [\n",
    "        col\n",
    "        for col in cv_res.columns\n",
    "        if not (col.startswith(\"split\") or col.endswith(\"_time\") or col == \"params\")\n",
    "    ]\n",
    ")\n",
    "print(cv_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63833049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-a5b521518f7f424f984f1620cbc57e54.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-a5b521518f7f424f984f1620cbc57e54.vega-embed details,\n",
       "  #altair-viz-a5b521518f7f424f984f1620cbc57e54.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-a5b521518f7f424f984f1620cbc57e54\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-a5b521518f7f424f984f1620cbc57e54\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-a5b521518f7f424f984f1620cbc57e54\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-ec9e0d9c87c071a29f27975710b8c1d6\"}, \"mark\": {\"type\": \"circle\"}, \"encoding\": {\"color\": {\"field\": \"mean_test_score\", \"legend\": {\"title\": \"Mean Test Score\"}, \"scale\": {\"clamp\": true, \"domain\": [0.8021169856970042, 0.8680501197846249], \"scheme\": \"turbo\"}, \"type\": \"quantitative\"}, \"size\": {\"field\": \"size_exp\", \"legend\": null, \"scale\": {\"range\": [80, 900]}, \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"param_n_estimators\", \"type\": \"quantitative\"}, {\"field\": \"param_learning_rate\", \"type\": \"quantitative\"}, {\"field\": \"mean_test_score\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"param_n_estimators\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"param_learning_rate\", \"type\": \"quantitative\"}}, \"height\": 400, \"params\": [{\"name\": \"param_3\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"title\": \"AdaBoost Hyperparameter Search Results\", \"transform\": [{\"calculate\": \"(datum.mean_test_score - 0.8021169856970042) / 0.06593313408762069\", \"as\": \"score_norm\"}, {\"calculate\": \"pow((datum.mean_test_score - 0.8021169856970042) / 0.06593313408762069, 3)\", \"as\": \"size_exp\"}], \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-ec9e0d9c87c071a29f27975710b8c1d6\": [{\"param_learning_rate\": 0.3783793657243272, \"param_n_estimators\": 163, \"mean_test_score\": 0.8680501197846249, \"std_test_score\": 0.04483591811603063, \"rank_test_score\": 1}, {\"param_learning_rate\": 0.6395831035558824, \"param_n_estimators\": 53, \"mean_test_score\": 0.8674090941435993, \"std_test_score\": 0.05558073233294055, \"rank_test_score\": 2}, {\"param_learning_rate\": 0.7162134912354418, \"param_n_estimators\": 264, \"mean_test_score\": 0.8673628406745891, \"std_test_score\": 0.04558661134689382, \"rank_test_score\": 3}, {\"param_learning_rate\": 0.647484850602537, \"param_n_estimators\": 50, \"mean_test_score\": 0.8659224602101568, \"std_test_score\": 0.054521966376277334, \"rank_test_score\": 4}, {\"param_learning_rate\": 0.14814392956130576, \"param_n_estimators\": 206, \"mean_test_score\": 0.8652814345691311, \"std_test_score\": 0.04859252889836856, \"rank_test_score\": 5}, {\"param_learning_rate\": 0.3387337731622081, \"param_n_estimators\": 167, \"mean_test_score\": 0.8640183590692379, \"std_test_score\": 0.044050648133045836, \"rank_test_score\": 6}, {\"param_learning_rate\": 1.3968212299186886, \"param_n_estimators\": 41, \"mean_test_score\": 0.8616208875922104, \"std_test_score\": 0.028336068578590418, \"rank_test_score\": 7}, {\"param_learning_rate\": 0.8346845243617448, \"param_n_estimators\": 170, \"mean_test_score\": 0.8612034203847341, \"std_test_score\": 0.04499142494082961, \"rank_test_score\": 8}, {\"param_learning_rate\": 0.6129065806111683, \"param_n_estimators\": 190, \"mean_test_score\": 0.8596705329822815, \"std_test_score\": 0.042333603152740644, \"rank_test_score\": 9}, {\"param_learning_rate\": 0.8653943910805915, \"param_n_estimators\": 191, \"mean_test_score\": 0.8596705329822815, \"std_test_score\": 0.042333603152740644, \"rank_test_score\": 9}, {\"param_learning_rate\": 1.1107982811735546, \"param_n_estimators\": 294, \"mean_test_score\": 0.8590295073412557, \"std_test_score\": 0.04558140782752105, \"rank_test_score\": 11}, {\"param_learning_rate\": 0.8291679640361531, \"param_n_estimators\": 190, \"mean_test_score\": 0.8590295073412557, \"std_test_score\": 0.041370175769607734, \"rank_test_score\": 11}, {\"param_learning_rate\": 0.4232513558710086, \"param_n_estimators\": 92, \"mean_test_score\": 0.8575891268768234, \"std_test_score\": 0.0433126191066824, \"rank_test_score\": 13}, {\"param_learning_rate\": 0.22388950287268727, \"param_n_estimators\": 215, \"mean_test_score\": 0.8575891268768234, \"std_test_score\": 0.0433126191066824, \"rank_test_score\": 13}, {\"param_learning_rate\": 0.5147829079857154, \"param_n_estimators\": 65, \"mean_test_score\": 0.8575891268768234, \"std_test_score\": 0.0433126191066824, \"rank_test_score\": 13}, {\"param_learning_rate\": 1.1811426770153204, \"param_n_estimators\": 136, \"mean_test_score\": 0.8575428734078134, \"std_test_score\": 0.04177850922719648, \"rank_test_score\": 16}, {\"param_learning_rate\": 0.10109027217742006, \"param_n_estimators\": 277, \"mean_test_score\": 0.8569481012357979, \"std_test_score\": 0.04822934136422766, \"rank_test_score\": 17}, {\"param_learning_rate\": 0.1653319284990616, \"param_n_estimators\": 188, \"mean_test_score\": 0.8569481012357979, \"std_test_score\": 0.04822934136422766, \"rank_test_score\": 17}, {\"param_learning_rate\": 0.31839232847068366, \"param_n_estimators\": 88, \"mean_test_score\": 0.8569018477667877, \"std_test_score\": 0.04875069587979443, \"rank_test_score\": 19}, {\"param_learning_rate\": 1.011243862128394, \"param_n_estimators\": 258, \"mean_test_score\": 0.8569018477667877, \"std_test_score\": 0.043540525094199894, \"rank_test_score\": 19}, {\"param_learning_rate\": 1.206245756743688, \"param_n_estimators\": 261, \"mean_test_score\": 0.8569018477667877, \"std_test_score\": 0.04715981842196319, \"rank_test_score\": 19}, {\"param_learning_rate\": 0.5552566508374458, \"param_n_estimators\": 99, \"mean_test_score\": 0.8553689603643351, \"std_test_score\": 0.04115701439205363, \"rank_test_score\": 22}, {\"param_learning_rate\": 1.3420978396068572, \"param_n_estimators\": 227, \"mean_test_score\": 0.8550440000948789, \"std_test_score\": 0.04978956530599651, \"rank_test_score\": 23}, {\"param_learning_rate\": 0.9355902211250817, \"param_n_estimators\": 122, \"mean_test_score\": 0.851337199648948, \"std_test_score\": 0.04462875285338524, \"rank_test_score\": 24}, {\"param_learning_rate\": 0.5671920555946306, \"param_n_estimators\": 152, \"mean_test_score\": 0.851337199648948, \"std_test_score\": 0.04462875285338524, \"rank_test_score\": 24}, {\"param_learning_rate\": 0.6354467877740277, \"param_n_estimators\": 244, \"mean_test_score\": 0.851337199648948, \"std_test_score\": 0.03601778917152045, \"rank_test_score\": 24}, {\"param_learning_rate\": 0.5554624630685701, \"param_n_estimators\": 208, \"mean_test_score\": 0.851337199648948, \"std_test_score\": 0.04462875285338524, \"rank_test_score\": 24}, {\"param_learning_rate\": 1.1181807941989892, \"param_n_estimators\": 271, \"mean_test_score\": 0.8507424274769326, \"std_test_score\": 0.045920486729980975, \"rank_test_score\": 28}, {\"param_learning_rate\": 0.6952182242877425, \"param_n_estimators\": 54, \"mean_test_score\": 0.8498968191845158, \"std_test_score\": 0.044202118867024555, \"rank_test_score\": 29}, {\"param_learning_rate\": 0.9214516319293874, \"param_n_estimators\": 217, \"mean_test_score\": 0.8491632866054697, \"std_test_score\": 0.03426252333319978, \"rank_test_score\": 30}, {\"param_learning_rate\": 0.9278169027908179, \"param_n_estimators\": 214, \"mean_test_score\": 0.8485685144334543, \"std_test_score\": 0.0391418537800199, \"rank_test_score\": 31}, {\"param_learning_rate\": 1.380943545761293, \"param_n_estimators\": 201, \"mean_test_score\": 0.8473979458715813, \"std_test_score\": 0.04072489468505077, \"rank_test_score\": 32}, {\"param_learning_rate\": 1.1247915185359671, \"param_n_estimators\": 189, \"mean_test_score\": 0.8464408548589862, \"std_test_score\": 0.046662960137804285, \"rank_test_score\": 33}, {\"param_learning_rate\": 0.49330831356233307, \"param_n_estimators\": 41, \"mean_test_score\": 0.8464408548589862, \"std_test_score\": 0.06316111742157955, \"rank_test_score\": 33}, {\"param_learning_rate\": 0.9293803964068594, \"param_n_estimators\": 131, \"mean_test_score\": 0.845177779359093, \"std_test_score\": 0.03234119669918104, \"rank_test_score\": 35}, {\"param_learning_rate\": 1.4152985181898647, \"param_n_estimators\": 270, \"mean_test_score\": 0.845177779359093, \"std_test_score\": 0.041718071005016094, \"rank_test_score\": 35}, {\"param_learning_rate\": 1.4518848463043832, \"param_n_estimators\": 242, \"mean_test_score\": 0.8446755141250979, \"std_test_score\": 0.05261838634737327, \"rank_test_score\": 37}, {\"param_learning_rate\": 1.3039165694308488, \"param_n_estimators\": 135, \"mean_test_score\": 0.8445367537180672, \"std_test_score\": 0.050205904063328595, \"rank_test_score\": 38}, {\"param_learning_rate\": 0.6243561663863074, \"param_n_estimators\": 271, \"mean_test_score\": 0.8430038663156149, \"std_test_score\": 0.0368508327350959, \"rank_test_score\": 39}, {\"param_learning_rate\": 1.279198684432998, \"param_n_estimators\": 44, \"mean_test_score\": 0.8428728148200859, \"std_test_score\": 0.04872344436410547, \"rank_test_score\": 40}, {\"param_learning_rate\": 0.9644741134788031, \"param_n_estimators\": 22, \"mean_test_score\": 0.8354040655613273, \"std_test_score\": 0.05880123296727451, \"rank_test_score\": 41}, {\"param_learning_rate\": 0.972617377558581, \"param_n_estimators\": 33, \"mean_test_score\": 0.8351805071277782, \"std_test_score\": 0.061690683462990434, \"rank_test_score\": 42}, {\"param_learning_rate\": 1.1462481541923333, \"param_n_estimators\": 53, \"mean_test_score\": 0.8304152138333452, \"std_test_score\": 0.033554085664954776, \"rank_test_score\": 43}, {\"param_learning_rate\": 1.0275311980955748, \"param_n_estimators\": 2, \"mean_test_score\": 0.8283338077278873, \"std_test_score\": 0.07112223571748877, \"rank_test_score\": 44}, {\"param_learning_rate\": 0.10773096397304337, \"param_n_estimators\": 139, \"mean_test_score\": 0.8270244787589839, \"std_test_score\": 0.055948455728885106, \"rank_test_score\": 45}, {\"param_learning_rate\": 0.22684900834594912, \"param_n_estimators\": 51, \"mean_test_score\": 0.8208188050001187, \"std_test_score\": 0.04904659913131047, \"rank_test_score\": 46}, {\"param_learning_rate\": 0.18898169040043308, \"param_n_estimators\": 62, \"mean_test_score\": 0.8208188050001185, \"std_test_score\": 0.0543406073113641, \"rank_test_score\": 47}, {\"param_learning_rate\": 0.11857094562381315, \"param_n_estimators\": 89, \"mean_test_score\": 0.8124854716667853, \"std_test_score\": 0.03554134588834691, \"rank_test_score\": 48}, {\"param_learning_rate\": 0.10989282730760437, \"param_n_estimators\": 49, \"mean_test_score\": 0.8063723048459405, \"std_test_score\": 0.061036489585615826, \"rank_test_score\": 49}, {\"param_learning_rate\": 0.12189096943767151, \"param_n_estimators\": 9, \"mean_test_score\": 0.8021169856970042, \"std_test_score\": 0.04574683940389742, \"rank_test_score\": 50}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_score = cv_res[\"mean_test_score\"].min()\n",
    "max_score = cv_res[\"mean_test_score\"].max()\n",
    "score_range = max_score - min_score if max_score != min_score else 1.0\n",
    "\n",
    "chart = (\n",
    "    alt.Chart(cv_res)\n",
    "    .transform_calculate(\n",
    "        # normalized version (0–1)\n",
    "        score_norm=f\"(datum.mean_test_score - {min_score}) / {score_range}\",\n",
    "        # exponential scaling for size (power of 3)\n",
    "        size_exp=f\"pow((datum.mean_test_score - {min_score}) / {score_range}, 3)\",\n",
    "    )\n",
    "    .mark_circle()\n",
    "    .encode(\n",
    "        x=\"param_n_estimators\",\n",
    "        y=\"param_learning_rate\",\n",
    "        color=alt.Color(\n",
    "            \"mean_test_score:Q\",\n",
    "            scale=alt.Scale(\n",
    "                domain=[min_score, max_score],\n",
    "                scheme=\"turbo\",  # bright and high contrast\n",
    "                clamp=True,\n",
    "            ),\n",
    "            legend=alt.Legend(title=\"Mean Test Score\"),\n",
    "        ),\n",
    "        size=alt.Size(\n",
    "            \"size_exp:Q\",\n",
    "            scale=alt.Scale(range=[80, 900]),\n",
    "            legend=None,\n",
    "        ),\n",
    "        tooltip=[\"param_n_estimators\", \"param_learning_rate\", \"mean_test_score\"],\n",
    "    )\n",
    "    .properties(\n",
    "        title=\"AdaBoost Hyperparameter Search Results\",\n",
    "        width=600,\n",
    "        height=400,\n",
    "    )\n",
    "    .interactive()\n",
    ")\n",
    "chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5766df10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(learning_rate=np.float64(0.3783793657243272),\n",
       "                   n_estimators=163, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>AdaBoostClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\">?<span>Documentation for AdaBoostClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimator&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">163</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(0.3783793657243272)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('algorithm',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">algorithm&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "AdaBoostClassifier(learning_rate=np.float64(0.3783793657243272),\n",
       "                   n_estimators=163, random_state=42)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88c0021b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy on test data: 0.8248587570621468\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HGG       0.92      0.98      0.95        59\n",
      "         LGG       0.91      0.67      0.77        15\n",
      "\n",
      "    accuracy                           0.92        74\n",
      "   macro avg       0.91      0.82      0.86        74\n",
      "weighted avg       0.92      0.92      0.91        74\n",
      "\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x77ab138b86e0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAGwCAYAAAAjT/bYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAM+NJREFUeJzt3Xl4VOXZx/HfJCELSWZCUkiIJJEUCJu4RCVp3UAk4gZCKyBWKNG+FmSnKlVQUECxBcUL0BciqBXBhUVoi1IUlLK8skRtxSCILAaiFZOQYBYy5/0DmToyYCbPJDMZvp/req4y5zznnHvaUO7c93POsVmWZQkAAOBHQvwdAAAACEwkCQAAwCOSBAAA4BFJAgAA8IgkAQAAeESSAAAAPCJJAAAAHoX5O4BA5XQ6VVhYqNjYWNlsNn+HAwDwkmVZOnbsmJKTkxUSUn+/E1dUVKiqqsr4POHh4YqMjPRBRL5DknAGhYWFSklJ8XcYAABDBw8eVKtWrerl3BUVFWqdFqMjX9UYnyspKUn79u0LqESBJOEMYmNjJUn7d5wvewxdGQSnW9td4O8QgHpzQtXaqL+5/v+8PlRVVenIVzXav/182WPr/m9F6TGn0jK/UFVVFUlCY3CqxWCPCTH6Hx4IZGG2Jv4OAag/3790oCFaxjGxNsXE1v06TgVmW5skAQAAQzWWUzUGb0KqsZy+C8aHSBIAADDklCWn6p4lmBxbn6ijAwAAj6gkAABgyCmnTBoGZkfXH5IEAAAM1ViWaqy6twxMjq1PtBsAAIBHVBIAADAUrAsXSRIAADDklKWaIEwSaDcAAACPqCQAAGCIdgMAAPCIuxsAAMA5hUoCAACGnN8Pk+MDEUkCAACGagzvbjA5tj6RJAAAYKjGkuFbIH0Xiy+xJgEAAHhEJQEAAEOsSQAAAB45ZVONbEbHByLaDQAAwCMqCQAAGHJaJ4fJ8YGIJAEAAEM1hu0Gk2PrE+0GAADgEZUEAAAMBWslgSQBAABDTssmp2Vwd4PBsfWJdgMAAPCISgIAAIZoNwAAAI9qFKIag+J8jQ9j8SWSBAAADFmGaxIs1iQAAIDGhEoCAACGWJMAAAA8qrFCVGMZrEkI0Mcy024AAAAeUUkAAMCQUzY5DX7vdiowSwkkCQAAGArWNQm0GwAAgEdUEgAAMGS+cJF2AwAAQenkmgSDFzzRbgAAAI0JlQQAAAw5Dd/dwN0NAAAEKdYkAAAAj5wKCcrnJLAmAQAAeEQlAQAAQzWWTTUGr3s2ObY+kSQAAGCoxnDhYg3tBgAA0JiQJAAAYMhphRgPbzzyyCOy2Wxuo3379q79FRUVGj58uBISEhQTE6N+/fqpqKjI6+9FkgAAgKFT7QaT4a1OnTrp8OHDrrFx40bXvjFjxmjVqlV67bXXtGHDBhUWFqpv375eX4M1CQAANEJhYWFKSko6bXtJSYny8vK0ePFide/eXZK0cOFCdejQQVu2bFFWVlatr0ElAQAAQ0799w6Hugzn9+cpLS11G5WVlWe85meffabk5GSlp6dr0KBBOnDggCRp+/btqq6uVo8ePVxz27dvr9TUVG3evNmr70WSAACAoVMPUzIZkpSSkiKHw+Ea06dP93i9rl27atGiRVqzZo3mzZunffv26corr9SxY8d05MgRhYeHKy4uzu2YxMREHTlyxKvvRbsBAIAAcfDgQdntdtfniIgIj/N69erl+nOXLl3UtWtXpaWl6dVXX1VUVJTP4iFJAADAkPm7G04ea7fb3ZKE2oqLi1O7du20Z88eXXfddaqqqlJxcbFbNaGoqMjjGoazod0AAIAhp2zGw0RZWZn27t2rli1bKjMzU02aNNG6detc+wsKCnTgwAFlZ2d7dV4qCQAAGPJVJaG2xo8fr5tvvllpaWkqLCzUww8/rNDQUA0cOFAOh0O5ubkaO3as4uPjZbfbNWLECGVnZ3t1Z4NEkgAAQKNz6NAhDRw4UN98842aN2+uK664Qlu2bFHz5s0lSbNmzVJISIj69eunyspK5eTkaO7cuV5fhyQBAABD5u9u8O7YJUuWnHV/ZGSk5syZozlz5tQ5JokkAQAAY07LJqfBmxxNjq1PLFwEAAAeUUkAAMCQ07Dd4AzQ39lJEgAAMFSXNzn++PhAFJhRAQAAv6OSAACAoRrZVGPwQCSTY+sTSQIAAIZoNwAAgHMKlQQAAAzVyKxlUOO7UHyKJAEAAEPB2m4gSQAAwFBDv+CpoQRmVAAAwO+oJAAAYMiSTU6DNQkWt0ACABCcaDcAAIBzCpUEAAAMBeurokkSAAAwVGP4FkiTY+tTYEYFAAD8jkoCAACGaDcAAACPnAqR06A4b3JsfQrMqAAAgN9RSQAAwFCNZVONQcvA5Nj6RJIAAIAh1iQAAACPLMO3QFo8cREAADQmVBIAADBUI5tqDF7SZHJsfSJJAADAkNMyW1fgtHwYjA/RbgAAAB5RSUCDeulPSfrLzCS3ba1+XqG89z+VJB39KkwLHk3WjvdidbwsRCk/r9SAUUW68sYSf4QLGOvctUy/Hva12l5wXAlJJ/TI0PO1eY3D32HBx5yGCxdNjq1PJAlocGkZ3+nxpXtdn0ND/1tne3JkqspKQ/XIon1yxJ/Qu8ubadr/nK9n/r5bbS74zh/hAkYimzr1+b8j9dYr8Xr4+S/8HQ7qiVM2OQ3WFZgcW5/8mroMGTJEffr0OW37+vXrZbPZVFxcLEmyLEvz589Xdna27Ha7YmJi1KlTJ40aNUp79uxxO7a0tFQTJ05Up06dFBUVpYSEBF122WWaMWOGvv322wb4VvgpoaFSfIsTruFIqHHt+2RbtHoP/Y/aX3xcLdOqdPvoIkU7avTZR1F+jBiou23v2vXCjJbaRPUAjVBg1jd+wLIs3X777Ro5cqRuuOEGvf322/rkk0+Ul5enyMhIPfbYY665R48eVVZWlhYuXKjx48dr69at2rFjh6ZOnaqdO3dq8eLFfvwmOOXLfeEaeHEnDc7qoMeHp+qrQ01c+zpeWq4Nb8ap9NtQOZ3S+hVxqqqwqcsvyvwYMQCc3aknLpqMQBTw7YalS5dqyZIlWrlypW655RbX9tTUVGVlZcmy/luq/uMf/6gDBw5o9+7dSk5Odm1PS0tTz5493ebCP9pfUq7xT32nVj+v1NGvmugvf07SuFvb6rl3P1XTGKcefG6/pt2Tpl93ukChYZYiopx6OO8Lnde6yt+hA8AZsSbBT1555RVlZGS4JQg/ZLOdzL6cTqeWLl2qO+64wy1B8DTXk8rKSlVWVro+l5aWGkSNM7ms+zHXn9M7Vqj9xcf1m8s76r0343T97Uf1wowklZWG6vGle2SPP6HNaxyaes/5+vPyz9S6Q4UfIweAc4/fU5fVq1crJibGbfTq1cu1f/fu3crIyHA7ZvTo0a65rVq1kiR9/fXXKi4uPm1uZmama+7AgQPPGMf06dPlcDhcIyUlxYffEmcS46hRq/RKFX4RocIvwvXmwuYaO/OgLr6yTD/vVKE7xhWpbZfjenPRz/wdKgCckVM21/sb6jRYuOhZt27dlJ+f7zYWLFhw1mMefPBB5efna9KkSSorO3uvevny5crPz1dOTo6+++7Mq+MnTJigkpIS1zh48GCdvg+88115iAr3hyu+RbUqvzv54xgS4t4WCg21ZDn9ER0A1I71/d0NdR1WgCYJfm83REdHq02bNm7bDh065Ppz27ZtVVBQ4La/efPmat68uVq0aOG2LS4u7rS5qampkqTY2FjX3RKeREREKCIioq5fA7X0v5OTldWzRC1aVeubI2F66U8tFRoiXXPrt4qx1yi5daWevi9Fd08qlL3ZCW1a49CO92I15cXP/R06UCeRTWuU/IM1NUkpVUrv9J2OFYfq6y/D/RgZfClY3wLp90rCTxk4cKAKCgq0cuXKs84LCQnRbbfdpr/85S8qLCxsoOjgrf8cbqLpw87XXVe217R7zpe92Qk9tXq34hJqFNZEeuylvXIknNDDg1vrnmsz9I/X4zX+6QO6/NpjP31yIAC1u/A7zVu7W/PW7pYk3TO5UPPW7tad44/4OTLgp/m9kvBTBgwYoGXLlmnAgAGaMGGCcnJylJiYqP3792vp0qUKDQ11zZ02bZrWr1+vyy+/XFOmTNGll16q6OhoffTRR9q8ebM6d+7sx28CSfrjs/vPuv+89CpNWvBFwwQDNICPNscoJ/lCf4eBesbdDX5is9m0dOlSzZ8/XwsXLtSMGTNUXV2tVq1a6dprr9XMmTNdcxMSEvR///d/euKJJ/Tkk09q3759CgkJUdu2bdW/f3+NHj3af18EABC0grXdYLN4eIBHpaWlcjgc+nZ3uuyxgZnhAaZyki/ydwhAvTlhVWu9VqqkpER2u71ernHq34rebw9Vk+i6rzGpLq/Syp7P12usdRHwlQQAAAJdsL67gSQBAABDwdpuoI4OAAA8opIAAIChYK0kkCQAAGAoWJME2g0AAMAjKgkAABgK1koCSQIAAIYsmd3GGKgPLCJJAADAULBWEliTAAAAPKKSAACAoWCtJJAkAABgKFiTBNoNAADAI5IEAAAMnaokmIy6evzxx2Wz2TR69GjXtoqKCg0fPlwJCQmKiYlRv379VFRU5PW5SRIAADBkWTbjURcffPCBnnvuOXXp0sVt+5gxY7Rq1Sq99tpr2rBhgwoLC9W3b1+vz0+SAABAI1RWVqZBgwZp/vz5atasmWt7SUmJ8vLyNHPmTHXv3l2ZmZlauHChNm3apC1btnh1DZIEAAAMOWUzHpJUWlrqNiorK894zeHDh+vGG29Ujx493LZv375d1dXVbtvbt2+v1NRUbd682avvRZIAAIAhX61JSElJkcPhcI3p06d7vN6SJUu0Y8cOj/uPHDmi8PBwxcXFuW1PTEzUkSNHvPpe3AIJAECAOHjwoOx2u+tzRESExzmjRo3S2rVrFRkZWa/xUEkAAMCQrxYu2u12t+EpSdi+fbu++uorXXLJJQoLC1NYWJg2bNig2bNnKywsTImJiaqqqlJxcbHbcUVFRUpKSvLqe1FJAADAUEM+TOnaa6/Vxx9/7Lbtt7/9rdq3b6/7779fKSkpatKkidatW6d+/fpJkgoKCnTgwAFlZ2d7FRdJAgAAhkxuYzx1fG3Fxsaqc+fObtuio6OVkJDg2p6bm6uxY8cqPj5edrtdI0aMUHZ2trKysryKiyQBAIAgM2vWLIWEhKhfv36qrKxUTk6O5s6d6/V5SBIAADBkGbYbTKoQkrR+/Xq3z5GRkZozZ47mzJljdF6SBAAADFmSLMvs+EDE3Q0AAMAjKgkAABhyyiabDO5uMDi2PpEkAABgqCHvbmhItBsAAIBHVBIAADDktGyyNdDDlBoSSQIAAIYsy/DuhgC9vYF2AwAA8IhKAgAAhoJ14SJJAgAAhkgSAACAR8G6cJE1CQAAwCMqCQAAGArWuxtIEgAAMHQySTBZk+DDYHyIdgMAAPCISgIAAIa4uwEAAHhkfT9Mjg9EtBsAAIBHVBIAADBEuwEAAHgWpP0GkgQAAEwZVhIUoJUE1iQAAACPqCQAAGCIJy4CAACPgnXhIu0GAADgEZUEAABMWTazxYcBWkkgSQAAwFCwrkmg3QAAADyikgAAgCkepgQAADwJ1rsbapUkvPnmm7U+4S233FLnYAAAQOCoVZLQp0+fWp3MZrOppqbGJB4AABqnAG0ZmKhVkuB0Ous7DgAAGq1gbTcY3d1QUVHhqzgAAGi8LB+MAOR1klBTU6NHH31U5513nmJiYvT5559LkiZOnKi8vDyfBwgAAPzD6yRh6tSpWrRokWbMmKHw8HDX9s6dO2vBggU+DQ4AgMbB5oMReLxOEl588UX97//+rwYNGqTQ0FDX9gsvvFCffvqpT4MDAKBRoN1w0pdffqk2bdqctt3pdKq6utonQQEAAP/zOkno2LGj3n///dO2v/7667r44ot9EhQAAI1KkFYSvH7i4qRJkzR48GB9+eWXcjqdWrZsmQoKCvTiiy9q9erV9REjAACBLUjfAul1JaF3795atWqV/vGPfyg6OlqTJk3Srl27tGrVKl133XX1ESMAAPCDOr274corr9TatWt9HQsAAI1SsL4qus4veNq2bZt27dol6eQ6hczMTJ8FBQBAo8JbIE86dOiQBg4cqH/+85+Ki4uTJBUXF+sXv/iFlixZolatWvk6RgAA4Ader0m46667VF1drV27duno0aM6evSodu3aJafTqbvuuqs+YgQAILCdWrhoMgKQ15WEDRs2aNOmTcrIyHBty8jI0DPPPKMrr7zSp8EBANAY2KyTw+T4QOR1kpCSkuLxoUk1NTVKTk72SVAAADQqQbomwet2w5NPPqkRI0Zo27Ztrm3btm3TqFGj9Kc//cmnwQEAAP+pVSWhWbNmstn+2y8pLy9X165dFRZ28vATJ04oLCxMQ4cOVZ8+feolUAAAAlaQPkypVknCU089Vc9hAADQiAVpu6FWScLgwYPrOw4AABBg6vwwJUmqqKhQVVWV2za73W4UEAAAjU6QVhK8XrhYXl6ue++9Vy1atFB0dLSaNWvmNgAAOOcE6VsgvU4S7rvvPr3zzjuaN2+eIiIitGDBAk2ePFnJycl68cUX6yNGAADgB14nCatWrdLcuXPVr18/hYWF6corr9RDDz2kadOm6eWXX66PGAEACGwN/MTFefPmqUuXLrLb7bLb7crOztbf//531/6KigoNHz5cCQkJiomJUb9+/VRUVOT11/I6STh69KjS09MlnVx/cPToUUnSFVdcoffee8/rAAAAaOxOPXHRZHijVatWevzxx7V9+3Zt27ZN3bt3V+/evfXvf/9bkjRmzBitWrVKr732mjZs2KDCwkL17dvX6+/ldZKQnp6uffv2SZLat2+vV199VdLJCsOpFz4BAID6c/PNN+uGG25Q27Zt1a5dO02dOlUxMTHasmWLSkpKlJeXp5kzZ6p79+7KzMzUwoULtWnTJm3ZssWr63idJPz2t7/Vhx9+KEl64IEHNGfOHEVGRmrMmDH6wx/+4O3pAABo/Hy0cLG0tNRtVFZW/uSla2pqtGTJEpWXlys7O1vbt29XdXW1evTo4ZrTvn17paamavPmzV59La9vgRwzZozrzz169NCnn36q7du3q02bNurSpYu3pwMAAN9LSUlx+/zwww/rkUce8Tj3448/VnZ2tioqKhQTE6Ply5erY8eOys/PV3h4+GnV/cTERB05csSreIyekyBJaWlpSktLMz0NAACNlk2Gb4H8/j8PHjzo9ryhiIiIMx6TkZGh/Px8lZSU6PXXX9fgwYO1YcOGugfhQa2ShNmzZ9f6hCNHjqxzMAAAnMtO3a1QG+Hh4WrTpo0kKTMzUx988IGefvpp9e/fX1VVVSouLnarJhQVFSkpKcmreGqVJMyaNatWJ7PZbEGXJPz6ymsVFhLu7zCAemG7rIW/QwDqja2mQtq+smEuFgAveHI6naqsrFRmZqaaNGmidevWqV+/fpKkgoICHThwQNnZ2V6ds1ZJwqm7GQAAgAcN/FjmCRMmqFevXkpNTdWxY8e0ePFirV+/Xm+99ZYcDodyc3M1duxYxcfHy263a8SIEcrOzlZWVpZX1zFekwAAABrWV199pTvvvFOHDx+Ww+FQly5d9NZbb+m6666TdLIDEBISon79+qmyslI5OTmaO3eu19chSQAAwFQDVxLy8vLOuj8yMlJz5szRnDlzDIIiSQAAwFhdnpr44+MDkdcPUwIAAOcGKgkAAJhq4HZDQ6lTJeH999/XHXfcoezsbH355ZeSpJdeekkbN270aXAAADQKPnosc6DxOkl44403lJOTo6ioKO3cudP1XOmSkhJNmzbN5wECAAD/8DpJeOyxx/Tss89q/vz5atKkiWv7L3/5S+3YscOnwQEA0Bg09KuiG4rXaxIKCgp01VVXnbbd4XCouLjYFzEBANC4BMATF+uD15WEpKQk7dmz57TtGzduVHp6uk+CAgCgUWFNwkl33323Ro0apa1bt8pms6mwsFAvv/yyxo8fr9///vf1ESMAAPADr9sNDzzwgJxOp6699lodP35cV111lSIiIjR+/HiNGDGiPmIEACCgBevDlLxOEmw2mx588EH94Q9/0J49e1RWVqaOHTsqJiamPuIDACDwBelzEur8MKXw8HB17NjRl7EAAIAA4nWS0K1bN9lsZ16F+c477xgFBABAo2N6G2OwVBIuuugit8/V1dXKz8/Xv/71Lw0ePNhXcQEA0HjQbjhp1qxZHrc/8sgjKisrMw4IAAAEBp+9BfKOO+7Q888/76vTAQDQeATpcxJ89hbIzZs3KzIy0lenAwCg0eAWyO/17dvX7bNlWTp8+LC2bdumiRMn+iwwAADgX14nCQ6Hw+1zSEiIMjIyNGXKFPXs2dNngQEAAP/yKkmoqanRb3/7W11wwQVq1qxZfcUEAEDjEqR3N3i1cDE0NFQ9e/bkbY8AAPxAsL4q2uu7Gzp37qzPP/+8PmIBAAABxOsk4bHHHtP48eO1evVqHT58WKWlpW4DAIBzUpDd/ih5sSZhypQpGjdunG644QZJ0i233OL2eGbLsmSz2VRTU+P7KAEACGRBuiah1knC5MmTdc899+jdd9+tz3gAAECAqHWSYFkn05yrr7663oIBAKAx4mFK0lnf/ggAwDnrXG83SFK7du1+MlE4evSoUUAAACAweJUkTJ48+bQnLgIAcK6j3SBpwIABatGiRX3FAgBA4xSk7YZaPyeB9QgAAJxbvL67AQAA/EiQVhJqnSQ4nc76jAMAgEaLNQkAAMCzIK0keP3uBgAAcG6gkgAAgKkgrSSQJAAAYChY1yTQbgAAAB5RSQAAwBTtBgAA4AntBgAAcE6hkgAAgCnaDQAAwKMgTRJoNwAAAI+oJAAAYMj2/TA5PhCRJAAAYCpI2w0kCQAAGOIWSAAAcE6hkgAAgCnaDQAA4IwC9B96E7QbAACAR1QSAAAwFKwLF0kSAAAwFaRrEmg3AAAAj0gSAAAwdKrdYDK8MX36dF122WWKjY1VixYt1KdPHxUUFLjNqaio0PDhw5WQkKCYmBj169dPRUVFXl2HJAEAAFOWD4YXNmzYoOHDh2vLli1au3atqqur1bNnT5WXl7vmjBkzRqtWrdJrr72mDRs2qLCwUH379vXqOqxJAACgkVmzZo3b50WLFqlFixbavn27rrrqKpWUlCgvL0+LFy9W9+7dJUkLFy5Uhw4dtGXLFmVlZdXqOlQSAAAw5Kt2Q2lpqduorKys1fVLSkokSfHx8ZKk7du3q7q6Wj169HDNad++vVJTU7V58+Zafy+SBAAATPmo3ZCSkiKHw+Ea06dP/8lLO51OjR49Wr/85S/VuXNnSdKRI0cUHh6uuLg4t7mJiYk6cuRIrb8W7QYAAEz56BbIgwcPym63uzZHRET85KHDhw/Xv/71L23cuNEgAM9IEgAACBB2u90tSfgp9957r1avXq333ntPrVq1cm1PSkpSVVWViouL3aoJRUVFSkpKqvX5aTcAAGCooW+BtCxL9957r5YvX6533nlHrVu3dtufmZmpJk2aaN26da5tBQUFOnDggLKzs2t9HSoJAACYauAnLg4fPlyLFy/WypUrFRsb61pn4HA4FBUVJYfDodzcXI0dO1bx8fGy2+0aMWKEsrOza31ng0SSAABAozNv3jxJ0jXXXOO2feHChRoyZIgkadasWQoJCVG/fv1UWVmpnJwczZ0716vrkCQAAGDIZlmyWXUvJXh7rFWL+ZGRkZozZ47mzJlT17BIEgAAMMYLngAAwLmESgIAAIbqcofCj48PRCQJAACYot0AAADOJVQSAAAwRLsBAAB4FqTtBpIEAAAMBWslgTUJAADAIyoJAACYot0AAADOJFBbBiZoNwAAAI+oJAAAYMqyTg6T4wMQSQIAAIa4uwEAAJxTqCQAAGCKuxsAAIAnNufJYXJ8IKLdAAAAPKKSAL+6/X/2aND/fO627eC+prqn3xV+iggw07ljkX516ydq2+aoEuK/0+RpV2vz1pQfzLD0m9s/Uq/rPlN0dLU++bS5npl3uQoP2/0WM3yAdgNQP77YE62Hfn+p63NNjc2P0QBmIiNPaN8XzfT2up9r0oT3Ttv/676fqPeNn+pPT/9CRUUxunPQh5r6yDv63b03q7o61A8Rwxe4u6GeDRkyRH369Dnj/p07d6p///5q2bKlIiIilJaWpptuukmrVq2S9aP7S9944w11795dzZo1U1RUlDIyMjR06FDt3Lmznr8F6sJZE6Jvv4lwjdLicH+HBNTZth3n6YWXL9KmLake9lq69eZdeuW1C7Tl/1K0b38zPfnUL5QQf1y/yDrY4LHCh049J8FkBKCASRLOZuXKlcrKylJZWZleeOEF7dq1S2vWrNGtt96qhx56SCUlJa65999/v/r376+LLrpIb775pgoKCrR48WKlp6drwoQJfvwWOJPk1HK9+NYG5b35vsY/9pGaJ33n75CAepGUWKb4+Art/DDJte348XB9uvtn6pDxtR8jAzwL+HZDeXm5cnNzdeONN2rZsmVu+zp06KDc3FxXJWHLli2aMWOGnn76aY0cOdI1LzU1VZmZmadVHH6osrJSlZWVrs+lpaU+/ibwpOBjh2Y93FmH9kcr/meVuv13ezUj7wMN+/Uv9N3xgP/xBLzSrFmFJKm4ONJte3FxpGsfGifaDX7y9ttv65tvvtF99913xjk228ke9iuvvKKYmBgNGzbsrPM8mT59uhwOh2ukpKSccS58Z/um5tr4jyR98Vmsdmz+mR4ecYmiY07oyuuO+Ds0AKg9ywcjAAV8krB7925JUkZGhmvbBx98oJiYGNdYvXq1a256errCwv77G+jMmTPd5v6wNfFDEyZMUElJiWscPEh/0B/Ky5roywNN1TKFlgOCz7ffnqwgxMW5Vw3i4ipc+4BAEvBJgiddunRRfn6+8vPzVV5erhMnTpxx7tChQ5Wfn6/nnntO5eXlZ2w5REREyG63uw00vMioE2rZ6riO/ofFiwg+R4pidPRopC7q8t9KWdOoKrVv9x/tKmjux8hg6lS7wWQEooBv+rZt21aSVFBQoKysLEkn/0Fv06aNx7kbN25UdXW1mjRpIkmKi4tTXFycDh061HBBo9ZyRxdo63vN9dXhKCU0r9Sge/bI6bRpw5qW/g4NqJPIyGoltzzm+pyUWKb01kd17FiEvv5PtJav6qCBt/1LhYdjdaQoRnfe/qG+OdpUm7bQ4mzUeAukf/Ts2VPx8fF64okntHz58rPOHThwoJ555hnNnTtXo0aNaqAIYSIhsVL3Tf9YdkeVSr4N17/zm2ns4K7cBolGq12bbzRj6j9cn/8nd7skae26dP159i/02rKOiow8oZHDtiomukr/3tVCD03uzjMSEJACKkkoKSlRfn6+27aEhAQtWLBA/fv314033qiRI0eqbdu2Kisr05o1ayRJoaEn/3JlZ2dr3LhxGjdunPbv36++ffsqJSVFhw8fVl5enmw2m0JCGmWHJWjNmNDF3yEAPvXRv5J0fe87zjLDppcWX6iXFl/YYDGh/gXr3Q0BlSSsX79eF198sdu23NxcLViwQJs2bdITTzyhO++8U0ePHpXD4dCll16qJUuW6KabbnLN/9Of/qTLL79c8+bN0/PPP6/jx48rMTFRV111lTZv3sxaAwCA7wXpY5lt1tkeHnAOKy0tlcPhUI/EuxUWQukbwakmpYW/QwDqzYmaCr27fbpKSkrq7RfEU/9WZF8/RWFN6n6HyonqCm1eM6leY62LgKokAADQGNFuAAAAnjmtk8Pk+ABEkgAAgKkgXZPAUn8AAOARlQQAAAzZZLgmwWeR+BZJAgAApoL0iYu0GwAAgEdUEgAAMMQtkAAAwDPubgAAAOcSKgkAABiyWZZsBosPTY6tTyQJAACYcn4/TI4PQLQbAACAR1QSAAAwRLsBAAB4FqR3N5AkAABgiicuAgCAcwmVBAAADPHERQAA4BntBgAAcC6hkgAAgCGb8+QwOT4QkSQAAGCKdgMAADiXkCQAAGDK8sHwwnvvvaebb75ZycnJstlsWrFihXs4lqVJkyapZcuWioqKUo8ePfTZZ595/bVIEgAAMHTqscwmwxvl5eW68MILNWfOHI/7Z8yYodmzZ+vZZ5/V1q1bFR0drZycHFVUVHh1HdYkAAAQIEpLS90+R0REKCIi4rR5vXr1Uq9evTyew7IsPfXUU3rooYfUu3dvSdKLL76oxMRErVixQgMGDKh1PFQSAAAwdWrhosmQlJKSIofD4RrTp0/3OpR9+/bpyJEj6tGjh2ubw+FQ165dtXnzZq/ORSUBAABTliST2xi/7zYcPHhQdrvdtdlTFeGnHDlyRJKUmJjotj0xMdG1r7ZIEgAAMOSrV0Xb7Xa3JMHfaDcAABBEkpKSJElFRUVu24uKilz7aoskAQAAU5YM1yT4LpTWrVsrKSlJ69atc20rLS3V1q1blZ2d7dW5aDcAAGCqgZ+4WFZWpj179rg+79u3T/n5+YqPj1dqaqpGjx6txx57TG3btlXr1q01ceJEJScnq0+fPl5dhyQBAIBGZtu2berWrZvr89ixYyVJgwcP1qJFi3TfffepvLxcv/vd71RcXKwrrrhCa9asUWRkpFfXIUkAAMCUU5LN8HgvXHPNNbLOUn2w2WyaMmWKpkyZYhAUSQIAAMZ8dXdDoGHhIgAA8IhKAgAApoL0VdEkCQAAmArSJIF2AwAA8IhKAgAApoK0kkCSAACAqQa+BbKhkCQAAGCIWyABAMA5hUoCAACmWJMAAAA8clqSzeAfemdgJgm0GwAAgEdUEgAAMEW7AQAAeGaYJCgwkwTaDQAAwCMqCQAAmKLdAAAAPHJaMmoZcHcDAABoTKgkAABgynKeHCbHByCSBAAATLEmAQAAeMSaBAAAcC6hkgAAgCnaDQAAwCNLhkmCzyLxKdoNAADAIyoJAACYot0AAAA8cjolGTzrwBmYz0mg3QAAADyikgAAgCnaDQAAwKMgTRJoNwAAAI+oJAAAYCpIH8tMkgAAgCHLcsoyeJOjybH1iSQBAABTlmVWDWBNAgAAaEyoJAAAYMoyXJMQoJUEkgQAAEw5nZLNYF1BgK5JoN0AAAA8opIAAIAp2g0AAMATy+mUZdBuCNRbIGk3AAAAj6gkAABginYDAADwyGlJtuBLEmg3AAAAj6gkAABgyrIkmTwnITArCSQJAAAYspyWLIN2g0WSAABAkLKcMqskcAskAABoRKgkAABgiHYDAADwLEjbDSQJZ3AqqzvhrPJzJED9qamp8HcIQL05UVMpqWF+Sz+haqNnKZ1Qte+C8SGShDM4duyYJGn91y/4ORKgHhX5OwCg/h07dkwOh6Nezh0eHq6kpCRtPPI343MlJSUpPDzcB1H5js0K1EaInzmdThUWFio2NlY2m83f4ZwTSktLlZKSooMHD8put/s7HMCn+PlueJZl6dixY0pOTlZISP2t06+oqFBVlXnVOTw8XJGRkT6IyHeoJJxBSEiIWrVq5e8wzkl2u53/E0XQ4ue7YdVXBeGHIiMjA+4fd1/hFkgAAOARSQIAAPCIJAEBIyIiQg8//LAiIiL8HQrgc/x8ozFi4SIAAPCISgIAAPCIJAEAAHhEkgAAADwiSQAAAB6RJMDnhgwZoj59+py2ff369bLZbCouLpZ08mlo8+fPV3Z2tux2u2JiYtSpUyeNGjVKe/bscTu2tLRUEydOVKdOnRQVFaWEhARddtllmjFjhr799tsG+FaAuzP9nJ+yc+dO9e/fXy1btlRERITS0tJ00003adWqVae9S+CNN95Q9+7d1axZM0VFRSkjI0NDhw7Vzp076/lbAGdHkgC/sCxLt99+u0aOHKkbbrhBb7/9tj755BPl5eUpMjJSjz32mGvu0aNHlZWVpYULF2r8+PHaunWrduzYoalTp2rnzp1avHixH78JcLqVK1cqKytLZWVleuGFF7Rr1y6tWbNGt956qx566CGVlJS45t5///3q37+/LrroIr355psqKCjQ4sWLlZ6ergkTJvjxWwA8lhl+snTpUi1ZskQrV67ULbfc4tqempqqrKwst9+0/vjHP+rAgQPavXu3kpOTXdvT0tLUs2fPgH0PO85N5eXlys3N1Y033qhly5a57evQoYNyc3NdP7NbtmzRjBkz9PTTT2vkyJGueampqcrMzORnG35HJQF+8corrygjI8MtQfihUy/VcjqdWrp0qe644w63BMHTXCAQvP322/rmm2903333nXHOqZ/ZV155RTExMRo2bNhZ5wH+QpKAerF69WrFxMS4jV69ern27969WxkZGW7HjB492jX31Mu1vv76axUXF582NzMz0zV34MCB9f+FgFravXu3JLn9zH7wwQdufxdWr17tmpuenq6wsP8WdWfOnOk294etCaChkSSgXnTr1k35+fluY8GCBWc95sEHH1R+fr4mTZqksrKys85dvny58vPzlZOTo++++86XoQM+16VLF9ffg/Lycp04ceKMc4cOHar8/Hw999xzKi8vp+UAv2JNAupFdHS02rRp47bt0KFDrj+3bdtWBQUFbvubN2+u5s2bq0WLFm7b4uLiTpubmpoqSYqNjXXdLQEEgrZt20qSCgoKlJWVJenkext+/Pfh1NyNGzequrpaTZo0kSTFxcUpLi7O7e8L4C9UEuAXAwcOVEFBgVauXHnWeSEhIbrtttv0l7/8RYWFhQ0UHVB3PXv2VHx8vJ544omfnDtw4ECVlZVp7ty5DRAZ4D0qCfCLAQMGaNmyZRowYIAmTJignJwcJSYmav/+/Vq6dKlCQ0Ndc6dNm6b169fr8ssv15QpU3TppZcqOjpaH330kTZv3qzOnTv78ZvgXFZSUqL8/Hy3bQkJCVqwYIH69++vG2+8USNHjlTbtm1VVlamNWvWSJLr5zs7O1vjxo3TuHHjtH//fvXt21cpKSk6fPiw8vLyZLPZFBLC73LwIwvwscGDB1u9e/c+bfu7775rSbK+/fZby7Isq6amxnr22Wetrl27WtHR0VZ4eLiVnp5u3X333dYnn3zidmxxcbE1YcIEq3379lZERIQVFRVldenSxZo4caL1zTffNMC3AtwNHjzYknTayM3NtSzLsj744APrV7/6ldWiRQsrLCzMSkhIsHJycqwlS5ZYTqfT7VxLly61rrnmGsvhcFhNmjSxWrVqZd1+++3Wli1b/PHVABdeFQ0AADyijgUAADwiSQAAAB6RJAAAAI9IEgAAgEckCQAAwCOSBAAA4BFJAgAA8IgkAQAAeESSAASwIUOGqE+fPq7P11xzjUaPHt3gcaxfv142m+2sL9Oy2WxasWJFrc/5yCOP6KKLLjKK64svvpDNZjvt0cgAfIMkAfDSkCFDZLPZZLPZFB4erjZt2mjKlClnff2vryxbtkyPPvporebW5h92ADgbXvAE1MH111+vhQsXqrKyUn/72980fPhwNWnSRBMmTDhtblVVlcLDw31y3fj4eJ+cBwBqg0oCUAcRERFKSkpSWlqafv/736tHjx568803Jf23RTB16lQlJycrIyNDknTw4EHddtttiouLU3x8vHr37q0vvvjCdc6amhqNHTtWcXFxSkhI0H333acfv1rlx+2GyspK3X///UpJSVFERITatGmjvLw8ffHFF+rWrZskqVmzZrLZbBoyZIgkyel0avr06WrdurWioqJ04YUX6vXXX3e7zt/+9je1a9dOUVFR6tatm1uctXX//ferXbt2atq0qdLT0zVx4kRVV1efNu+5555TSkqKmjZtqttuu00lJSVu+xcsWKAOHTooMjJS7du357XKQAMiSQB8ICoqSlVVVa7P69atU0FBgdauXavVq1erurpaOTk5io2N1fvvv69//vOfiomJ0fXXX+867s9//rMWLVqk559/Xhs3btTRo0e1fPnys173zjvv1CuvvKLZs2dr165deu655xQTE6OUlBS98cYbkqSCggIdPnxYTz/9tCRp+vTpevHFF/Xss8/q3//+t8aMGaM77rhDGzZskHQymenbt69uvvlm5efn66677tIDDzzg9X8nsbGxWrRokT755BM9/fTTmj9/vmbNmuU2Z8+ePXr11Ve1atUqrVmzRjt37tSwYcNc+19++WVNmjRJU6dO1a5duzRt2jRNnDhRL7zwgtfxAKgDP7+FEmh0fvgqbKfTaa1du9aKiIiwxo8f79qfmJhoVVZWuo556aWXrIyMDLdXBFdWVlpRUVHWW2+9ZVmWZbVs2dKaMWOGa391dbXVqlUrt9duX3311daoUaMsy7KsgoICS5K1du1aj3H++NXclmVZFRUVVtOmTa1Nmza5zc3NzbUGDhxoWZZlTZgwwerYsaPb/vvvv/+0c/2YJGv58uVn3P/kk09amZmZrs8PP/ywFRoaah06dMi17e9//7sVEhJiHT582LIsy/r5z39uLV682O08jz76qJWdnW1ZlmXt27fPkmTt3LnzjNcFUHesSQDqYPXq1YqJiVF1dbWcTqduv/12PfLII679F1xwgds6hA8//FB79uxRbGys23kqKiq0d+9elZSU6PDhw+ratatrX1hYmC699NLTWg6n5OfnKzQ0VFdffXWt496zZ4+OHz+u6667zm17VVWVLr74YknSrl273OKQpOzs7Fpf45SlS5dq9uzZ2rt3r8rKynTixAnZ7Xa3OampqTrvvPPcruN0OlVQUKDY2Fjt3btXubm5uvvuu11zTpw4IYfD4XU8ALxHkgDUQbdu3TRv3jyFh4crOTlZYWHuf5Wio6PdPpeVlSkzM1Mvv/zyaedq3rx5nWKIiory+piysjJJ0l//+le3f5ylk+ssfGXz5s0aNGiQJk+erJycHDkcDi1ZskR//vOfvY51/vz5pyUtoaGhPosVwJmRJAB1EB0drTZt2tR6/iWXXKKlS5eqRYsWp/02fUrLli21detWXXXVVZJO/sa8fft2XXLJJR7nX3DBBXI6ndqwYYN69Ohx2v5TlYyamhrXto4dOyoiIkIHDhw4YwWiQ4cOrkWYp2zZsuWnv+QPbNq0SWlpaXrwwQdd2/bv33/avAMHDqiwsFDJycmu64SEhCgjI0OJiYlKTk7W559/rkGDBnl1fQC+wcJFoAEMGjRIP/vZz9S7d2+9//772rdvn9avX6+RI0fq0KFDkqRRo0bp8ccf14oVK/Tpp59q2LBhZ33Gwfnnn6/Bgwdr6NChWrFiheucr776qiQpLS1NNptNq1ev1tdff62ysjLFxsZq/PjxGjNmjF544QXt3btXO3bs0DPPPONaDHjPPffos88+0x/+8AcVFBRo8eLFWrRokVfft23btjpw4ICWLFmivXv3avbs2R4XYUZGRmrw4MH68MMP9f7772vkyJG67bbblJSUJEmaPHmypk+frtmzZ2v37t36+OOPtXDhQs2cOdOreADUDUkC0ACaNm2q9957T6mpqerbt686dOig3NxcVVRUuCoL48aN029+8xsNHjxY2dnZio2N1a233nrW886bN0+/+tWvNGzYMLVv31533323ysvLJUnnnXeeJk+erAceeECJiYm69957JUmPPvqoJk6cqOnTp6tDhw66/vrr9de//lWtW7eWdHKdwBtvvKEVK1bowgsv1LPPPqtp06Z59X1vueUWjRkzRvfee68uuugibdq0SRMnTjxtXps2bdS3b1/dcMMN6tmzp7p06eJ2i+Ndd92lBQsWaOHChbrgggt09dVXa9GiRa5YAdQvm3WmVVEAAOCcRiUBAAB4RJIAAAA8IkkAAAAekSQAAACPSBIAAIBHJAkAAMAjkgQAAOARSQIAAPCIJAEAAHhEkgAAADwiSQAAAB79P3NSOntscKIyAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the best model on the held-out test dataset\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "test_inputs_df = test_data.drop(\"Group\")\n",
    "test_targets_df = test_data.select(\"Group\")\n",
    "X_test = preprocessor.transform(test_inputs_df)\n",
    "y_test = label_encoder.transform(test_targets_df.to_numpy().ravel())\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Balanced Accuracy on test data:\", balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred, display_labels=label_encoder.classes_\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-radiomics-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
