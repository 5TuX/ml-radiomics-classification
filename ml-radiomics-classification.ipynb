{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07663c35",
   "metadata": {},
   "source": [
    "# Introductory machine learning experiment with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f2aab3",
   "metadata": {},
   "source": [
    "## Google colab setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3182062a",
   "metadata": {},
   "source": [
    "If you are running this notebook in Google Colab, uncomment and run this cell to download and install this project's repository in the Colab runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "769c0c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Disable cell output\n",
    "# %%capture\n",
    "\n",
    "# # Download the repository from github\n",
    "# !git clone https://github.com/5TuX/ml-radiomics-classification.git\n",
    "\n",
    "# # Set working directory\n",
    "# %cd ml-radiomics-classification\n",
    "\n",
    "# # Install dependencies with uv\n",
    "# !curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "# import os\n",
    "# os.environ[\"PATH\"] = f\"/root/.cargo/bin:{os.environ['PATH']}\"\n",
    "# !uv sync"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861c267a",
   "metadata": {},
   "source": [
    "## Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163caacf",
   "metadata": {},
   "source": [
    "### The goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc137b8",
   "metadata": {},
   "source": [
    "The purpose of this tutorial is to showcase a basic machine learning training pipeline that you can apply on your own tabular datasets. \n",
    "\n",
    "Let's imagine we have a reasonably sized tabular dataset (e.g. a CSV file) where each line is a sample and each column is a feature. We want to train a model to predict one of these columns (the target feature) using the other columns (the input features)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e522698c",
   "metadata": {},
   "source": [
    "### Training machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619e9418",
   "metadata": {},
   "source": [
    "There are a lot of general approaches to machine learning:\n",
    "- Supervised learning trains models on labelled data (most common)\n",
    "- Unsupervised learning searches patterns in unlabelled data\n",
    "- Self-supervised learning uses labels automatically generated from the data itself (e.g., contrastive learning)\n",
    "- Reinforcement learning learns by interacting in an environment to maximize a reward\n",
    "- Many more learning paradigms are listed on wikipedia: https://en.wikipedia.org/wiki/Machine_learning\n",
    "\n",
    "In this notebook, we'll focus on a supervised learning classification task, which consists in predicting a class label from a set of input variables. Another common supervised machine learning task is regression, which tries to predict a continuous value. It won't be addressed here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482ca1ce",
   "metadata": {},
   "source": [
    "The Python scikit-learn library provides lots of tools to experiment with machine learning methods on our dataset. In this tutorial, we will showcase some of these tools that will help us to:\n",
    "- Split the dataset in training and test subset (testing is crucial to avoid overfitting)\n",
    "- Create a preprocessing pipeline for the data (numerical variable normalization, categorical variable one-hot encoding)\n",
    "- Leverage cross-validation to quickly compare a bunch of different models\n",
    "- Do the final training and evaluation of one selected model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40985ac",
   "metadata": {},
   "source": [
    "### Spending time with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab95cd7f",
   "metadata": {},
   "source": [
    "Playing around with AI models is only 10% of the job. The other 90% is spending time with the data to understand it and make sure what we do has a meaning. This involves loading the dataset, visualizing and exploring the data, looking at feature distributions and correlations, selecting input and target features, handling missing values, possibly creating new features... In this tutorial, we'll hide most of this part to focus on scikit-learn tools, but keep in mind that in a real-world scenario your dataset will never be ready to use for training out-of-the box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc9f59",
   "metadata": {},
   "source": [
    "A widely used Python library for handling tabular data is Pandas. In this tutorial however, we prefered to briefly showcase a more recent library named [Polars](https://github.com/pola-rs/polars). Notably, Polars prefers to use [Altair](https://github.com/vega/altair) over Matplotlib for interactive plotting and visualization. Polars provides tools to convert to Pandas format, but scikit-learn is compatible with both libraries anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a0855",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af64998",
   "metadata": {},
   "source": [
    "- This notebook is heavily inspired by Aurelien Geron's [End-to-end machine learning project](https://github.com/ageron/handson-ml3/blob/main/02_end_to_end_machine_learning_project.ipynb) notebook from his book [Hand-on machine learning with scikit-learn and Pytorch](https://www.oreilly.com/library/view/hands-on-machine-learning/9798341607972/). In this tutorial we're looking at a classification task, but his example focuses on regression. Feel free to check it out if you are interested.\n",
    "- Andrej Karpathy provides a nifty [Recipe for Training Neural Networks](https://karpathy.github.io/2019/04/25/recipe/) which gives useful guidelines for any machine learning project and points at common mistakes to avoid.\n",
    "- The CNRS has a freely accessible program called [FIDLE](https://fidle.cnrs.fr), yearly revisited, wich provides a nice entry point for anyone curious about artifical intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bfe926",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2fc1f2",
   "metadata": {},
   "source": [
    "In this notebook, we are looking at a version of the [BraTS-2020-Openradiomics](https://openradiomics.org/?page_id=1087) dataset (see [publication](https://doi.org/10.1186/s12880-025-01855-2)). \n",
    "\n",
    "It contains information of 369 adult patients with brain tumors. Each line contains around 1500 [radiomic](https://en.wikipedia.org/wiki/Radiomics) features computed from tumor segmentations of the patient's MRI scans, as well as two target variables: \n",
    "- The category of brain tumor:\n",
    "    - \"LGG\" for low-grade glioma (less aggressive tumor)\n",
    "    - \"HGG\" for high-grade glioma (more aggressive tumor)\n",
    "- Survival information (in days, provided for 236 patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eee021",
   "metadata": {},
   "source": [
    "<figure style=\"max-width: 600px; margin: auto; text-align: left;\">\n",
    "    <img src=\"https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs12880-025-01855-2/MediaObjects/12880_2025_1855_Fig1_HTML.png\">\n",
    "    <figcaption>An example BraTS 2020 image (the FLAIR sequence) and its corresponding segmentation mask. The orange area is AT (active tumor), the green area is ED (peritumoral edematous/invaded tissue), and the gray parts are NETnNCR (Union of necrotic and non-enhancing tumor)</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe1fd6",
   "metadata": {},
   "source": [
    "We will ignore the survival information entirely and try to predict the class of the tumor (LGG or HGG) with a binary classifier. We'll drop most of the radiomic feature and keep only the original ones (107 input features)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea971a4a",
   "metadata": {},
   "source": [
    "## Python imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ed3a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import re\n",
    "from itertools import groupby\n",
    "\n",
    "# Data handling imports\n",
    "import polars as pl\n",
    "\n",
    "# Scikit-learn utility imports\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "\n",
    "# Scikit-learn model imports\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Other imports\n",
    "from tabulate import tabulate  # for pretty-printing tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b208cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"dataset-path\": \"data/Radiomics_binWidth-15_ZScore_NETnNCR_T1CE.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a990b71",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b39526",
   "metadata": {},
   "source": [
    "Here we decide what columns to keep, how to handle missing values, and we put a test set aside (20% of the data) for evaluating our final model. All further data pre-processing and model training will be done on the rest of the data without ever looking at the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155778fa",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1674bbc8",
   "metadata": {},
   "source": [
    "Use Polars (you can also use Pandas) to load the dataset from the CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20253ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (369, 1720)\n"
     ]
    }
   ],
   "source": [
    "df = pl.read_csv(settings[\"dataset-path\"])\n",
    "print(\"Dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480c740b",
   "metadata": {},
   "source": [
    "### First look at the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f9b7c1",
   "metadata": {},
   "source": [
    "Look at a few examples to get an idea of the data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d521e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 1_720)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Patient_ID</th><th>Group</th><th>Group_label</th><th>binWidth</th><th>Normalization</th><th>Age</th><th>Survival_days</th><th>Extent_of_Resection</th><th>Subregion</th><th>Sequence</th><th>diagnostics_Versions_PyRadiomics</th><th>diagnostics_Versions_Numpy</th><th>diagnostics_Versions_SimpleITK</th><th>diagnostics_Versions_PyWavelet</th><th>diagnostics_Versions_Python</th><th>diagnostics_Configuration_Settings</th><th>diagnostics_Configuration_EnabledImageTypes</th><th>diagnostics_Image-original_Hash</th><th>diagnostics_Image-original_Dimensionality</th><th>diagnostics_Image-original_Spacing</th><th>diagnostics_Image-original_Size</th><th>diagnostics_Image-original_Mean</th><th>diagnostics_Image-original_Minimum</th><th>diagnostics_Image-original_Maximum</th><th>diagnostics_Mask-original_Hash</th><th>diagnostics_Mask-original_Spacing</th><th>diagnostics_Mask-original_Size</th><th>diagnostics_Mask-original_BoundingBox</th><th>diagnostics_Mask-original_VoxelNum</th><th>diagnostics_Mask-original_VolumeNum</th><th>diagnostics_Mask-original_CenterOfMassIndex</th><th>diagnostics_Mask-original_CenterOfMass</th><th>original_shape_Elongation</th><th>original_shape_Flatness</th><th>original_shape_LeastAxisLength</th><th>original_shape_MajorAxisLength</th><th>original_shape_Maximum2DDiameterColumn</th><th>&hellip;</th><th>wavelet-LLL_glrlm_GrayLevelNonUniformity</th><th>wavelet-LLL_glrlm_GrayLevelNonUniformityNormalized</th><th>wavelet-LLL_glrlm_GrayLevelVariance</th><th>wavelet-LLL_glrlm_HighGrayLevelRunEmphasis</th><th>wavelet-LLL_glrlm_LongRunEmphasis</th><th>wavelet-LLL_glrlm_LongRunHighGrayLevelEmphasis</th><th>wavelet-LLL_glrlm_LongRunLowGrayLevelEmphasis</th><th>wavelet-LLL_glrlm_LowGrayLevelRunEmphasis</th><th>wavelet-LLL_glrlm_RunEntropy</th><th>wavelet-LLL_glrlm_RunLengthNonUniformity</th><th>wavelet-LLL_glrlm_RunLengthNonUniformityNormalized</th><th>wavelet-LLL_glrlm_RunPercentage</th><th>wavelet-LLL_glrlm_RunVariance</th><th>wavelet-LLL_glrlm_ShortRunEmphasis</th><th>wavelet-LLL_glrlm_ShortRunHighGrayLevelEmphasis</th><th>wavelet-LLL_glrlm_ShortRunLowGrayLevelEmphasis</th><th>wavelet-LLL_glszm_GrayLevelNonUniformity</th><th>wavelet-LLL_glszm_GrayLevelNonUniformityNormalized</th><th>wavelet-LLL_glszm_GrayLevelVariance</th><th>wavelet-LLL_glszm_HighGrayLevelZoneEmphasis</th><th>wavelet-LLL_glszm_LargeAreaEmphasis</th><th>wavelet-LLL_glszm_LargeAreaHighGrayLevelEmphasis</th><th>wavelet-LLL_glszm_LargeAreaLowGrayLevelEmphasis</th><th>wavelet-LLL_glszm_LowGrayLevelZoneEmphasis</th><th>wavelet-LLL_glszm_SizeZoneNonUniformity</th><th>wavelet-LLL_glszm_SizeZoneNonUniformityNormalized</th><th>wavelet-LLL_glszm_SmallAreaEmphasis</th><th>wavelet-LLL_glszm_SmallAreaHighGrayLevelEmphasis</th><th>wavelet-LLL_glszm_SmallAreaLowGrayLevelEmphasis</th><th>wavelet-LLL_glszm_ZoneEntropy</th><th>wavelet-LLL_glszm_ZonePercentage</th><th>wavelet-LLL_glszm_ZoneVariance</th><th>wavelet-LLL_ngtdm_Busyness</th><th>wavelet-LLL_ngtdm_Coarseness</th><th>wavelet-LLL_ngtdm_Complexity</th><th>wavelet-LLL_ngtdm_Contrast</th><th>wavelet-LLL_ngtdm_Strength</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;BraTS20_Training_001&quot;</td><td>&quot;HGG&quot;</td><td>1</td><td>&quot;binWidth-15&quot;</td><td>&quot;ZScore&quot;</td><td>60.463</td><td>&quot;289&quot;</td><td>&quot;GTR&quot;</td><td>&quot;NETnNCR&quot;</td><td>&quot;T1CE&quot;</td><td>&quot;v3.0.1&quot;</td><td>&quot;1.20.3&quot;</td><td>&quot;2.1.1&quot;</td><td>&quot;1.1.1&quot;</td><td>&quot;3.9.7&quot;</td><td>&quot;{&#x27;minimumROIDimensions&#x27;: 2, &#x27;m…</td><td>&quot;{&#x27;Original&#x27;: {}, &#x27;Exponential&#x27;…</td><td>&quot;fcf31c6f56b4067eb28299303a0674…</td><td>&quot;3D&quot;</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>-6.4336e-16</td><td>-0.404772</td><td>11.492377</td><td>&quot;f3599f6c7ce9538e47d18beaef7292…</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>&quot;(70, 102, 41, 50, 56, 37)&quot;</td><td>15443.0</td><td>34.0</td><td>&quot;(89.23389237842387, 122.326749…</td><td>&quot;(89.23389237842387, 122.326749…</td><td>0.731829</td><td>0.41979</td><td>21.139285</td><td>50.356792</td><td>50.358713</td><td>&hellip;</td><td>2837.692308</td><td>1.0</td><td>0.0</td><td>1.0</td><td>56.108317</td><td>56.108317</td><td>56.108317</td><td>1.0</td><td>3.683174</td><td>314.441224</td><td>0.108017</td><td>0.183753</td><td>23.691856</td><td>0.28482</td><td>0.28482</td><td>0.28482</td><td>34.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>6.3840e6</td><td>6.3840e6</td><td>6.3840e6</td><td>1.0</td><td>5.470588</td><td>0.1609</td><td>0.379267</td><td>0.379267</td><td>0.379267</td><td>3.133984</td><td>0.002202</td><td>6.1777e6</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;BraTS20_Training_002&quot;</td><td>&quot;HGG&quot;</td><td>1</td><td>&quot;binWidth-15&quot;</td><td>&quot;ZScore&quot;</td><td>52.263</td><td>&quot;616&quot;</td><td>&quot;GTR&quot;</td><td>&quot;NETnNCR&quot;</td><td>&quot;T1CE&quot;</td><td>&quot;v3.0.1&quot;</td><td>&quot;1.20.3&quot;</td><td>&quot;2.1.1&quot;</td><td>&quot;1.1.1&quot;</td><td>&quot;3.9.7&quot;</td><td>&quot;{&#x27;minimumROIDimensions&#x27;: 2, &#x27;m…</td><td>&quot;{&#x27;Original&#x27;: {}, &#x27;Exponential&#x27;…</td><td>&quot;58a926796869be2fcbfafa87f1e2d3…</td><td>&quot;3D&quot;</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>7.7498e-16</td><td>-0.438949</td><td>8.906679</td><td>&quot;f6ef775f5d12edcb4e8926782d7773…</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>&quot;(67, 86, 37, 28, 32, 34)&quot;</td><td>9160.0</td><td>9.0</td><td>&quot;(77.61626637554585, 101.946397…</td><td>&quot;(77.61626637554585, 101.946397…</td><td>0.805201</td><td>0.596898</td><td>17.919111</td><td>30.020387</td><td>34.132096</td><td>&hellip;</td><td>931.230769</td><td>1.0</td><td>0.0</td><td>1.0</td><td>148.738015</td><td>148.738015</td><td>148.738015</td><td>1.0</td><td>4.063811</td><td>65.188726</td><td>0.068125</td><td>0.101663</td><td>37.847387</td><td>0.148596</td><td>0.148596</td><td>0.148596</td><td>9.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>9.1449e6</td><td>9.1449e6</td><td>9.1449e6</td><td>1.0</td><td>1.0</td><td>0.111111</td><td>0.155282</td><td>0.155282</td><td>0.155282</td><td>3.169925</td><td>0.000983</td><td>8.1090e6</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;BraTS20_Training_003&quot;</td><td>&quot;HGG&quot;</td><td>1</td><td>&quot;binWidth-15&quot;</td><td>&quot;ZScore&quot;</td><td>54.301</td><td>&quot;464&quot;</td><td>&quot;GTR&quot;</td><td>&quot;NETnNCR&quot;</td><td>&quot;T1CE&quot;</td><td>&quot;v3.0.1&quot;</td><td>&quot;1.20.3&quot;</td><td>&quot;2.1.1&quot;</td><td>&quot;1.1.1&quot;</td><td>&quot;3.9.7&quot;</td><td>&quot;{&#x27;minimumROIDimensions&#x27;: 2, &#x27;m…</td><td>&quot;{&#x27;Original&#x27;: {}, &#x27;Exponential&#x27;…</td><td>&quot;923aabc1a6c23ad6accc67bcd26fe1…</td><td>&quot;3D&quot;</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>2.7571e-16</td><td>-0.389427</td><td>11.927897</td><td>&quot;27f9116fc7420ab3c6eedf267830db…</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>&quot;(160, 149, 61, 16, 19, 18)&quot;</td><td>733.0</td><td>7.0</td><td>&quot;(168.64529331514325, 158.99317…</td><td>&quot;(168.64529331514325, 158.99317…</td><td>0.768372</td><td>0.722447</td><td>11.550058</td><td>15.987407</td><td>18.681542</td><td>&hellip;</td><td>291.153846</td><td>1.0</td><td>0.0</td><td>1.0</td><td>10.77577</td><td>10.77577</td><td>10.77577</td><td>1.0</td><td>2.387787</td><td>77.714144</td><td>0.259495</td><td>0.397209</td><td>3.934461</td><td>0.500213</td><td>0.500213</td><td>0.500213</td><td>7.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>62367.571429</td><td>62367.571429</td><td>62367.571429</td><td>1.0</td><td>1.285714</td><td>0.183673</td><td>0.298127</td><td>0.298127</td><td>0.298127</td><td>2.521641</td><td>0.00955</td><td>51402.489796</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;BraTS20_Training_004&quot;</td><td>&quot;HGG&quot;</td><td>1</td><td>&quot;binWidth-15&quot;</td><td>&quot;ZScore&quot;</td><td>39.068</td><td>&quot;788&quot;</td><td>&quot;GTR&quot;</td><td>&quot;NETnNCR&quot;</td><td>&quot;T1CE&quot;</td><td>&quot;v3.0.1&quot;</td><td>&quot;1.20.3&quot;</td><td>&quot;2.1.1&quot;</td><td>&quot;1.1.1&quot;</td><td>&quot;3.9.7&quot;</td><td>&quot;{&#x27;minimumROIDimensions&#x27;: 2, &#x27;m…</td><td>&quot;{&#x27;Original&#x27;: {}, &#x27;Exponential&#x27;…</td><td>&quot;55fa7fba043c7c44a6e842b5a586a4…</td><td>&quot;3D&quot;</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>-5.9757e-16</td><td>-0.438407</td><td>11.005426</td><td>&quot;07742fbe85b3d48e3aa5ff6ad53873…</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>&quot;(149, 150, 64, 31, 44, 44)&quot;</td><td>10902.0</td><td>37.0</td><td>&quot;(162.29728490185286, 169.57576…</td><td>&quot;(162.29728490185286, 169.57576…</td><td>0.880563</td><td>0.556199</td><td>21.603687</td><td>38.841633</td><td>42.720019</td><td>&hellip;</td><td>2986.769231</td><td>1.0</td><td>0.0</td><td>1.0</td><td>27.455009</td><td>27.455009</td><td>27.455009</td><td>1.0</td><td>3.051311</td><td>557.843589</td><td>0.182311</td><td>0.273965</td><td>13.085883</td><td>0.40605</td><td>0.40605</td><td>0.40605</td><td>37.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>3.0228e6</td><td>3.0228e6</td><td>3.0228e6</td><td>1.0</td><td>5.594595</td><td>0.151205</td><td>0.360428</td><td>0.360428</td><td>0.360428</td><td>3.230669</td><td>0.003394</td><td>2.9360e6</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;BraTS20_Training_005&quot;</td><td>&quot;HGG&quot;</td><td>1</td><td>&quot;binWidth-15&quot;</td><td>&quot;ZScore&quot;</td><td>68.493</td><td>&quot;465&quot;</td><td>&quot;GTR&quot;</td><td>&quot;NETnNCR&quot;</td><td>&quot;T1CE&quot;</td><td>&quot;v3.0.1&quot;</td><td>&quot;1.20.3&quot;</td><td>&quot;2.1.1&quot;</td><td>&quot;1.1.1&quot;</td><td>&quot;3.9.7&quot;</td><td>&quot;{&#x27;minimumROIDimensions&#x27;: 2, &#x27;m…</td><td>&quot;{&#x27;Original&#x27;: {}, &#x27;Exponential&#x27;…</td><td>&quot;6c94ee5878e0aca66cb21e828c50fe…</td><td>&quot;3D&quot;</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>-4.8643e-17</td><td>-0.416155</td><td>12.239193</td><td>&quot;5fec5dd1de3d85905a292c12f948d4…</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>&quot;(123, 157, 84, 52, 34, 42)&quot;</td><td>3624.0</td><td>37.0</td><td>&quot;(155.71136865342163, 172.22599…</td><td>&quot;(155.71136865342163, 172.22599…</td><td>0.342747</td><td>0.309231</td><td>20.04694</td><td>64.828365</td><td>60.60528</td><td>&hellip;</td><td>1608.791873</td><td>0.985289</td><td>0.007356</td><td>1.022234</td><td>8.446223</td><td>8.469023</td><td>8.440523</td><td>0.994442</td><td>2.250301</td><td>508.396876</td><td>0.305674</td><td>0.450458</td><td>3.256455</td><td>0.552665</td><td>0.574758</td><td>0.547142</td><td>30.148936</td><td>0.641467</td><td>0.179267</td><td>1.702128</td><td>168949.234043</td><td>168950.12766</td><td>168949.010638</td><td>0.824468</td><td>17.851064</td><td>0.37981</td><td>0.634417</td><td>1.288673</td><td>0.470853</td><td>2.825271</td><td>0.012969</td><td>163003.839746</td><td>2.292387</td><td>0.220302</td><td>0.002505</td><td>0.000012</td><td>0.153538</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 1_720)\n",
       "┌────────────┬───────┬────────────┬────────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ Patient_ID ┆ Group ┆ Group_labe ┆ binWidth   ┆ … ┆ wavelet-L ┆ wavelet-L ┆ wavelet-L ┆ wavelet-L │\n",
       "│ ---        ┆ ---   ┆ l          ┆ ---        ┆   ┆ LL_ngtdm_ ┆ LL_ngtdm_ ┆ LL_ngtdm_ ┆ LL_ngtdm_ │\n",
       "│ str        ┆ str   ┆ ---        ┆ str        ┆   ┆ Coarsenes ┆ Complexit ┆ Contrast  ┆ Strength  │\n",
       "│            ┆       ┆ i64        ┆            ┆   ┆ s         ┆ y         ┆ ---       ┆ ---       │\n",
       "│            ┆       ┆            ┆            ┆   ┆ ---       ┆ ---       ┆ f64       ┆ f64       │\n",
       "│            ┆       ┆            ┆            ┆   ┆ f64       ┆ f64       ┆           ┆           │\n",
       "╞════════════╪═══════╪════════════╪════════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ BraTS20_Tr ┆ HGG   ┆ 1          ┆ binWidth-1 ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ aining_001 ┆       ┆            ┆ 5          ┆   ┆           ┆           ┆           ┆           │\n",
       "│ BraTS20_Tr ┆ HGG   ┆ 1          ┆ binWidth-1 ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ aining_002 ┆       ┆            ┆ 5          ┆   ┆           ┆           ┆           ┆           │\n",
       "│ BraTS20_Tr ┆ HGG   ┆ 1          ┆ binWidth-1 ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ aining_003 ┆       ┆            ┆ 5          ┆   ┆           ┆           ┆           ┆           │\n",
       "│ BraTS20_Tr ┆ HGG   ┆ 1          ┆ binWidth-1 ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ aining_004 ┆       ┆            ┆ 5          ┆   ┆           ┆           ┆           ┆           │\n",
       "│ BraTS20_Tr ┆ HGG   ┆ 1          ┆ binWidth-1 ┆ … ┆ 0.220302  ┆ 0.002505  ┆ 0.000012  ┆ 0.153538  │\n",
       "│ aining_005 ┆       ┆            ┆ 5          ┆   ┆           ┆           ┆           ┆           │\n",
       "└────────────┴───────┴────────────┴────────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f872b20a",
   "metadata": {},
   "source": [
    "Look at basic statistics: \n",
    "- number of defined and undefined values in each column\n",
    "- means, standard deviations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6551cf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 1_721)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>Patient_ID</th><th>Group</th><th>Group_label</th><th>binWidth</th><th>Normalization</th><th>Age</th><th>Survival_days</th><th>Extent_of_Resection</th><th>Subregion</th><th>Sequence</th><th>diagnostics_Versions_PyRadiomics</th><th>diagnostics_Versions_Numpy</th><th>diagnostics_Versions_SimpleITK</th><th>diagnostics_Versions_PyWavelet</th><th>diagnostics_Versions_Python</th><th>diagnostics_Configuration_Settings</th><th>diagnostics_Configuration_EnabledImageTypes</th><th>diagnostics_Image-original_Hash</th><th>diagnostics_Image-original_Dimensionality</th><th>diagnostics_Image-original_Spacing</th><th>diagnostics_Image-original_Size</th><th>diagnostics_Image-original_Mean</th><th>diagnostics_Image-original_Minimum</th><th>diagnostics_Image-original_Maximum</th><th>diagnostics_Mask-original_Hash</th><th>diagnostics_Mask-original_Spacing</th><th>diagnostics_Mask-original_Size</th><th>diagnostics_Mask-original_BoundingBox</th><th>diagnostics_Mask-original_VoxelNum</th><th>diagnostics_Mask-original_VolumeNum</th><th>diagnostics_Mask-original_CenterOfMassIndex</th><th>diagnostics_Mask-original_CenterOfMass</th><th>original_shape_Elongation</th><th>original_shape_Flatness</th><th>original_shape_LeastAxisLength</th><th>original_shape_MajorAxisLength</th><th>&hellip;</th><th>wavelet-LLL_glrlm_GrayLevelNonUniformity</th><th>wavelet-LLL_glrlm_GrayLevelNonUniformityNormalized</th><th>wavelet-LLL_glrlm_GrayLevelVariance</th><th>wavelet-LLL_glrlm_HighGrayLevelRunEmphasis</th><th>wavelet-LLL_glrlm_LongRunEmphasis</th><th>wavelet-LLL_glrlm_LongRunHighGrayLevelEmphasis</th><th>wavelet-LLL_glrlm_LongRunLowGrayLevelEmphasis</th><th>wavelet-LLL_glrlm_LowGrayLevelRunEmphasis</th><th>wavelet-LLL_glrlm_RunEntropy</th><th>wavelet-LLL_glrlm_RunLengthNonUniformity</th><th>wavelet-LLL_glrlm_RunLengthNonUniformityNormalized</th><th>wavelet-LLL_glrlm_RunPercentage</th><th>wavelet-LLL_glrlm_RunVariance</th><th>wavelet-LLL_glrlm_ShortRunEmphasis</th><th>wavelet-LLL_glrlm_ShortRunHighGrayLevelEmphasis</th><th>wavelet-LLL_glrlm_ShortRunLowGrayLevelEmphasis</th><th>wavelet-LLL_glszm_GrayLevelNonUniformity</th><th>wavelet-LLL_glszm_GrayLevelNonUniformityNormalized</th><th>wavelet-LLL_glszm_GrayLevelVariance</th><th>wavelet-LLL_glszm_HighGrayLevelZoneEmphasis</th><th>wavelet-LLL_glszm_LargeAreaEmphasis</th><th>wavelet-LLL_glszm_LargeAreaHighGrayLevelEmphasis</th><th>wavelet-LLL_glszm_LargeAreaLowGrayLevelEmphasis</th><th>wavelet-LLL_glszm_LowGrayLevelZoneEmphasis</th><th>wavelet-LLL_glszm_SizeZoneNonUniformity</th><th>wavelet-LLL_glszm_SizeZoneNonUniformityNormalized</th><th>wavelet-LLL_glszm_SmallAreaEmphasis</th><th>wavelet-LLL_glszm_SmallAreaHighGrayLevelEmphasis</th><th>wavelet-LLL_glszm_SmallAreaLowGrayLevelEmphasis</th><th>wavelet-LLL_glszm_ZoneEntropy</th><th>wavelet-LLL_glszm_ZonePercentage</th><th>wavelet-LLL_glszm_ZoneVariance</th><th>wavelet-LLL_ngtdm_Busyness</th><th>wavelet-LLL_ngtdm_Coarseness</th><th>wavelet-LLL_ngtdm_Complexity</th><th>wavelet-LLL_ngtdm_Contrast</th><th>wavelet-LLL_ngtdm_Strength</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;369&quot;</td><td>&quot;369&quot;</td><td>369.0</td><td>&quot;369&quot;</td><td>&quot;369&quot;</td><td>236.0</td><td>&quot;236&quot;</td><td>&quot;129&quot;</td><td>&quot;369&quot;</td><td>&quot;369&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>368.0</td><td>368.0</td><td>368.0</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>368.0</td><td>368.0</td><td>&quot;368&quot;</td><td>&quot;368&quot;</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>&hellip;</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>0.0</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>133.0</td><td>&quot;133&quot;</td><td>&quot;240&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>1.0</td><td>1.0</td><td>1.0</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>1.0</td><td>1.0</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>&hellip;</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>null</td><td>0.794038</td><td>null</td><td>null</td><td>61.223203</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-1.3152e-17</td><td>-0.419098</td><td>10.345853</td><td>null</td><td>null</td><td>null</td><td>null</td><td>22179.336957</td><td>33.103261</td><td>null</td><td>null</td><td>0.723042</td><td>0.555079</td><td>24.485618</td><td>45.730192</td><td>&hellip;</td><td>2963.677357</td><td>0.994174</td><td>0.002913</td><td>1.352574</td><td>101.552119</td><td>169.249656</td><td>84.627828</td><td>0.911909</td><td>3.333423</td><td>422.079383</td><td>0.182812</td><td>0.256798</td><td>38.762551</td><td>0.368986</td><td>0.469273</td><td>0.343959</td><td>33.113254</td><td>0.945609</td><td>0.030401</td><td>1.31665</td><td>3.7638e8</td><td>4.8846e8</td><td>3.4836e8</td><td>0.924942</td><td>9.287271</td><td>0.324657</td><td>0.428875</td><td>0.594118</td><td>0.38953</td><td>2.38682</td><td>0.009033</td><td>1.0555e8</td><td>9.729446</td><td>760869.714043</td><td>0.0013</td><td>0.000169</td><td>0.100075</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>null</td><td>0.404952</td><td>null</td><td>null</td><td>11.874114</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>4.3709e-16</td><td>0.024681</td><td>2.671905</td><td>null</td><td>null</td><td>null</td><td>null</td><td>29878.14703</td><td>35.848002</td><td>null</td><td>null</td><td>0.155188</td><td>0.147826</td><td>10.167512</td><td>19.301596</td><td>&hellip;</td><td>2666.229821</td><td>0.037481</td><td>0.018741</td><td>0.954343</td><td>144.981048</td><td>351.244154</td><td>128.949013</td><td>0.23844</td><td>1.007408</td><td>403.022144</td><td>0.133684</td><td>0.167152</td><td>49.280637</td><td>0.171601</td><td>0.335728</td><td>0.190336</td><td>35.204095</td><td>0.129886</td><td>0.082513</td><td>0.822908</td><td>2.0864e9</td><td>2.3183e9</td><td>2.0745e9</td><td>0.190537</td><td>10.806416</td><td>0.216648</td><td>0.185001</td><td>0.522212</td><td>0.186838</td><td>0.913765</td><td>0.022325</td><td>5.4160e8</td><td>120.791894</td><td>427133.013751</td><td>0.010525</td><td>0.002248</td><td>0.280222</td></tr><tr><td>&quot;min&quot;</td><td>&quot;BraTS20_Training_001&quot;</td><td>&quot;HGG&quot;</td><td>0.0</td><td>&quot;binWidth-15&quot;</td><td>&quot;ZScore&quot;</td><td>18.975</td><td>&quot;1020&quot;</td><td>&quot;GTR&quot;</td><td>&quot;NETnNCR&quot;</td><td>&quot;T1CE&quot;</td><td>&quot;v3.0.1&quot;</td><td>&quot;1.20.3&quot;</td><td>&quot;2.1.1&quot;</td><td>&quot;1.1.1&quot;</td><td>&quot;3.9.7&quot;</td><td>&quot;{&#x27;minimumROIDimensions&#x27;: 2, &#x27;m…</td><td>&quot;{&#x27;Original&#x27;: {}, &#x27;Exponential&#x27;…</td><td>&quot;00d17d31c60689868bffb781d60587…</td><td>&quot;3D&quot;</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>-1.0822e-15</td><td>-0.50596</td><td>5.281236</td><td>&quot;0025e0bf9a63fc731cbd4286d5090c…</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>&quot;(100, 122, 78, 57, 54, 40)&quot;</td><td>47.0</td><td>1.0</td><td>&quot;(100.07977976897334, 145.51592…</td><td>&quot;(100.07977976897334, 145.51592…</td><td>0.222498</td><td>0.124907</td><td>3.738339</td><td>7.287142</td><td>&hellip;</td><td>24.230769</td><td>0.51188</td><td>0.0</td><td>1.0</td><td>1.401858</td><td>1.401858</td><td>1.011264</td><td>0.249277</td><td>0.463787</td><td>10.058603</td><td>0.025891</td><td>0.042804</td><td>0.16028</td><td>0.049052</td><td>0.049052</td><td>0.021336</td><td>1.0</td><td>0.333333</td><td>0.0</td><td>1.0</td><td>46.769231</td><td>46.769231</td><td>46.769231</td><td>0.252768</td><td>1.0</td><td>0.080332</td><td>4.0048e-11</td><td>4.0048e-11</td><td>4.0048e-11</td><td>-3.2034e-16</td><td>0.000006</td><td>0.0</td><td>0.0</td><td>0.000213</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>54.279</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-3.4967e-16</td><td>-0.434824</td><td>8.488869</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3916.0</td><td>8.0</td><td>null</td><td>null</td><td>0.634073</td><td>0.464006</td><td>17.272473</td><td>33.002982</td><td>&hellip;</td><td>1073.153846</td><td>1.0</td><td>0.0</td><td>1.0</td><td>17.366738</td><td>17.480936</td><td>16.36676</td><td>1.0</td><td>2.708348</td><td>139.166628</td><td>0.090103</td><td>0.13737</td><td>7.674577</td><td>0.248304</td><td>0.279907</td><td>0.189201</td><td>8.285714</td><td>1.0</td><td>0.0</td><td>1.0</td><td>461810.015625</td><td>502626.625</td><td>442701.042373</td><td>1.0</td><td>2.142857</td><td>0.194471</td><td>0.337449</td><td>0.349895</td><td>0.284439</td><td>2.034941</td><td>0.000739</td><td>202644.637755</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>61.526</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-2.6079e-17</td><td>-0.419837</td><td>9.997395</td><td>null</td><td>null</td><td>null</td><td>null</td><td>10590.0</td><td>22.0</td><td>null</td><td>null</td><td>0.745096</td><td>0.575729</td><td>23.508105</td><td>43.981132</td><td>&hellip;</td><td>2347.154719</td><td>1.0</td><td>0.0</td><td>1.0</td><td>43.578971</td><td>46.046788</td><td>37.590433</td><td>1.0</td><td>3.366516</td><td>310.531785</td><td>0.15146</td><td>0.216342</td><td>20.198637</td><td>0.362393</td><td>0.393413</td><td>0.341103</td><td>22.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>4.2532e6</td><td>4.6091e6</td><td>3.8849e6</td><td>1.0</td><td>5.625</td><td>0.273288</td><td>0.471941</td><td>0.5</td><td>0.420159</td><td>2.535858</td><td>0.00305</td><td>2.0973e6</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>69.178</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3.1513e-16</td><td>-0.404016</td><td>12.003048</td><td>null</td><td>null</td><td>null</td><td>null</td><td>25394.0</td><td>46.0</td><td>null</td><td>null</td><td>0.841307</td><td>0.662864</td><td>30.729417</td><td>55.860815</td><td>&hellip;</td><td>4221.153846</td><td>1.0</td><td>0.0</td><td>1.0</td><td>112.832558</td><td>139.451056</td><td>98.480431</td><td>1.0</td><td>4.035562</td><td>568.203129</td><td>0.232698</td><td>0.327519</td><td>49.737264</td><td>0.472026</td><td>0.540567</td><td>0.469102</td><td>44.166667</td><td>1.0</td><td>0.0</td><td>1.0</td><td>2.9597e7</td><td>4.0328e7</td><td>2.7477e7</td><td>1.0</td><td>12.322034</td><td>0.346939</td><td>0.553092</td><td>0.610795</td><td>0.530467</td><td>2.977079</td><td>0.007737</td><td>1.5137e7</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;max&quot;</td><td>&quot;BraTS20_Training_369&quot;</td><td>&quot;LGG&quot;</td><td>1.0</td><td>&quot;binWidth-15&quot;</td><td>&quot;ZScore&quot;</td><td>86.652</td><td>&quot;ALIVE (361 days later)&quot;</td><td>&quot;STR&quot;</td><td>&quot;NETnNCR&quot;</td><td>&quot;T1CE&quot;</td><td>&quot;v3.0.1&quot;</td><td>&quot;1.20.3&quot;</td><td>&quot;2.1.1&quot;</td><td>&quot;1.1.1&quot;</td><td>&quot;3.9.7&quot;</td><td>&quot;{&#x27;minimumROIDimensions&#x27;: 2, &#x27;m…</td><td>&quot;{&#x27;Original&#x27;: {}, &#x27;Exponential&#x27;…</td><td>&quot;feca6e10bcc8b3b7a9097190e4cc2c…</td><td>&quot;3D&quot;</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>1.0307e-15</td><td>-0.331704</td><td>35.951043</td><td>&quot;fdf0ff3c0badd2e8a8a0881244d27f…</td><td>&quot;(1.0, 1.0, 1.0)&quot;</td><td>&quot;(240, 240, 155)&quot;</td><td>&quot;(99, 84, 72, 44, 51, 50)&quot;</td><td>189152.0</td><td>270.0</td><td>&quot;(99.95001372906317, 88.9456828…</td><td>&quot;(99.95001372906317, 88.9456828…</td><td>0.984177</td><td>0.878147</td><td>59.587263</td><td>171.979417</td><td>&hellip;</td><td>16845.846154</td><td>1.0</td><td>0.24406</td><td>4.058931</td><td>879.823903</td><td>2593.162303</td><td>879.823903</td><td>1.0</td><td>5.492313</td><td>3019.874758</td><td>0.835281</td><td>0.898687</td><td>299.155169</td><td>0.929974</td><td>2.792085</td><td>0.929974</td><td>269.00738</td><td>1.0</td><td>0.734375</td><td>6.375</td><td>2.4970e10</td><td>2.4970e10</td><td>2.4970e10</td><td>1.0</td><td>75.723247</td><td>1.0</td><td>0.805556</td><td>3.087144</td><td>0.805556</td><td>4.384792</td><td>0.216667</td><td>7.9505e9</td><td>1937.165966</td><td>1e6</td><td>0.163813</td><td>0.037715</td><td>1.833333</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 1_721)\n",
       "┌────────────┬────────────┬───────┬────────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ statistic  ┆ Patient_ID ┆ Group ┆ Group_labe ┆ … ┆ wavelet-L ┆ wavelet-L ┆ wavelet-L ┆ wavelet-L │\n",
       "│ ---        ┆ ---        ┆ ---   ┆ l          ┆   ┆ LL_ngtdm_ ┆ LL_ngtdm_ ┆ LL_ngtdm_ ┆ LL_ngtdm_ │\n",
       "│ str        ┆ str        ┆ str   ┆ ---        ┆   ┆ Coarsenes ┆ Complexit ┆ Contrast  ┆ Strength  │\n",
       "│            ┆            ┆       ┆ f64        ┆   ┆ s         ┆ y         ┆ ---       ┆ ---       │\n",
       "│            ┆            ┆       ┆            ┆   ┆ ---       ┆ ---       ┆ f64       ┆ f64       │\n",
       "│            ┆            ┆       ┆            ┆   ┆ f64       ┆ f64       ┆           ┆           │\n",
       "╞════════════╪════════════╪═══════╪════════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ count      ┆ 369        ┆ 369   ┆ 369.0      ┆ … ┆ 368.0     ┆ 368.0     ┆ 368.0     ┆ 368.0     │\n",
       "│ null_count ┆ 0          ┆ 0     ┆ 0.0        ┆ … ┆ 1.0       ┆ 1.0       ┆ 1.0       ┆ 1.0       │\n",
       "│ mean       ┆ null       ┆ null  ┆ 0.794038   ┆ … ┆ 760869.71 ┆ 0.0013    ┆ 0.000169  ┆ 0.100075  │\n",
       "│            ┆            ┆       ┆            ┆   ┆ 4043      ┆           ┆           ┆           │\n",
       "│ std        ┆ null       ┆ null  ┆ 0.404952   ┆ … ┆ 427133.01 ┆ 0.010525  ┆ 0.002248  ┆ 0.280222  │\n",
       "│            ┆            ┆       ┆            ┆   ┆ 3751      ┆           ┆           ┆           │\n",
       "│ min        ┆ BraTS20_Tr ┆ HGG   ┆ 0.0        ┆ … ┆ 0.000213  ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│            ┆ aining_001 ┆       ┆            ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 25%        ┆ null       ┆ null  ┆ 1.0        ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ 50%        ┆ null       ┆ null  ┆ 1.0        ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ 75%        ┆ null       ┆ null  ┆ 1.0        ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ max        ┆ BraTS20_Tr ┆ LGG   ┆ 1.0        ┆ … ┆ 1e6       ┆ 0.163813  ┆ 0.037715  ┆ 1.833333  │\n",
       "│            ┆ aining_369 ┆       ┆            ┆   ┆           ┆           ┆           ┆           │\n",
       "└────────────┴────────────┴───────┴────────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f8e771",
   "metadata": {},
   "source": [
    "### Choosing columns to keep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863b0dd7",
   "metadata": {},
   "source": [
    "#### Understanding the structure of the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac4741f",
   "metadata": {},
   "source": [
    "There is a huge number of columns. Let's quickly explore the structure of column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b5c22f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1720 columns in total.\n",
      "\n",
      "Patient\n",
      "\t-> ['Patient_ID']\n",
      "Group\n",
      "\t -> [''] \n",
      "\tlabel -> [''] \n",
      "binWidth\n",
      "\t-> ['binWidth']\n",
      "Normalization\n",
      "\t-> ['Normalization']\n",
      "Age\n",
      "\t-> ['Age']\n",
      "Survival\n",
      "\t-> ['Survival_days']\n",
      "Extent\n",
      "\t-> ['Extent_of_Resection']\n",
      "Subregion\n",
      "\t-> ['Subregion']\n",
      "Sequence\n",
      "\t-> ['Sequence']\n",
      "diagnostics\n",
      "\tVersions -> ['PyRadiomics', 'Numpy', 'SimpleITK'] ... (5 total)\n",
      "\tConfiguration -> ['Settings', 'EnabledImageTypes'] \n",
      "\tImage-original -> ['Hash', 'Dimensionality', 'Spacing'] ... (7 total)\n",
      "\tMask-original -> ['Hash', 'Spacing', 'Size'] ... (8 total)\n",
      "original\n",
      "\tshape -> ['Elongation', 'Flatness', 'LeastAxisLength'] ... (14 total)\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "exponential\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "gradient\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "lbp-2D\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "lbp-3D-m1\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "lbp-3D-m2\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "lbp-3D-k\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "logarithm\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "square\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "squareroot\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "wavelet-LLH\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "wavelet-LHL\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "wavelet-LHH\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "wavelet-HLL\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "wavelet-HLH\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "wavelet-HHL\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "wavelet-HHH\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n",
      "wavelet-LLL\n",
      "\tfirstorder -> ['10Percentile', '90Percentile', 'Energy'] ... (18 total)\n",
      "\tglcm -> ['Autocorrelation', 'ClusterProminence', 'ClusterShade'] ... (24 total)\n",
      "\tgldm -> ['DependenceEntropy', 'DependenceNonUniformity', 'DependenceNonUniformityNormalized'] ... (14 total)\n",
      "\tglrlm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tglszm -> ['GrayLevelNonUniformity', 'GrayLevelNonUniformityNormalized', 'GrayLevelVariance'] ... (16 total)\n",
      "\tngtdm -> ['Busyness', 'Coarseness', 'Complexity'] ... (5 total)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(df.columns)} columns in total.\\n\")\n",
    "\n",
    "\n",
    "def key(colname):\n",
    "    return colname.split(\"_\")[0]\n",
    "\n",
    "\n",
    "for column_group, columns in groupby(df.columns, key):\n",
    "    print(column_group)\n",
    "    columns = list(columns)\n",
    "    if len(columns) == 1:\n",
    "        print(f\"\\t-> {columns}\")\n",
    "        continue\n",
    "    columns = [colname[len(column_group) + 1 :] for colname in columns]\n",
    "    for column_subgroup, subcolumns in groupby(columns, key):\n",
    "        maxlen, suffix = 3, \"\"\n",
    "        subcolumns = [colname[len(column_subgroup) + 1 :] for colname in subcolumns]\n",
    "        if (lensubcols := len(subcolumns)) > maxlen:\n",
    "            subcolumns = subcolumns[:maxlen]\n",
    "            suffix = f\"... ({lensubcols} total)\"\n",
    "        print(f\"\\t{column_subgroup} -> {subcolumns} {suffix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5b1222",
   "metadata": {},
   "source": [
    "#### Selecting wanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e3e7575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can either specify columns to drop or to keep.\n",
    "# In this case, there are 1720 columns, so it's easier to specify which ones to keep.\n",
    "\n",
    "# Target variables: ignore Survival_days (too many missing values)\n",
    "targets = [\"Group\"]\n",
    "\n",
    "# Clinical inputs: ignore Age and Extent_of_Resection (too many missing values):\n",
    "inputs_clinical = []\n",
    "\n",
    "# Radiomic inputs: keep only basic radiomic features and ignore the rest:\n",
    "inputs_radiomics = [col for col in df.columns if col.startswith(\"original_\")]\n",
    "df = df.select(targets + inputs_clinical + inputs_radiomics).rename(\n",
    "    {col: col[9:] for col in inputs_radiomics}\n",
    ")\n",
    "\n",
    "# By doing this selection, we also dropped the following metadata columns:\n",
    "# Patient_ID, Group_label, binWidth, Normalization, Subregion, Sequence\n",
    "# As well as all diagnostics_... columns (give information about radiomic feature extraction process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8a2296",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d2fa9b",
   "metadata": {},
   "source": [
    "Handle missing values: in this case there is only one row with missing data (as shown by the `df.describe` output above).\n",
    "\n",
    "Generally, there are different strategies to handle missing data:\n",
    "- Dropping all rows with missing values (like we do here since there is only one)\n",
    "- Dropping columns with missing values (after checking there is almost no data in them)\n",
    "- Filling missing values, e.g. with the median (imputation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58638f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after dropping nulls: (368, 108)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_nulls()\n",
    "print(\"Dataset shape after dropping nulls:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b6712c",
   "metadata": {},
   "source": [
    "### Looking at the prepared data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957fd0ab",
   "metadata": {},
   "source": [
    "Look again at a few examples and basic statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9628e6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 108)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Group</th><th>shape_Elongation</th><th>shape_Flatness</th><th>shape_LeastAxisLength</th><th>shape_MajorAxisLength</th><th>shape_Maximum2DDiameterColumn</th><th>shape_Maximum2DDiameterRow</th><th>shape_Maximum2DDiameterSlice</th><th>shape_Maximum3DDiameter</th><th>shape_MeshVolume</th><th>shape_MinorAxisLength</th><th>shape_Sphericity</th><th>shape_SurfaceArea</th><th>shape_SurfaceVolumeRatio</th><th>shape_VoxelVolume</th><th>firstorder_10Percentile</th><th>firstorder_90Percentile</th><th>firstorder_Energy</th><th>firstorder_Entropy</th><th>firstorder_InterquartileRange</th><th>firstorder_Kurtosis</th><th>firstorder_Maximum</th><th>firstorder_MeanAbsoluteDeviation</th><th>firstorder_Mean</th><th>firstorder_Median</th><th>firstorder_Minimum</th><th>firstorder_Range</th><th>firstorder_RobustMeanAbsoluteDeviation</th><th>firstorder_RootMeanSquared</th><th>firstorder_Skewness</th><th>firstorder_TotalEnergy</th><th>firstorder_Uniformity</th><th>firstorder_Variance</th><th>glcm_Autocorrelation</th><th>glcm_ClusterProminence</th><th>glcm_ClusterShade</th><th>glcm_ClusterTendency</th><th>&hellip;</th><th>glrlm_GrayLevelNonUniformity</th><th>glrlm_GrayLevelNonUniformityNormalized</th><th>glrlm_GrayLevelVariance</th><th>glrlm_HighGrayLevelRunEmphasis</th><th>glrlm_LongRunEmphasis</th><th>glrlm_LongRunHighGrayLevelEmphasis</th><th>glrlm_LongRunLowGrayLevelEmphasis</th><th>glrlm_LowGrayLevelRunEmphasis</th><th>glrlm_RunEntropy</th><th>glrlm_RunLengthNonUniformity</th><th>glrlm_RunLengthNonUniformityNormalized</th><th>glrlm_RunPercentage</th><th>glrlm_RunVariance</th><th>glrlm_ShortRunEmphasis</th><th>glrlm_ShortRunHighGrayLevelEmphasis</th><th>glrlm_ShortRunLowGrayLevelEmphasis</th><th>glszm_GrayLevelNonUniformity</th><th>glszm_GrayLevelNonUniformityNormalized</th><th>glszm_GrayLevelVariance</th><th>glszm_HighGrayLevelZoneEmphasis</th><th>glszm_LargeAreaEmphasis</th><th>glszm_LargeAreaHighGrayLevelEmphasis</th><th>glszm_LargeAreaLowGrayLevelEmphasis</th><th>glszm_LowGrayLevelZoneEmphasis</th><th>glszm_SizeZoneNonUniformity</th><th>glszm_SizeZoneNonUniformityNormalized</th><th>glszm_SmallAreaEmphasis</th><th>glszm_SmallAreaHighGrayLevelEmphasis</th><th>glszm_SmallAreaLowGrayLevelEmphasis</th><th>glszm_ZoneEntropy</th><th>glszm_ZonePercentage</th><th>glszm_ZoneVariance</th><th>ngtdm_Busyness</th><th>ngtdm_Coarseness</th><th>ngtdm_Complexity</th><th>ngtdm_Contrast</th><th>ngtdm_Strength</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;HGG&quot;</td><td>0.731829</td><td>0.41979</td><td>21.139285</td><td>50.356792</td><td>50.358713</td><td>59.539903</td><td>50.990195</td><td>63.85922</td><td>15226.333333</td><td>36.852581</td><td>0.333812</td><td>8899.775397</td><td>0.584499</td><td>15443.0</td><td>0.891341</td><td>2.406696</td><td>43805.647206</td><td>0.000994</td><td>0.76735</td><td>3.905945</td><td>4.857057</td><td>0.476079</td><td>1.57019</td><td>1.471689</td><td>-0.037217</td><td>4.894274</td><td>0.322622</td><td>1.684222</td><td>0.845454</td><td>43805.647206</td><td>0.99987</td><td>0.371107</td><td>3.999682</td><td>0.000159</td><td>-0.000159</td><td>0.000159</td><td>&hellip;</td><td>2837.693033</td><td>0.999275</td><td>0.000362</td><td>3.998912</td><td>56.052892</td><td>224.210478</td><td>14.013495</td><td>0.250272</td><td>3.685716</td><td>315.192629</td><td>0.108203</td><td>0.183882</td><td>23.686554</td><td>0.285304</td><td>1.140127</td><td>0.071598</td><td>33.057143</td><td>0.94449</td><td>0.027755</td><td>3.914286</td><td>6.2008e6</td><td>2.4803e7</td><td>1.5502e6</td><td>0.271429</td><td>5.971429</td><td>0.170612</td><td>0.397002</td><td>1.502295</td><td>0.120679</td><td>3.231618</td><td>0.002266</td><td>6.0061e6</td><td>0.300826</td><td>0.831125</td><td>0.000156</td><td>9.2377e-9</td><td>0.90777</td></tr><tr><td>&quot;HGG&quot;</td><td>0.805201</td><td>0.596898</td><td>17.919111</td><td>30.020387</td><td>34.132096</td><td>34.525353</td><td>31.144823</td><td>35.496479</td><td>9073.541667</td><td>24.172434</td><td>0.73062</td><td>2879.455924</td><td>0.317346</td><td>9160.0</td><td>0.511066</td><td>1.20927</td><td>7040.180407</td><td>-3.2034e-16</td><td>0.263257</td><td>10.595436</td><td>3.429786</td><td>0.233776</td><td>0.801736</td><td>0.711371</td><td>0.013167</td><td>3.416619</td><td>0.120232</td><td>0.876686</td><td>2.380337</td><td>7040.180407</td><td>1.0</td><td>0.125799</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>931.230769</td><td>1.0</td><td>0.0</td><td>1.0</td><td>148.738015</td><td>148.738015</td><td>148.738015</td><td>1.0</td><td>4.063811</td><td>65.188726</td><td>0.068125</td><td>0.101663</td><td>37.847387</td><td>0.148596</td><td>0.148596</td><td>0.148596</td><td>9.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>9.1449e6</td><td>9.1449e6</td><td>9.1449e6</td><td>1.0</td><td>1.0</td><td>0.111111</td><td>0.155282</td><td>0.155282</td><td>0.155282</td><td>3.169925</td><td>0.000983</td><td>8.1090e6</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;HGG&quot;</td><td>0.768372</td><td>0.722447</td><td>11.550058</td><td>15.987407</td><td>18.681542</td><td>18.384776</td><td>18.681542</td><td>22.135944</td><td>684.083333</td><td>12.284284</td><td>0.406249</td><td>924.196735</td><td>1.351</td><td>733.0</td><td>1.441948</td><td>3.355092</td><td>4630.563368</td><td>-3.2034e-16</td><td>1.090258</td><td>2.45011</td><td>4.360985</td><td>0.592579</td><td>2.407835</td><td>2.420584</td><td>0.713811</td><td>3.647174</td><td>0.43292</td><td>2.513419</td><td>0.055125</td><td>4630.563368</td><td>1.0</td><td>0.519605</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>291.153846</td><td>1.0</td><td>0.0</td><td>1.0</td><td>10.77577</td><td>10.77577</td><td>10.77577</td><td>1.0</td><td>2.387787</td><td>77.714144</td><td>0.259495</td><td>0.397209</td><td>3.934461</td><td>0.500213</td><td>0.500213</td><td>0.500213</td><td>7.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>62367.571429</td><td>62367.571429</td><td>62367.571429</td><td>1.0</td><td>1.285714</td><td>0.183673</td><td>0.298127</td><td>0.298127</td><td>0.298127</td><td>2.521641</td><td>0.00955</td><td>51402.489796</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;HGG&quot;</td><td>0.880563</td><td>0.556199</td><td>21.603687</td><td>38.841633</td><td>42.720019</td><td>46.238512</td><td>44.384682</td><td>46.914816</td><td>10608.041667</td><td>34.202508</td><td>0.246069</td><td>9488.192833</td><td>0.894434</td><td>10902.0</td><td>0.862828</td><td>2.445411</td><td>32015.142395</td><td>-3.2034e-16</td><td>0.977685</td><td>2.574108</td><td>4.196802</td><td>0.524396</td><td>1.598139</td><td>1.523996</td><td>0.342334</td><td>3.854469</td><td>0.404497</td><td>1.71366</td><td>0.501066</td><td>32015.142395</td><td>1.0</td><td>0.382583</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>2986.769231</td><td>1.0</td><td>0.0</td><td>1.0</td><td>27.455009</td><td>27.455009</td><td>27.455009</td><td>1.0</td><td>3.051311</td><td>557.843589</td><td>0.182311</td><td>0.273965</td><td>13.085883</td><td>0.40605</td><td>0.40605</td><td>0.40605</td><td>37.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>3.0228e6</td><td>3.0228e6</td><td>3.0228e6</td><td>1.0</td><td>5.594595</td><td>0.151205</td><td>0.360428</td><td>0.360428</td><td>0.360428</td><td>3.230669</td><td>0.003394</td><td>2.9360e6</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;HGG&quot;</td><td>0.342747</td><td>0.309231</td><td>20.04694</td><td>64.828365</td><td>60.60528</td><td>32.280025</td><td>48.754487</td><td>61.43289</td><td>3209.833333</td><td>22.219752</td><td>0.201071</td><td>5233.470765</td><td>1.630449</td><td>3624.0</td><td>1.890351</td><td>3.694297</td><td>29902.191747</td><td>-3.2034e-16</td><td>0.940189</td><td>3.291029</td><td>5.82697</td><td>0.555445</td><td>2.785681</td><td>2.769665</td><td>0.639021</td><td>5.187949</td><td>0.391193</td><td>2.872483</td><td>0.463672</td><td>29902.191747</td><td>1.0</td><td>0.491141</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>1629.384615</td><td>1.0</td><td>0.0</td><td>1.0</td><td>8.473932</td><td>8.473932</td><td>8.473932</td><td>1.0</td><td>2.199209</td><td>505.603602</td><td>0.304522</td><td>0.449609</td><td>3.261904</td><td>0.551107</td><td>0.551107</td><td>0.551107</td><td>37.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>216977.945946</td><td>216977.945946</td><td>216977.945946</td><td>1.0</td><td>12.027027</td><td>0.325055</td><td>0.582357</td><td>0.582357</td><td>0.582357</td><td>2.332735</td><td>0.01021</td><td>207384.537619</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 108)\n",
       "┌───────┬────────────┬────────────┬────────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ Group ┆ shape_Elon ┆ shape_Flat ┆ shape_Leas ┆ … ┆ ngtdm_Coa ┆ ngtdm_Com ┆ ngtdm_Con ┆ ngtdm_Str │\n",
       "│ ---   ┆ gation     ┆ ness       ┆ tAxisLengt ┆   ┆ rseness   ┆ plexity   ┆ trast     ┆ ength     │\n",
       "│ str   ┆ ---        ┆ ---        ┆ h          ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│       ┆ f64        ┆ f64        ┆ ---        ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "│       ┆            ┆            ┆ f64        ┆   ┆           ┆           ┆           ┆           │\n",
       "╞═══════╪════════════╪════════════╪════════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ HGG   ┆ 0.731829   ┆ 0.41979    ┆ 21.139285  ┆ … ┆ 0.831125  ┆ 0.000156  ┆ 9.2377e-9 ┆ 0.90777   │\n",
       "│ HGG   ┆ 0.805201   ┆ 0.596898   ┆ 17.919111  ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ HGG   ┆ 0.768372   ┆ 0.722447   ┆ 11.550058  ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ HGG   ┆ 0.880563   ┆ 0.556199   ┆ 21.603687  ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ HGG   ┆ 0.342747   ┆ 0.309231   ┆ 20.04694   ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "└───────┴────────────┴────────────┴────────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac56c3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 109)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>Group</th><th>shape_Elongation</th><th>shape_Flatness</th><th>shape_LeastAxisLength</th><th>shape_MajorAxisLength</th><th>shape_Maximum2DDiameterColumn</th><th>shape_Maximum2DDiameterRow</th><th>shape_Maximum2DDiameterSlice</th><th>shape_Maximum3DDiameter</th><th>shape_MeshVolume</th><th>shape_MinorAxisLength</th><th>shape_Sphericity</th><th>shape_SurfaceArea</th><th>shape_SurfaceVolumeRatio</th><th>shape_VoxelVolume</th><th>firstorder_10Percentile</th><th>firstorder_90Percentile</th><th>firstorder_Energy</th><th>firstorder_Entropy</th><th>firstorder_InterquartileRange</th><th>firstorder_Kurtosis</th><th>firstorder_Maximum</th><th>firstorder_MeanAbsoluteDeviation</th><th>firstorder_Mean</th><th>firstorder_Median</th><th>firstorder_Minimum</th><th>firstorder_Range</th><th>firstorder_RobustMeanAbsoluteDeviation</th><th>firstorder_RootMeanSquared</th><th>firstorder_Skewness</th><th>firstorder_TotalEnergy</th><th>firstorder_Uniformity</th><th>firstorder_Variance</th><th>glcm_Autocorrelation</th><th>glcm_ClusterProminence</th><th>glcm_ClusterShade</th><th>&hellip;</th><th>glrlm_GrayLevelNonUniformity</th><th>glrlm_GrayLevelNonUniformityNormalized</th><th>glrlm_GrayLevelVariance</th><th>glrlm_HighGrayLevelRunEmphasis</th><th>glrlm_LongRunEmphasis</th><th>glrlm_LongRunHighGrayLevelEmphasis</th><th>glrlm_LongRunLowGrayLevelEmphasis</th><th>glrlm_LowGrayLevelRunEmphasis</th><th>glrlm_RunEntropy</th><th>glrlm_RunLengthNonUniformity</th><th>glrlm_RunLengthNonUniformityNormalized</th><th>glrlm_RunPercentage</th><th>glrlm_RunVariance</th><th>glrlm_ShortRunEmphasis</th><th>glrlm_ShortRunHighGrayLevelEmphasis</th><th>glrlm_ShortRunLowGrayLevelEmphasis</th><th>glszm_GrayLevelNonUniformity</th><th>glszm_GrayLevelNonUniformityNormalized</th><th>glszm_GrayLevelVariance</th><th>glszm_HighGrayLevelZoneEmphasis</th><th>glszm_LargeAreaEmphasis</th><th>glszm_LargeAreaHighGrayLevelEmphasis</th><th>glszm_LargeAreaLowGrayLevelEmphasis</th><th>glszm_LowGrayLevelZoneEmphasis</th><th>glszm_SizeZoneNonUniformity</th><th>glszm_SizeZoneNonUniformityNormalized</th><th>glszm_SmallAreaEmphasis</th><th>glszm_SmallAreaHighGrayLevelEmphasis</th><th>glszm_SmallAreaLowGrayLevelEmphasis</th><th>glszm_ZoneEntropy</th><th>glszm_ZonePercentage</th><th>glszm_ZoneVariance</th><th>ngtdm_Busyness</th><th>ngtdm_Coarseness</th><th>ngtdm_Complexity</th><th>ngtdm_Contrast</th><th>ngtdm_Strength</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;368&quot;</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>&hellip;</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td><td>368.0</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>0.723042</td><td>0.555079</td><td>24.485618</td><td>45.730192</td><td>45.057</td><td>51.053797</td><td>49.333276</td><td>56.808197</td><td>21862.7851</td><td>32.004908</td><td>0.376242</td><td>9237.61258</td><td>0.923609</td><td>22179.336957</td><td>1.374584</td><td>2.522678</td><td>74696.113733</td><td>0.007873</td><td>0.626598</td><td>3.996735</td><td>4.162478</td><td>0.36554</td><td>1.920441</td><td>1.882498</td><td>0.571002</td><td>3.591476</td><td>0.261605</td><td>1.985013</td><td>0.372539</td><td>74696.113733</td><td>0.996985</td><td>0.23679</td><td>1.530893</td><td>0.006383</td><td>-0.003187</td><td>&hellip;</td><td>2971.81061</td><td>0.994031</td><td>0.002985</td><td>1.526069</td><td>100.816023</td><td>186.329359</td><td>79.43769</td><td>0.868483</td><td>3.329075</td><td>428.802215</td><td>0.183117</td><td>0.2571</td><td>38.653377</td><td>0.369848</td><td>0.53148</td><td>0.32944</td><td>34.180723</td><td>0.959979</td><td>0.02001</td><td>1.353266</td><td>3.3695e8</td><td>5.0550e8</td><td>2.9481e8</td><td>0.911684</td><td>9.541138</td><td>0.32483</td><td>0.43707</td><td>0.604474</td><td>0.395219</td><td>2.36478</td><td>0.008932</td><td>1.1143e8</td><td>14.646119</td><td>826087.014728</td><td>0.0014</td><td>0.000218</td><td>0.055786</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>0.155188</td><td>0.147826</td><td>10.167512</td><td>19.301596</td><td>16.080009</td><td>20.17874</td><td>19.738679</td><td>21.27765</td><td>29860.458179</td><td>12.507605</td><td>0.155833</td><td>8357.631322</td><td>0.910963</td><td>29878.14703</td><td>0.524901</td><td>0.51373</td><td>101634.496284</td><td>0.067677</td><td>0.276941</td><td>3.48061</td><td>1.281748</td><td>0.143954</td><td>0.490192</td><td>0.526195</td><td>0.592212</td><td>1.55996</td><td>0.111509</td><td>0.474185</td><td>0.726591</td><td>101634.496284</td><td>0.032312</td><td>0.185438</td><td>1.140018</td><td>0.065065</td><td>0.030067</td><td>&hellip;</td><td>2678.237799</td><td>0.03868</td><td>0.01934</td><td>1.1305</td><td>143.823868</td><td>380.737352</td><td>123.451225</td><td>0.282625</td><td>1.00734</td><td>424.904352</td><td>0.133404</td><td>0.166938</td><td>49.160277</td><td>0.170914</td><td>0.427127</td><td>0.195481</td><td>35.946525</td><td>0.10927</td><td>0.054635</td><td>0.870037</td><td>1.8943e9</td><td>2.7633e9</td><td>1.8311e9</td><td>0.217509</td><td>11.072411</td><td>0.214116</td><td>0.182395</td><td>0.521023</td><td>0.192639</td><td>0.912152</td><td>0.022245</td><td>5.8674e8</td><td>181.567308</td><td>379550.608458</td><td>0.013492</td><td>0.002967</td><td>0.199405</td></tr><tr><td>&quot;min&quot;</td><td>&quot;HGG&quot;</td><td>0.222498</td><td>0.124907</td><td>3.738339</td><td>7.287142</td><td>8.062258</td><td>7.28011</td><td>5.385165</td><td>9.0</td><td>22.083333</td><td>5.415523</td><td>0.096556</td><td>68.848149</td><td>0.131759</td><td>47.0</td><td>-0.190334</td><td>0.736837</td><td>370.774559</td><td>-3.2034e-16</td><td>0.153756</td><td>1.752027</td><td>1.681907</td><td>0.093379</td><td>0.203953</td><td>0.105943</td><td>-0.454909</td><td>0.528899</td><td>0.064838</td><td>0.431033</td><td>-3.62028</td><td>370.774559</td><td>0.534089</td><td>0.01326</td><td>1.0</td><td>0.0</td><td>-0.472291</td><td>&hellip;</td><td>24.230769</td><td>0.50779</td><td>0.0</td><td>1.0</td><td>1.401858</td><td>1.401858</td><td>0.70266</td><td>0.250107</td><td>0.463787</td><td>10.058603</td><td>0.025888</td><td>0.042804</td><td>0.16028</td><td>0.049052</td><td>0.049052</td><td>0.021305</td><td>1.0</td><td>0.5</td><td>0.0</td><td>1.0</td><td>46.769231</td><td>46.769231</td><td>46.769231</td><td>0.255952</td><td>1.0</td><td>0.080332</td><td>4.0048e-11</td><td>4.0048e-11</td><td>4.0048e-11</td><td>-3.2034e-16</td><td>0.000006</td><td>0.0</td><td>0.0</td><td>0.000141</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>0.634073</td><td>0.464006</td><td>17.272473</td><td>33.002982</td><td>33.615473</td><td>36.796739</td><td>35.171011</td><td>42.296572</td><td>3599.625</td><td>22.601235</td><td>0.255762</td><td>3351.436318</td><td>0.417864</td><td>3916.0</td><td>0.979455</td><td>2.190171</td><td>15821.058967</td><td>-3.2034e-16</td><td>0.434014</td><td>2.627947</td><td>3.155506</td><td>0.264655</td><td>1.598257</td><td>1.526641</td><td>0.12344</td><td>2.401487</td><td>0.185134</td><td>1.684222</td><td>-0.086409</td><td>15821.058967</td><td>1.0</td><td>0.118225</td><td>1.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>1073.153846</td><td>1.0</td><td>0.0</td><td>1.0</td><td>17.366738</td><td>17.68425</td><td>13.858298</td><td>1.0</td><td>2.709055</td><td>139.281601</td><td>0.09154</td><td>0.137531</td><td>7.674577</td><td>0.249261</td><td>0.285863</td><td>0.162384</td><td>9.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>461810.015625</td><td>518611.833333</td><td>358783.870588</td><td>1.0</td><td>2.166667</td><td>0.195924</td><td>0.346738</td><td>0.354169</td><td>0.277291</td><td>2.0</td><td>0.000764</td><td>206626.107085</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>0.745096</td><td>0.575729</td><td>23.508105</td><td>43.981132</td><td>44.407207</td><td>50.219518</td><td>49.406477</td><td>56.471232</td><td>10340.5</td><td>31.362378</td><td>0.34617</td><td>7331.645871</td><td>0.695517</td><td>10590.0</td><td>1.327203</td><td>2.508456</td><td>41385.619211</td><td>-3.2034e-16</td><td>0.586345</td><td>3.262533</td><td>3.778643</td><td>0.346395</td><td>1.901583</td><td>1.847197</td><td>0.505102</td><td>3.35169</td><td>0.242905</td><td>1.964811</td><td>0.387561</td><td>41385.619211</td><td>1.0</td><td>0.190868</td><td>1.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>2348.384615</td><td>1.0</td><td>0.0</td><td>1.0</td><td>43.578971</td><td>52.818404</td><td>33.627387</td><td>1.0</td><td>3.366516</td><td>310.531785</td><td>0.153595</td><td>0.216342</td><td>20.198637</td><td>0.364618</td><td>0.412441</td><td>0.32097</td><td>22.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>4.3332e6</td><td>4.9021e6</td><td>3.0420e6</td><td>1.0</td><td>5.769231</td><td>0.27388</td><td>0.478282</td><td>0.501914</td><td>0.432565</td><td>2.508817</td><td>0.002867</td><td>2.1113e6</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>0.841307</td><td>0.662864</td><td>30.729417</td><td>55.860815</td><td>55.713553</td><td>63.906181</td><td>61.188234</td><td>69.318107</td><td>25147.291667</td><td>39.560643</td><td>0.469189</td><td>12960.865504</td><td>1.102541</td><td>25394.0</td><td>1.757149</td><td>2.800596</td><td>90886.79294</td><td>-3.2034e-16</td><td>0.789395</td><td>4.172358</td><td>5.021085</td><td>0.461592</td><td>2.238754</td><td>2.250661</td><td>0.973464</td><td>4.641944</td><td>0.327086</td><td>2.290388</td><td>0.778114</td><td>90886.79294</td><td>1.0</td><td>0.312538</td><td>1.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>4221.153846</td><td>1.0</td><td>0.0</td><td>1.0</td><td>112.962502</td><td>171.722879</td><td>91.251669</td><td>1.0</td><td>4.035562</td><td>568.203129</td><td>0.232698</td><td>0.327519</td><td>49.737264</td><td>0.47274</td><td>0.609252</td><td>0.462379</td><td>46.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>3.0101e7</td><td>4.1876e7</td><td>2.0333272e7</td><td>1.0</td><td>12.742857</td><td>0.34375</td><td>0.559436</td><td>0.597117</td><td>0.535245</td><td>2.947703</td><td>0.00765</td><td>1.5384e7</td><td>0.0</td><td>1e6</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;max&quot;</td><td>&quot;LGG&quot;</td><td>0.984177</td><td>0.878147</td><td>59.587263</td><td>171.979417</td><td>105.475116</td><td>113.216607</td><td>117.885538</td><td>132.07195</td><td>188726.0</td><td>70.539774</td><td>0.831783</td><td>52815.73818</td><td>9.842839</td><td>189152.0</td><td>3.048159</td><td>4.654783</td><td>874135.428433</td><td>0.950246</td><td>2.081183</td><td>50.929231</td><td>8.818044</td><td>1.103804</td><td>3.364545</td><td>3.396505</td><td>2.232331</td><td>9.234909</td><td>0.839303</td><td>3.372971</td><td>4.427729</td><td>874135.428433</td><td>1.0</td><td>1.726145</td><td>4.0</td><td>0.914482</td><td>0.0</td><td>&hellip;</td><td>16845.846154</td><td>1.0</td><td>0.246105</td><td>3.99957</td><td>879.823903</td><td>2928.225613</td><td>879.823903</td><td>1.0</td><td>5.492323</td><td>3024.76271</td><td>0.835281</td><td>0.898687</td><td>299.155169</td><td>0.929974</td><td>2.972293</td><td>0.929974</td><td>267.116364</td><td>1.0</td><td>0.25</td><td>3.97619</td><td>2.4970e10</td><td>3.8177e10</td><td>2.4970e10</td><td>1.0</td><td>78.549091</td><td>1.0</td><td>0.857143</td><td>2.667181</td><td>0.857143</td><td>4.328883</td><td>0.216667</td><td>7.9505e9</td><td>3093.259142</td><td>1e6</td><td>0.199553</td><td>0.046437</td><td>1.236522</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 109)\n",
       "┌────────────┬───────┬────────────┬────────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ statistic  ┆ Group ┆ shape_Elon ┆ shape_Flat ┆ … ┆ ngtdm_Coa ┆ ngtdm_Com ┆ ngtdm_Con ┆ ngtdm_Str │\n",
       "│ ---        ┆ ---   ┆ gation     ┆ ness       ┆   ┆ rseness   ┆ plexity   ┆ trast     ┆ ength     │\n",
       "│ str        ┆ str   ┆ ---        ┆ ---        ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│            ┆       ┆ f64        ┆ f64        ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞════════════╪═══════╪════════════╪════════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ count      ┆ 368   ┆ 368.0      ┆ 368.0      ┆ … ┆ 368.0     ┆ 368.0     ┆ 368.0     ┆ 368.0     │\n",
       "│ null_count ┆ 0     ┆ 0.0        ┆ 0.0        ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ mean       ┆ null  ┆ 0.723042   ┆ 0.555079   ┆ … ┆ 826087.01 ┆ 0.0014    ┆ 0.000218  ┆ 0.055786  │\n",
       "│            ┆       ┆            ┆            ┆   ┆ 4728      ┆           ┆           ┆           │\n",
       "│ std        ┆ null  ┆ 0.155188   ┆ 0.147826   ┆ … ┆ 379550.60 ┆ 0.013492  ┆ 0.002967  ┆ 0.199405  │\n",
       "│            ┆       ┆            ┆            ┆   ┆ 8458      ┆           ┆           ┆           │\n",
       "│ min        ┆ HGG   ┆ 0.222498   ┆ 0.124907   ┆ … ┆ 0.000141  ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ 25%        ┆ null  ┆ 0.634073   ┆ 0.464006   ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ 50%        ┆ null  ┆ 0.745096   ┆ 0.575729   ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ 75%        ┆ null  ┆ 0.841307   ┆ 0.662864   ┆ … ┆ 1e6       ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ max        ┆ LGG   ┆ 0.984177   ┆ 0.878147   ┆ … ┆ 1e6       ┆ 0.199553  ┆ 0.046437  ┆ 1.236522  │\n",
       "└────────────┴───────┴────────────┴────────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f258c5",
   "metadata": {},
   "source": [
    "### Create a test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e252b0",
   "metadata": {},
   "source": [
    "This is important to make sure our final model performs as well on unseen data as it does on the training set.\n",
    "\n",
    "- Here we use a stratified split to make ensure that training and test sets have the same class distribution.\n",
    "- We also specify a random seed to ensure reproducibility of the sample shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "725aa59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split the data in Train and Test subsets.\n",
      "\n",
      "Check class proportions in training dataset:\n",
      "shape: (2, 3)\n",
      "┌───────┬───────┬────────────┐\n",
      "│ Group ┆ count ┆ proportion │\n",
      "│ ---   ┆ ---   ┆ ---        │\n",
      "│ str   ┆ u32   ┆ f64        │\n",
      "╞═══════╪═══════╪════════════╡\n",
      "│ HGG   ┆ 233   ┆ 0.792517   │\n",
      "│ LGG   ┆ 61    ┆ 0.207483   │\n",
      "└───────┴───────┴────────────┘\n",
      "\n",
      "Check class proportions in test dataset:\n",
      "shape: (2, 3)\n",
      "┌───────┬───────┬────────────┐\n",
      "│ Group ┆ count ┆ proportion │\n",
      "│ ---   ┆ ---   ┆ ---        │\n",
      "│ str   ┆ u32   ┆ f64        │\n",
      "╞═══════╪═══════╪════════════╡\n",
      "│ HGG   ┆ 59    ┆ 0.797297   │\n",
      "│ LGG   ┆ 15    ┆ 0.202703   │\n",
      "└───────┴───────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(\"Split the data in Train and Test subsets.\")\n",
    "\n",
    "training_data, test_data = train_test_split(\n",
    "    df,\n",
    "    test_size=0.20,\n",
    "    stratify=df[\"Group\"],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "def check_class_proportions(df: pl.DataFrame):\n",
    "    summary = (\n",
    "        df.group_by(\"Group\")\n",
    "        .agg(pl.len().alias(\"count\"))\n",
    "        .with_columns((pl.col(\"count\") / pl.col(\"count\").sum()).alias(\"proportion\"))\n",
    "        .sort(\"count\", descending=True)\n",
    "    )\n",
    "    return summary\n",
    "\n",
    "\n",
    "print(\"\\nCheck class proportions in training dataset:\")\n",
    "print(check_class_proportions(training_data))\n",
    "\n",
    "print(\"\\nCheck class proportions in test dataset:\")\n",
    "print(check_class_proportions(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5e71dc",
   "metadata": {},
   "source": [
    "Finaly we separate inputs from targets in the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64ece5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(training_inputs_df)=<class 'polars.dataframe.frame.DataFrame'>\n",
      "type(training_targets_df)=<class 'polars.dataframe.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "training_inputs_df = training_data.drop(\"Group\")\n",
    "training_targets_df = training_data.select(\"Group\")\n",
    "\n",
    "print(f\"{type(training_inputs_df)=}\")\n",
    "print(f\"{type(training_targets_df)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe434729",
   "metadata": {},
   "source": [
    "## Pre-processing the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdbdd38",
   "metadata": {},
   "source": [
    "### Encoding the target variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e639ea3",
   "metadata": {},
   "source": [
    "Each sample has a target class label to predict, either \"HGG\" or \"LGG\".\n",
    "Scikit-learn provides a label encoder to convert label strings to label integer IDs.\n",
    "The `LabelEncoder` class that can be fitted to the target data and later reused to convert the output of the model (class 0, class 1...) to a human-readable format (\"HGG\", \"LGG\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da8b9247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(y_train) = <class 'numpy.ndarray'>\n",
      "y_train.shape = (294,)\n",
      "y_train[:10] = array([0, 0, 0, 1, 0, 0, 1, 0, 0, 0])\n",
      "Class 0: HGG (support: 233)\n",
      "Class 1: LGG (support: 61)\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(training_targets_df.to_numpy().ravel())\n",
    "\n",
    "print(f\"{type(y_train) = }\")\n",
    "print(f\"{y_train.shape = }\")\n",
    "print(f\"{y_train[:10] = }\")\n",
    "\n",
    "for i, class_name in enumerate(label_encoder.classes_):\n",
    "    class_support = sum(y_train == i)\n",
    "    print(f\"Class {i}: {class_name} (support: {class_support})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965c2a20",
   "metadata": {},
   "source": [
    "### Preprocessing the input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd684e9",
   "metadata": {},
   "source": [
    "The input variables cannot be used in their raw form directly. Categorical inputs are strings that don't mean anything to the model, and numerical inputs can have widely different distributions, making learning difficult for some models: they need to be normalized first. Some models don't require normalization, like the powerful Random Forest, but it doesn't hurt to normalize the data anyways.\n",
    "\n",
    "Below, we use some of scikit-learn's [transformers](https://scikit-learn.org/stable/data_transforms.html) to preprocess the training data before training. \n",
    "\n",
    "Transformers (the name is unrelated to the famous deep learning [transformer](https://doi.org/10.48550/arXiv.1706.03762) architecture) are one of the three types of building blocks of the scikit-learn API, which are *Estimators*, *Transformers* and *Predictors*. These are detailed in the library's main [design principles](https://doi.org/10.48550/arXiv.1309.0238)\n",
    "\n",
    "Each of transformer has a `fit` and a `transform` method: `fit` is used a single time to record what preprocessing needs to be done, while `transform` can be used any number of times in downstream tasks to apply the pre-processing to new inputs. In the code, we use the shortcut `fit_transform` method that does both actions at the same time on our training dataset.\n",
    "\n",
    "We also use the `Pipeline` class to wrap each transformer object we define. Eventually, we'll define a `ColumnTransformer` object that applies each pipeline to the correct subset of features.\n",
    "\n",
    "This slightly complicated but powerful set of tools enables you to build virtually any pre-processing pipeline you can think of."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7834ebf3",
   "metadata": {},
   "source": [
    "**Warning**: since some transformers need to look at the data's statistics, it is important to use their `fit` method on *training data only* !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41818c2e",
   "metadata": {},
   "source": [
    "#### Handling categorical input features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2daadce",
   "metadata": {},
   "source": [
    "Similar to how we encoded target class labels, we also want to use a proper encoding for **categorical input features**: these are originally string values that cannot be understood as-is by AI models. They need to be converted to numbers first.\n",
    "\n",
    "In a lot of cases, categorical variables (\"Blue\", \"Red\", \"Green\") have no order, therefore a practical way of representing them is through **one-hot encoding**: we create a binary variable for each possible category, and set all values to zero except for the correct categories: \"Blue\" becomes (1, 0, 0), \"Red\" becomes (0, 1, 0), \"Green\" becomes (0, 0, 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a286d9",
   "metadata": {},
   "source": [
    "Scikit-learn provides a `OneHotEncoder` class that can be fitted to our data to convert categorical string data to binary numbers. In this notebook, there are no categorical input variables, but we still write a code to handle them in case the data changes at some point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "babe3c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical features: 0\n"
     ]
    }
   ],
   "source": [
    "# Handling categorical input variables (one-hot feature encoding):\n",
    "\n",
    "# There are no categorical variables in this dataset, so this part does nothing\n",
    "categorical_features = training_inputs_df.select(pl.col(pl.Utf8)).columns\n",
    "print(f\"Number of categorical features: {len(categorical_features)}\")\n",
    "categorical_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"onehot\", OneHotEncoder()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8ba12c",
   "metadata": {},
   "source": [
    "#### Handling numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ceb48c",
   "metadata": {},
   "source": [
    "Most machine learning models don't perform well on numerical features that have different scales. To prevent problems, it is a good practice to apply feature scaling methods such as *min-max scaling* and *standardization* (also known as *Z-Score normalization*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4bd530",
   "metadata": {},
   "source": [
    "Here, we'll go for the latter. Scikit-learn provides a `StandardScaler` class that can learn each of our numerical features' mean and variance and be used later to normalize them. Similarly, there is a `MinMaxScaler` class that exists for the other scaling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebac40f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numerical features: 107\n"
     ]
    }
   ],
   "source": [
    "# Handling numerical input variables (feature scaling):\n",
    "\n",
    "numerical_features = training_inputs_df.select(pl.col(pl.Float64)).columns\n",
    "print(f\"Number of numerical features: {len(numerical_features)}\")\n",
    "numerical_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8196553b",
   "metadata": {},
   "source": [
    "#### Defining a complete pre-processing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d7f694",
   "metadata": {},
   "source": [
    "Once all necessary transformations are defined and wrapped in their respective `Pipeline` objects, we wrap everything in a `ColumnTransformer` that will apply each transformation to the appropriate subset of features. Once that's done, we can fit this big pipeline to our training data and apply the transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "929f417f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(X_train) = <class 'numpy.ndarray'>, X_train.shape = (294, 107)\n"
     ]
    }
   ],
   "source": [
    "# Combine preprocessing for numerical and categorical features:\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_pipeline, numerical_features),\n",
    "        (\"cat\", categorical_pipeline, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train = preprocessor.fit_transform(training_inputs_df)\n",
    "print(f\"{type(X_train) = }, {X_train.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962ee4b7",
   "metadata": {},
   "source": [
    "Let's look at one feature distribution before and after pre-processing and see that the mean is now zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57749e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-57d5b9131f0d4f719d12ff9ef4edbf3f.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-57d5b9131f0d4f719d12ff9ef4edbf3f.vega-embed details,\n",
       "  #altair-viz-57d5b9131f0d4f719d12ff9ef4edbf3f.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-57d5b9131f0d4f719d12ff9ef4edbf3f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-57d5b9131f0d4f719d12ff9ef4edbf3f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-57d5b9131f0d4f719d12ff9ef4edbf3f\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-d36083baf6aa0863de475d3abc668130\"}, \"mark\": {\"type\": \"bar\", \"tooltip\": true}, \"encoding\": {\"x\": {\"bin\": true, \"field\": \"shape_Elongation\", \"type\": \"quantitative\"}, \"y\": {\"aggregate\": \"count\", \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"param_1\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-d36083baf6aa0863de475d3abc668130\": [{\"shape_Elongation\": 0.881837783555764}, {\"shape_Elongation\": 0.8806613902998159}, {\"shape_Elongation\": 0.5869907604495888}, {\"shape_Elongation\": 0.7196367612787553}, {\"shape_Elongation\": 0.7542247051706336}, {\"shape_Elongation\": 0.7937968041951489}, {\"shape_Elongation\": 0.6973740136913338}, {\"shape_Elongation\": 0.9355998957006624}, {\"shape_Elongation\": 0.8844004302129791}, {\"shape_Elongation\": 0.7393147712507019}, {\"shape_Elongation\": 0.5402751483745071}, {\"shape_Elongation\": 0.8444572916279666}, {\"shape_Elongation\": 0.8800615904315857}, {\"shape_Elongation\": 0.8324823946306883}, {\"shape_Elongation\": 0.5453090350025663}, {\"shape_Elongation\": 0.5660493491862587}, {\"shape_Elongation\": 0.7792886767717686}, {\"shape_Elongation\": 0.6121584896056944}, {\"shape_Elongation\": 0.644567708690273}, {\"shape_Elongation\": 0.7123975767522577}, {\"shape_Elongation\": 0.8330047986592265}, {\"shape_Elongation\": 0.4306502770201536}, {\"shape_Elongation\": 0.7456063616254065}, {\"shape_Elongation\": 0.6364633128027789}, {\"shape_Elongation\": 0.6477835184368431}, {\"shape_Elongation\": 0.8708246251266828}, {\"shape_Elongation\": 0.6048876409288843}, {\"shape_Elongation\": 0.6976819625789594}, {\"shape_Elongation\": 0.8396383303655445}, {\"shape_Elongation\": 0.5555056623751816}, {\"shape_Elongation\": 0.780405960269327}, {\"shape_Elongation\": 0.5492303083772235}, {\"shape_Elongation\": 0.7191600106391254}, {\"shape_Elongation\": 0.7281443206571913}, {\"shape_Elongation\": 0.2224975823301929}, {\"shape_Elongation\": 0.8734987729082657}, {\"shape_Elongation\": 0.6712758651483043}, {\"shape_Elongation\": 0.8871393638736774}, {\"shape_Elongation\": 0.3772206269962161}, {\"shape_Elongation\": 0.829356481488418}, {\"shape_Elongation\": 0.9282155540096664}, {\"shape_Elongation\": 0.8017422115900514}, {\"shape_Elongation\": 0.6883997848415926}, {\"shape_Elongation\": 0.5471649227795186}, {\"shape_Elongation\": 0.8250597262835374}, {\"shape_Elongation\": 0.2828832568027544}, {\"shape_Elongation\": 0.7639109556431466}, {\"shape_Elongation\": 0.8837549827479186}, {\"shape_Elongation\": 0.7408102054161212}, {\"shape_Elongation\": 0.8046089801457428}, {\"shape_Elongation\": 0.3935856350464809}, {\"shape_Elongation\": 0.4181380288368765}, {\"shape_Elongation\": 0.612029676607651}, {\"shape_Elongation\": 0.8342650778827113}, {\"shape_Elongation\": 0.725783622930287}, {\"shape_Elongation\": 0.4883217476939661}, {\"shape_Elongation\": 0.6086069710554626}, {\"shape_Elongation\": 0.2545581951304055}, {\"shape_Elongation\": 0.8999348479142685}, {\"shape_Elongation\": 0.902821139527775}, {\"shape_Elongation\": 0.8604321846124915}, {\"shape_Elongation\": 0.8038670745446767}, {\"shape_Elongation\": 0.8282424593702484}, {\"shape_Elongation\": 0.757725043459743}, {\"shape_Elongation\": 0.8055513835814794}, {\"shape_Elongation\": 0.6201079390243082}, {\"shape_Elongation\": 0.8926929286133561}, {\"shape_Elongation\": 0.8536566732405108}, {\"shape_Elongation\": 0.6569343253849869}, {\"shape_Elongation\": 0.8718920499511426}, {\"shape_Elongation\": 0.8668561109952235}, {\"shape_Elongation\": 0.5510317335514223}, {\"shape_Elongation\": 0.8012890209983241}, {\"shape_Elongation\": 0.8087390322911397}, {\"shape_Elongation\": 0.9660631525323566}, {\"shape_Elongation\": 0.8127651102731637}, {\"shape_Elongation\": 0.7683724678300983}, {\"shape_Elongation\": 0.8704789171967657}, {\"shape_Elongation\": 0.8268722759357687}, {\"shape_Elongation\": 0.8898982189759186}, {\"shape_Elongation\": 0.9220070153180806}, {\"shape_Elongation\": 0.7363234759339982}, {\"shape_Elongation\": 0.7128085829987428}, {\"shape_Elongation\": 0.6623126602755992}, {\"shape_Elongation\": 0.984176779420159}, {\"shape_Elongation\": 0.8273322269545608}, {\"shape_Elongation\": 0.7596336269628606}, {\"shape_Elongation\": 0.626749127126722}, {\"shape_Elongation\": 0.6078556548339429}, {\"shape_Elongation\": 0.5492968488274075}, {\"shape_Elongation\": 0.5299297284369422}, {\"shape_Elongation\": 0.5892309863119122}, {\"shape_Elongation\": 0.8051414727877837}, {\"shape_Elongation\": 0.8438870151652159}, {\"shape_Elongation\": 0.4052919411279712}, {\"shape_Elongation\": 0.4692598505328043}, {\"shape_Elongation\": 0.7907393682116409}, {\"shape_Elongation\": 0.8908306897247898}, {\"shape_Elongation\": 0.6631669232080514}, {\"shape_Elongation\": 0.6473462951267056}, {\"shape_Elongation\": 0.9061958302653312}, {\"shape_Elongation\": 0.3205142609386198}, {\"shape_Elongation\": 0.8805630989287804}, {\"shape_Elongation\": 0.3568049552667189}, {\"shape_Elongation\": 0.8540428940483642}, {\"shape_Elongation\": 0.699388898181262}, {\"shape_Elongation\": 0.2614605557878571}, {\"shape_Elongation\": 0.80342949561891}, {\"shape_Elongation\": 0.5329571072046094}, {\"shape_Elongation\": 0.5503797287733687}, {\"shape_Elongation\": 0.8169791290026692}, {\"shape_Elongation\": 0.916947888536499}, {\"shape_Elongation\": 0.742091209591504}, {\"shape_Elongation\": 0.9350061210525036}, {\"shape_Elongation\": 0.2503391880661045}, {\"shape_Elongation\": 0.8889931812251508}, {\"shape_Elongation\": 0.8320523269605771}, {\"shape_Elongation\": 0.5906322369535895}, {\"shape_Elongation\": 0.8959991603766461}, {\"shape_Elongation\": 0.9179499351946784}, {\"shape_Elongation\": 0.3456512803966546}, {\"shape_Elongation\": 0.5370474204618896}, {\"shape_Elongation\": 0.6561987709393482}, {\"shape_Elongation\": 0.7921656297083046}, {\"shape_Elongation\": 0.7087593227477021}, {\"shape_Elongation\": 0.5507847506145221}, {\"shape_Elongation\": 0.5171083683569021}, {\"shape_Elongation\": 0.7456591313800806}, {\"shape_Elongation\": 0.5740073641546587}, {\"shape_Elongation\": 0.6410503536159741}, {\"shape_Elongation\": 0.6461735263371358}, {\"shape_Elongation\": 0.9182609386928692}, {\"shape_Elongation\": 0.8787767026706522}, {\"shape_Elongation\": 0.7510938129277441}, {\"shape_Elongation\": 0.750070926944449}, {\"shape_Elongation\": 0.8808691736769337}, {\"shape_Elongation\": 0.7318294022132728}, {\"shape_Elongation\": 0.8530344205390946}, {\"shape_Elongation\": 0.7990538997668666}, {\"shape_Elongation\": 0.727318182675756}, {\"shape_Elongation\": 0.730071016470459}, {\"shape_Elongation\": 0.7606894830713818}, {\"shape_Elongation\": 0.7261159300201432}, {\"shape_Elongation\": 0.6744832850980027}, {\"shape_Elongation\": 0.8492188074936814}, {\"shape_Elongation\": 0.7680044283729054}, {\"shape_Elongation\": 0.794280574127227}, {\"shape_Elongation\": 0.8567486551275992}, {\"shape_Elongation\": 0.5953137150026709}, {\"shape_Elongation\": 0.7171306843307763}, {\"shape_Elongation\": 0.7382234643192925}, {\"shape_Elongation\": 0.6633073788790518}, {\"shape_Elongation\": 0.6805963218022485}, {\"shape_Elongation\": 0.7742922944387782}, {\"shape_Elongation\": 0.7563908175691489}, {\"shape_Elongation\": 0.5373028545487839}, {\"shape_Elongation\": 0.8789742446719768}, {\"shape_Elongation\": 0.7454716577950956}, {\"shape_Elongation\": 0.5310774113538386}, {\"shape_Elongation\": 0.8593773927727184}, {\"shape_Elongation\": 0.6759101480273696}, {\"shape_Elongation\": 0.7270836151162758}, {\"shape_Elongation\": 0.8731288708740391}, {\"shape_Elongation\": 0.8165423313839408}, {\"shape_Elongation\": 0.6006026919424912}, {\"shape_Elongation\": 0.70840589150041}, {\"shape_Elongation\": 0.6274311674461207}, {\"shape_Elongation\": 0.8739222087269443}, {\"shape_Elongation\": 0.7886327231497514}, {\"shape_Elongation\": 0.7333825825813226}, {\"shape_Elongation\": 0.9467395385874948}, {\"shape_Elongation\": 0.6878489382516565}, {\"shape_Elongation\": 0.5806831151048759}, {\"shape_Elongation\": 0.6897914815105209}, {\"shape_Elongation\": 0.6943811234508904}, {\"shape_Elongation\": 0.4849348829634273}, {\"shape_Elongation\": 0.9580510247543472}, {\"shape_Elongation\": 0.9632465775866866}, {\"shape_Elongation\": 0.7705221899156937}, {\"shape_Elongation\": 0.7394888935361913}, {\"shape_Elongation\": 0.4800131286125347}, {\"shape_Elongation\": 0.8662097424473064}, {\"shape_Elongation\": 0.7480175042124968}, {\"shape_Elongation\": 0.9169055398466196}, {\"shape_Elongation\": 0.8842983152192249}, {\"shape_Elongation\": 0.6932687337382145}, {\"shape_Elongation\": 0.8076208538448995}, {\"shape_Elongation\": 0.4054844939714093}, {\"shape_Elongation\": 0.4207885665452728}, {\"shape_Elongation\": 0.7558045213930945}, {\"shape_Elongation\": 0.7202880385168599}, {\"shape_Elongation\": 0.7228524613617275}, {\"shape_Elongation\": 0.853559715582559}, {\"shape_Elongation\": 0.6344670270513885}, {\"shape_Elongation\": 0.4707356156608409}, {\"shape_Elongation\": 0.6159244981937869}, {\"shape_Elongation\": 0.9147134450829124}, {\"shape_Elongation\": 0.8617390901355723}, {\"shape_Elongation\": 0.8413070229726414}, {\"shape_Elongation\": 0.7883167342456618}, {\"shape_Elongation\": 0.934135544733488}, {\"shape_Elongation\": 0.8198986909670758}, {\"shape_Elongation\": 0.5794306455763734}, {\"shape_Elongation\": 0.747756505654911}, {\"shape_Elongation\": 0.9430278870716252}, {\"shape_Elongation\": 0.7303951498370722}, {\"shape_Elongation\": 0.7034846042633596}, {\"shape_Elongation\": 0.7894114566701966}, {\"shape_Elongation\": 0.6282875863207688}, {\"shape_Elongation\": 0.8493705945161304}, {\"shape_Elongation\": 0.4324990747164314}, {\"shape_Elongation\": 0.7192009048142834}, {\"shape_Elongation\": 0.6324380786418368}, {\"shape_Elongation\": 0.3427473726296172}, {\"shape_Elongation\": 0.6265712294139628}, {\"shape_Elongation\": 0.4929374086905045}, {\"shape_Elongation\": 0.7021763612720763}, {\"shape_Elongation\": 0.6489348317935557}, {\"shape_Elongation\": 0.6431941213138064}, {\"shape_Elongation\": 0.739544927883696}, {\"shape_Elongation\": 0.704765829045325}, {\"shape_Elongation\": 0.7512943812807592}, {\"shape_Elongation\": 0.7070463837051796}, {\"shape_Elongation\": 0.726013690328234}, {\"shape_Elongation\": 0.8909876095026805}, {\"shape_Elongation\": 0.7762225471737592}, {\"shape_Elongation\": 0.6579938709567186}, {\"shape_Elongation\": 0.8208445478063242}, {\"shape_Elongation\": 0.8546412436709138}, {\"shape_Elongation\": 0.8118515367456458}, {\"shape_Elongation\": 0.645445018801302}, {\"shape_Elongation\": 0.8343015080914497}, {\"shape_Elongation\": 0.9246719351470568}, {\"shape_Elongation\": 0.569215364120855}, {\"shape_Elongation\": 0.8486140605540229}, {\"shape_Elongation\": 0.6651250927447889}, {\"shape_Elongation\": 0.8086339435845209}, {\"shape_Elongation\": 0.8240359823389349}, {\"shape_Elongation\": 0.8365524053916737}, {\"shape_Elongation\": 0.9010504862555436}, {\"shape_Elongation\": 0.7763963142549949}, {\"shape_Elongation\": 0.8664768216277147}, {\"shape_Elongation\": 0.5186926960559509}, {\"shape_Elongation\": 0.7740339771845458}, {\"shape_Elongation\": 0.6007327533597258}, {\"shape_Elongation\": 0.5878812188400308}, {\"shape_Elongation\": 0.8682148742612583}, {\"shape_Elongation\": 0.5714924873737244}, {\"shape_Elongation\": 0.7450435495432195}, {\"shape_Elongation\": 0.6461968651216959}, {\"shape_Elongation\": 0.9451504125976256}, {\"shape_Elongation\": 0.8384639717852981}, {\"shape_Elongation\": 0.7702031973497082}, {\"shape_Elongation\": 0.4700544393382458}, {\"shape_Elongation\": 0.729992848299595}, {\"shape_Elongation\": 0.5997380591268343}, {\"shape_Elongation\": 0.9175335049761394}, {\"shape_Elongation\": 0.7206347436497064}, {\"shape_Elongation\": 0.304373745891748}, {\"shape_Elongation\": 0.3263366775197226}, {\"shape_Elongation\": 0.8710537436344298}, {\"shape_Elongation\": 0.6340727671504491}, {\"shape_Elongation\": 0.8792558567537156}, {\"shape_Elongation\": 0.7312161139567237}, {\"shape_Elongation\": 0.8131545127312378}, {\"shape_Elongation\": 0.6756745281274947}, {\"shape_Elongation\": 0.5405335723478782}, {\"shape_Elongation\": 0.8232930540244885}, {\"shape_Elongation\": 0.736524603642708}, {\"shape_Elongation\": 0.6560369626421848}, {\"shape_Elongation\": 0.9416830811948684}, {\"shape_Elongation\": 0.7031462773448296}, {\"shape_Elongation\": 0.8631920701692956}, {\"shape_Elongation\": 0.727380087042932}, {\"shape_Elongation\": 0.656230373680076}, {\"shape_Elongation\": 0.7362227470156918}, {\"shape_Elongation\": 0.7056400643625397}, {\"shape_Elongation\": 0.7576637482268632}, {\"shape_Elongation\": 0.9334375193057862}, {\"shape_Elongation\": 0.733626485626721}, {\"shape_Elongation\": 0.8828377630870489}, {\"shape_Elongation\": 0.8477190589346183}, {\"shape_Elongation\": 0.6606412709276807}, {\"shape_Elongation\": 0.7466723921800149}, {\"shape_Elongation\": 0.7876113168265544}, {\"shape_Elongation\": 0.8418300929281762}, {\"shape_Elongation\": 0.92921818052429}, {\"shape_Elongation\": 0.8156483290080643}, {\"shape_Elongation\": 0.5980767782102054}, {\"shape_Elongation\": 0.8092672245775526}, {\"shape_Elongation\": 0.7777136992854954}, {\"shape_Elongation\": 0.8612879685665715}, {\"shape_Elongation\": 0.7399696025126145}, {\"shape_Elongation\": 0.6328062669050236}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After preprocessing:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-3f1125bbf53047339b3d903e7537321e.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-3f1125bbf53047339b3d903e7537321e.vega-embed details,\n",
       "  #altair-viz-3f1125bbf53047339b3d903e7537321e.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-3f1125bbf53047339b3d903e7537321e\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-3f1125bbf53047339b3d903e7537321e\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-3f1125bbf53047339b3d903e7537321e\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-b0398631462e88d5b98699bd7efde64b\"}, \"mark\": {\"type\": \"bar\", \"tooltip\": true}, \"encoding\": {\"x\": {\"bin\": true, \"field\": \"shape_Elongation\", \"type\": \"quantitative\"}, \"y\": {\"aggregate\": \"count\", \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"param_2\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-b0398631462e88d5b98699bd7efde64b\": [{\"shape_Elongation\": 1.0300718284260384}, {\"shape_Elongation\": 1.0224197924740324}, {\"shape_Elongation\": -0.8878072564315731}, {\"shape_Elongation\": -0.024990369219338605}, {\"shape_Elongation\": 0.1999923810883498}, {\"shape_Elongation\": 0.45739535658219554}, {\"shape_Elongation\": -0.16980193122722292}, {\"shape_Elongation\": 1.3797759880754306}, {\"shape_Elongation\": 1.0467409688296816}, {\"shape_Elongation\": 0.10300835825374004}, {\"shape_Elongation\": -1.1916763421399863}, {\"shape_Elongation\": 0.7869245078434755}, {\"shape_Elongation\": 1.0185182993870059}, {\"shape_Elongation\": 0.7090318967787406}, {\"shape_Elongation\": -1.1589326305779988}, {\"shape_Elongation\": -1.0240239773814044}, {\"shape_Elongation\": 0.3630249476405718}, {\"shape_Elongation\": -0.7240997824562484}, {\"shape_Elongation\": -0.5132888921712936}, {\"shape_Elongation\": -0.07207878967727566}, {\"shape_Elongation\": 0.7124299563881741}, {\"shape_Elongation\": -1.9047486524376898}, {\"shape_Elongation\": 0.14393300271179943}, {\"shape_Elongation\": -0.5660052167394879}, {\"shape_Elongation\": -0.4923711491706898}, {\"shape_Elongation\": 0.9584349979542851}, {\"shape_Elongation\": -0.7713941673868276}, {\"shape_Elongation\": -0.1677988289928493}, {\"shape_Elongation\": 0.7555788123076239}, {\"shape_Elongation\": -1.0926070554780483}, {\"shape_Elongation\": 0.3702924948223254}, {\"shape_Elongation\": -1.133426087856162}, {\"shape_Elongation\": -0.028091469141617528}, {\"shape_Elongation\": 0.030348396026430607}, {\"shape_Elongation\": -3.258710769460219}, {\"shape_Elongation\": 0.9758294150526372}, {\"shape_Elongation\": -0.33956146522855196}, {\"shape_Elongation\": 1.06455679592309}, {\"shape_Elongation\": -2.252290259650293}, {\"shape_Elongation\": 0.6886989004558208}, {\"shape_Elongation\": 1.3317433698878511}, {\"shape_Elongation\": 0.5090775153600688}, {\"shape_Elongation\": -0.22817622184180547}, {\"shape_Elongation\": -1.146860715068179}, {\"shape_Elongation\": 0.6607499767957501}, {\"shape_Elongation\": -2.8659226012912584}, {\"shape_Elongation\": 0.2629981289375837}, {\"shape_Elongation\": 1.042542553730988}, {\"shape_Elongation\": 0.11273564625015434}, {\"shape_Elongation\": 0.527724864742016}, {\"shape_Elongation\": -2.145841477049469}, {\"shape_Elongation\": -1.9861365492610992}, {\"shape_Elongation\": -0.7249376669707426}, {\"shape_Elongation\": 0.7206276418805988}, {\"shape_Elongation\": 0.014992864373427452}, {\"shape_Elongation\": -1.529615452064647}, {\"shape_Elongation\": -0.7472011964546549}, {\"shape_Elongation\": -3.0501674438757385}, {\"shape_Elongation\": 1.147787045167431}, {\"shape_Elongation\": 1.1665613853660455}, {\"shape_Elongation\": 0.8908357253117494}, {\"shape_Elongation\": 0.5228990224451072}, {\"shape_Elongation\": 0.6814525674320112}, {\"shape_Elongation\": 0.2227608849853413}, {\"shape_Elongation\": 0.5338548769085161}, {\"shape_Elongation\": -0.6723913316959955}, {\"shape_Elongation\": 1.1006808359368738}, {\"shape_Elongation\": 0.8467633402062794}, {\"shape_Elongation\": -0.4328482783934097}, {\"shape_Elongation\": 0.9653782315129024}, {\"shape_Elongation\": 0.932621170259824}, {\"shape_Elongation\": -1.121708432957921}, {\"shape_Elongation\": 0.5061296654948352}, {\"shape_Elongation\": 0.5545894419915404}, {\"shape_Elongation\": 1.5779290591787234}, {\"shape_Elongation\": 0.580777702854357}, {\"shape_Elongation\": 0.29201874043994464}, {\"shape_Elongation\": 0.95618628605863}, {\"shape_Elongation\": 0.6725399926204261}, {\"shape_Elongation\": 1.0825022051831172}, {\"shape_Elongation\": 1.291358948235292}, {\"shape_Elongation\": 0.08355100486383416}, {\"shape_Elongation\": -0.06940533455612335}, {\"shape_Elongation\": -0.39786404864132263}, {\"shape_Elongation\": 1.6957520095109055}, {\"shape_Elongation\": 0.6755318167525033}, {\"shape_Elongation\": 0.23517556817858293}, {\"shape_Elongation\": -0.6291926735374624}, {\"shape_Elongation\": -0.7520882516203703}, {\"shape_Elongation\": -1.1329932649761465}, {\"shape_Elongation\": -1.2589697620066664}, {\"shape_Elongation\": -0.8732353530715041}, {\"shape_Elongation\": 0.5311885473332528}, {\"shape_Elongation\": 0.7832150544158172}, {\"shape_Elongation\": -2.0696959580677605}, {\"shape_Elongation\": -1.653606576336348}, {\"shape_Elongation\": 0.4375077807664839}, {\"shape_Elongation\": 1.0885676086172829}, {\"shape_Elongation\": -0.39230736031576624}, {\"shape_Elongation\": -0.4952151373279757}, {\"shape_Elongation\": 1.1885125948957789}, {\"shape_Elongation\": -2.6211457844387533}, {\"shape_Elongation\": 1.0217804407086826}, {\"shape_Elongation\": -2.385087224669071}, {\"shape_Elongation\": 0.8492755745226225}, {\"shape_Elongation\": -0.1566957964562917}, {\"shape_Elongation\": -3.0052699475347175}, {\"shape_Elongation\": 0.5200527211297292}, {\"shape_Elongation\": -1.2392776981042264}, {\"shape_Elongation\": -1.125949501135862}, {\"shape_Elongation\": 0.6081884540275394}, {\"shape_Elongation\": 1.2584510581035868}, {\"shape_Elongation\": 0.12106814046935907}, {\"shape_Elongation\": 1.3759136869851043}, {\"shape_Elongation\": -3.077610642461385}, {\"shape_Elongation\": 1.0766152440229937}, {\"shape_Elongation\": 0.7062344536135005}, {\"shape_Elongation\": -0.8641206966981603}, {\"shape_Elongation\": 1.122186743243329}, {\"shape_Elongation\": 1.2649690290416271}, {\"shape_Elongation\": -2.457638066550541}, {\"shape_Elongation\": -1.2126716087362206}, {\"shape_Elongation\": -0.43763280859555603}, {\"shape_Elongation\": 0.4467851242009604}, {\"shape_Elongation\": -0.09574438815348546}, {\"shape_Elongation\": -1.1233149725254816}, {\"shape_Elongation\": -1.3423683260412855}, {\"shape_Elongation\": 0.14427625192536192}, {\"shape_Elongation\": -0.9722598106481283}, {\"shape_Elongation\": -0.5361680844383512}, {\"shape_Elongation\": -0.5028435973653009}, {\"shape_Elongation\": 1.2669920004734359}, {\"shape_Elongation\": 1.0101605437714898}, {\"shape_Elongation\": 0.17962699741812613}, {\"shape_Elongation\": 0.17297347379462552}, {\"shape_Elongation\": 1.023771352306508}, {\"shape_Elongation\": 0.05431859171620766}, {\"shape_Elongation\": 0.8427157991154121}, {\"shape_Elongation\": 0.4915909660134098}, {\"shape_Elongation\": 0.024974650892057543}, {\"shape_Elongation\": 0.0428808936050761}, {\"shape_Elongation\": 0.24204355119505983}, {\"shape_Elongation\": 0.01715440838588174}, {\"shape_Elongation\": -0.31869829498834745}, {\"shape_Elongation\": 0.8178965407128177}, {\"shape_Elongation\": 0.2896247695939226}, {\"shape_Elongation\": 0.46054211460213823}, {\"shape_Elongation\": 0.866875625314446}, {\"shape_Elongation\": -0.833669282463192}, {\"shape_Elongation\": -0.04129154300409794}, {\"shape_Elongation\": 0.09590977975408042}, {\"shape_Elongation\": -0.3913937441940111}, {\"shape_Elongation\": -0.27893508111381554}, {\"shape_Elongation\": 0.33052518869627456}, {\"shape_Elongation\": 0.21408220170379288}, {\"shape_Elongation\": -1.211010097327174}, {\"shape_Elongation\": 1.0114454869556877}, {\"shape_Elongation\": 0.1430568003473264}, {\"shape_Elongation\": -1.2515044769948815}, {\"shape_Elongation\": 0.8839746649996335}, {\"shape_Elongation\": -0.30941703943975074}, {\"shape_Elongation\": 0.023448869110122887}, {\"shape_Elongation\": 0.9734233287797769}, {\"shape_Elongation\": 0.6053472348473372}, {\"shape_Elongation\": -0.7992662956318729}, {\"shape_Elongation\": -0.09804333758826628}, {\"shape_Elongation\": -0.6247562344314339}, {\"shape_Elongation\": 0.9785837202915634}, {\"shape_Elongation\": 0.42380477484547263}, {\"shape_Elongation\": 0.06442149901882467}, {\"shape_Elongation\": 1.4522355567031435}, {\"shape_Elongation\": -0.23175929058936798}, {\"shape_Elongation\": -0.9288363329807637}, {\"shape_Elongation\": -0.2191237107949412}, {\"shape_Elongation\": -0.1892696590507926}, {\"shape_Elongation\": -1.5516458492567637}, {\"shape_Elongation\": 1.5258129071186854}, {\"shape_Elongation\": 1.559608202070089}, {\"shape_Elongation\": 0.30600194767326033}, {\"shape_Elongation\": 0.1041409641930155}, {\"shape_Elongation\": -1.5836601786908606}, {\"shape_Elongation\": 0.928416763832042}, {\"shape_Elongation\": 0.15961666093454072}, {\"shape_Elongation\": 1.2581755943538255}, {\"shape_Elongation\": 1.046076745705743}, {\"shape_Elongation\": -0.19650537383494235}, {\"shape_Elongation\": 0.5473160734745702}, {\"shape_Elongation\": -2.068443467649952}, {\"shape_Elongation\": -1.9688957076171627}, {\"shape_Elongation\": 0.2102685455178124}, {\"shape_Elongation\": -0.02075403344003946}, {\"shape_Elongation\": -0.004073339542947905}, {\"shape_Elongation\": 0.8461326637885785}, {\"shape_Elongation\": -0.5789903730746504}, {\"shape_Elongation\": -1.6440072287037815}, {\"shape_Elongation\": -0.6996031840900651}, {\"shape_Elongation\": 1.2439167673354976}, {\"shape_Elongation\": 0.8993366989427394}, {\"shape_Elongation\": 0.7664330872346433}, {\"shape_Elongation\": 0.4217493750526715}, {\"shape_Elongation\": 1.3702508856570712}, {\"shape_Elongation\": 0.6271792064845002}, {\"shape_Elongation\": -0.9369832190772583}, {\"shape_Elongation\": 0.15791895454599258}, {\"shape_Elongation\": 1.4280925325085159}, {\"shape_Elongation\": 0.044989270342215684}, {\"shape_Elongation\": -0.1300546286065138}, {\"shape_Elongation\": 0.4288701701674448}, {\"shape_Elongation\": -0.6191855224389533}, {\"shape_Elongation\": 0.8188838634018547}, {\"shape_Elongation\": -1.8927228554787452}, {\"shape_Elongation\": -0.027825466512858003}, {\"shape_Elongation\": -0.5921879888346476}, {\"shape_Elongation\": -2.4765269938053738}, {\"shape_Elongation\": -0.6303498373404086}, {\"shape_Elongation\": -1.4995921552553508}, {\"shape_Elongation\": -0.138564302010916}, {\"shape_Elongation\": -0.4848822493890524}, {\"shape_Elongation\": -0.5222236084617856}, {\"shape_Elongation\": 0.10450544846686269}, {\"shape_Elongation\": -0.12172069941690838}, {\"shape_Elongation\": 0.1809316259854406}, {\"shape_Elongation\": -0.10688647101625541}, {\"shape_Elongation\": 0.016489374143076357}, {\"shape_Elongation\": 1.0895883181257138}, {\"shape_Elongation\": 0.34308082283464614}, {\"shape_Elongation\": -0.42595629668007906}, {\"shape_Elongation\": 0.6333316818602167}, {\"shape_Elongation\": 0.8531676342572971}, {\"shape_Elongation\": 0.5748352193846319}, {\"shape_Elongation\": -0.5075822898283197}, {\"shape_Elongation\": 0.7208646079339107}, {\"shape_Elongation\": 1.308693340656732}, {\"shape_Elongation\": -1.0034301326091524}, {\"shape_Elongation\": 0.8139628686174238}, {\"shape_Elongation\": -0.3795701369259886}, {\"shape_Elongation\": 0.5539058758820516}, {\"shape_Elongation\": 0.6540908724272597}, {\"shape_Elongation\": 0.7355059253492394}, {\"shape_Elongation\": 1.155043891169998}, {\"shape_Elongation\": 0.34421111829168644}, {\"shape_Elongation\": 0.9301540225932452}, {\"shape_Elongation\": -1.3320628159989742}, {\"shape_Elongation\": 0.3288449232693728}, {\"shape_Elongation\": -0.7984202905773421}, {\"shape_Elongation\": -0.8820151290260687}, {\"shape_Elongation\": 0.9414594607799306}, {\"shape_Elongation\": -0.9886182243378304}, {\"shape_Elongation\": 0.1402721025278321}, {\"shape_Elongation\": -0.502691786550654}, {\"shape_Elongation\": 1.4418988354194546}, {\"shape_Elongation\": 0.7479400112254553}, {\"shape_Elongation\": 0.30392701008669964}, {\"shape_Elongation\": -1.6484380478059801}, {\"shape_Elongation\": 0.04237243637724876}, {\"shape_Elongation\": -0.8048904365024853}, {\"shape_Elongation\": 1.262260292836578}, {\"shape_Elongation\": -0.018498835080245735}, {\"shape_Elongation\": -2.7261343168007635}, {\"shape_Elongation\": -2.5832729551098845}, {\"shape_Elongation\": 0.9599253355175831}, {\"shape_Elongation\": -0.5815548989431626}, {\"shape_Elongation\": 1.0132772772716294}, {\"shape_Elongation\": 0.050329361274492626}, {\"shape_Elongation\": 0.5833106327176633}, {\"shape_Elongation\": -0.3109496663361855}, {\"shape_Elongation\": -1.1899953825415714}, {\"shape_Elongation\": 0.6492583777294507}, {\"shape_Elongation\": 0.08485927184871406}, {\"shape_Elongation\": -0.43868531625059975}, {\"shape_Elongation\": 1.419345030033998}, {\"shape_Elongation\": -0.1322553295464697}, {\"shape_Elongation\": 0.908787837326423}, {\"shape_Elongation\": 0.025377317637061338}, {\"shape_Elongation\": -0.43742724357126833}, {\"shape_Elongation\": 0.08289579768682105}, {\"shape_Elongation\": -0.1160340975565055}, {\"shape_Elongation\": 0.22236218045068745}, {\"shape_Elongation\": 1.3657104688864192}, {\"shape_Elongation\": 0.0660080049450999}, {\"shape_Elongation\": 1.0365763534103258}, {\"shape_Elongation\": 0.8081411890607283}, {\"shape_Elongation\": -0.40873586494544206}, {\"shape_Elongation\": 0.15086716702169783}, {\"shape_Elongation\": 0.41716087590505335}, {\"shape_Elongation\": 0.769835478471527}, {\"shape_Elongation\": 1.338265112593823}, {\"shape_Elongation\": 0.5995320550281764}, {\"shape_Elongation\": -0.8156965009168723}, {\"shape_Elongation\": 0.5580251522395954}, {\"shape_Elongation\": 0.35278025753577363}, {\"shape_Elongation\": 0.8964023073629978}, {\"shape_Elongation\": 0.10726781174288307}, {\"shape_Elongation\": -0.5897930500565076}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the preprocessed data back to a DataFrame for easier visualization\n",
    "feature_names = preprocessor.get_feature_names_out().tolist()\n",
    "simple_feature_names = [re.sub(r\"^.*?__\", \"\", name) for name in feature_names]\n",
    "X_train_df = pl.DataFrame(X_train, schema=simple_feature_names)\n",
    "\n",
    "# Look at some preprocessed input features distributions:\n",
    "max_features_to_plot = 1\n",
    "print(\"Before preprocessing:\")\n",
    "for feature in training_inputs_df.columns[:max_features_to_plot]:\n",
    "    training_inputs_df[feature].plot.hist().show()\n",
    "print(\"After preprocessing:\")\n",
    "for feature in X_train_df.columns[:max_features_to_plot]:\n",
    "    X_train_df[feature].plot.hist().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db25099d",
   "metadata": {},
   "source": [
    "## Cross-validating a few models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e7f727",
   "metadata": {},
   "source": [
    "Now that our data is correctly pre-processed, we can finally train our some models. Since our dataset is small, we can test multiple models in a reasonable amount of time and we can use cross-validation instead of using a regular train/validation split. What does this mean?\n",
    "\n",
    "In a normal train/validation split, we separate part of the data for validation to estimate how well the model will generalize to unseen data. This helps detect [overfitting](https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html), where a model performs well on training data but poorly on new data. However, a single split can give misleading results if the partition is unbalanced or too small. Cross-validation addresses this by training and evaluating the model multiple times on different folds of the data, ensuring every sample is used for validation once. This provides a more robust and reliable estimate of the model’s true performance while still guarding against overfitting. At the end, we obtain multiple values for our performance metric and typically look at their average.\n",
    "\n",
    "Once cross-validation is complete and a model is selected, we retrain it on the entire training data (both train and validation). Finally, we evaluate it on the test set that was set aside at the beginning and never used during training or model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94d8f5a",
   "metadata": {},
   "source": [
    "#### List classification models that we want to compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8463794",
   "metadata": {},
   "source": [
    "Here we instantiate some classification models we'd like to try on our training data. This list was essentially taken from scikit-learn documentation's [classifier comparison tutorial](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html).\n",
    "\n",
    "We set a random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5bbf912",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_state = 42  # set to None for a different random state each time\n",
    "\n",
    "# Base\n",
    "# models = {\n",
    "#     \"LogisticRegression\": LogisticRegression(random_state=rnd_state),\n",
    "#     \"RandomForestClassifier\": RandomForestClassifier(random_state=rnd_state),\n",
    "#     \"Nearest Neighbors\": KNeighborsClassifier(3),\n",
    "#     \"Linear SVM\": SVC(kernel=\"linear\", C=0.025, random_state=rnd_state),\n",
    "#     \"RBF SVM\": SVC(gamma=2, C=1, random_state=rnd_state),\n",
    "#     \"Decision Tree\": DecisionTreeClassifier(max_depth=5, random_state=rnd_state),\n",
    "#     \"Random Forest\": RandomForestClassifier(\n",
    "#         max_depth=5, n_estimators=10, max_features=1, random_state=rnd_state\n",
    "#     ),\n",
    "#     \"Neural Net\": MLPClassifier(alpha=1, max_iter=1000, random_state=rnd_state),\n",
    "#     \"AdaBoost\": AdaBoostClassifier(random_state=rnd_state),\n",
    "#     \"Naive Bayes\": GaussianNB(),\n",
    "# }\n",
    "\n",
    "\n",
    "# Models to underfit\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(\n",
    "        C=0.01, random_state=rnd_state\n",
    "    ),  # stronger regularization\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(\n",
    "        max_depth=2, random_state=rnd_state\n",
    "    ),  # shallow trees\n",
    "    \"Nearest Neighbors\": KNeighborsClassifier(\n",
    "        n_neighbors=20\n",
    "    ),  # high k -> smoother predictions\n",
    "    \"Linear SVM\": SVC(\n",
    "        kernel=\"linear\", C=0.01, random_state=rnd_state\n",
    "    ),  # low C -> high regularization\n",
    "    \"RBF SVM\": SVC(gamma=0.1, C=0.1, random_state=rnd_state),  # smoother boundary\n",
    "    \"Decision Tree\": DecisionTreeClassifier(\n",
    "        max_depth=2, random_state=rnd_state\n",
    "    ),  # shallow tree\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        max_depth=2, n_estimators=5, random_state=rnd_state\n",
    "    ),  # shallow + few trees\n",
    "    \"Neural Net\": MLPClassifier(\n",
    "        hidden_layer_sizes=(5,), alpha=1, max_iter=500, random_state=rnd_state\n",
    "    ),  # small network\n",
    "    \"AdaBoost\": AdaBoostClassifier(\n",
    "        n_estimators=10, random_state=rnd_state\n",
    "    ),  # few weak learners\n",
    "    \"Naive Bayes\": GaussianNB(),  # simple, no change needed\n",
    "}\n",
    "\n",
    "# Models to overfit\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(\n",
    "        C=100, max_iter=1000, random_state=rnd_state\n",
    "    ),\n",
    "    # very low regularization -> can fit noise\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(random_state=rnd_state),\n",
    "    # full depth, many trees -> high capacity\n",
    "    \"Nearest Neighbors\": KNeighborsClassifier(n_neighbors=1),\n",
    "    # memorize training points\n",
    "    \"Linear SVM\": SVC(kernel=\"linear\", C=1000, random_state=rnd_state),\n",
    "    # very low regularization -> can fit all training points\n",
    "    \"RBF SVM\": SVC(gamma=\"scale\", C=1000, random_state=rnd_state),\n",
    "    # RBF kernel + high C -> highly flexible\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=rnd_state),\n",
    "    # no max_depth -> can grow full tree\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=rnd_state),\n",
    "    # more trees, full depth\n",
    "    \"Neural Net\": MLPClassifier(\n",
    "        hidden_layer_sizes=(100,), max_iter=2000, random_state=rnd_state\n",
    "    ),\n",
    "    # large network -> can fit small dataset perfectly\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=200, random_state=rnd_state),\n",
    "    # many weak learners -> memorize small dataset\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    # already flexible for small data -> no change needed\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b91234",
   "metadata": {},
   "source": [
    "#### Decide on a performance metric for model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6b76c4",
   "metadata": {},
   "source": [
    "There are many performance metrics that we can use to evaluate and compare models. Some of the most commons are: accuracy, class recall, class precision, class f1-score. Scikit-learn's documentation lists a huge variety of other metrics that can be used:: https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics\n",
    "\n",
    "Arbitrary performance metrics can be defined  with scikit learn's `make_scorer` method, but this notebook, we're going to keep things simple and use a *balanced accuracy score*, since we don't have the same number of samples in each class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76942510",
   "metadata": {},
   "source": [
    "#### Run cross-validation for each model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938caea9",
   "metadata": {},
   "source": [
    "Here we use scikit-learn's `cross-validate` method that returns training and validation scores for each validation split (5 total). We store the average and standard deviation of each score for later comparison. It is important that we do keep both training and validation scores, as the comparison between both allows us to spot oeverfitting issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31ca81cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying model: LogisticRegression\n",
      "Train balanced accuracy: 0.9753 ± 0.0087\n",
      "Validation balanced accuracy: 0.7940 ± 0.0694\n",
      "\n",
      "Trying model: RandomForestClassifier\n",
      "Train balanced accuracy: 1.0000 ± 0.0000\n",
      "Validation balanced accuracy: 0.8637 ± 0.0484\n",
      "\n",
      "Trying model: Nearest Neighbors\n",
      "Train balanced accuracy: 1.0000 ± 0.0000\n",
      "Validation balanced accuracy: 0.7697 ± 0.0687\n",
      "\n",
      "Trying model: Linear SVM\n",
      "Train balanced accuracy: 1.0000 ± 0.0000\n",
      "Validation balanced accuracy: 0.7748 ± 0.0680\n",
      "\n",
      "Trying model: RBF SVM\n",
      "Train balanced accuracy: 1.0000 ± 0.0000\n",
      "Validation balanced accuracy: 0.7857 ± 0.0691\n",
      "\n",
      "Trying model: Decision Tree\n",
      "Train balanced accuracy: 1.0000 ± 0.0000\n",
      "Validation balanced accuracy: 0.8020 ± 0.0734\n",
      "\n",
      "Trying model: Random Forest\n",
      "Train balanced accuracy: 1.0000 ± 0.0000\n",
      "Validation balanced accuracy: 0.8616 ± 0.0481\n",
      "\n",
      "Trying model: Neural Net\n",
      "Train balanced accuracy: 1.0000 ± 0.0000\n",
      "Validation balanced accuracy: 0.8165 ± 0.0746\n",
      "\n",
      "Trying model: AdaBoost\n",
      "Train balanced accuracy: 1.0000 ± 0.0000\n",
      "Validation balanced accuracy: 0.8569 ± 0.0435\n",
      "\n",
      "Trying model: Naive Bayes\n",
      "Train balanced accuracy: 0.7921 ± 0.0190\n",
      "Validation balanced accuracy: 0.7961 ± 0.0365\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTrying model: {model_name}\")\n",
    "    cv_results = cross_validate(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=5,\n",
    "        scoring=\"balanced_accuracy\",\n",
    "        return_train_score=True,\n",
    "    )\n",
    "\n",
    "    train_mean = cv_results[\"train_score\"].mean()\n",
    "    train_std = cv_results[\"train_score\"].std()\n",
    "    val_mean = cv_results[\"test_score\"].mean()\n",
    "    val_std = cv_results[\"test_score\"].std()\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"Model\": model_name,\n",
    "            \"Train Mean\": train_mean,\n",
    "            \"Train Std\": train_std,\n",
    "            \"Val Mean\": val_mean,\n",
    "            \"Val Std\": val_std,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\"Train balanced accuracy: {train_mean:.4f} ± {train_std:.4f}\")\n",
    "    print(f\"Validation balanced accuracy: {val_mean:.4f} ± {val_std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a76c9",
   "metadata": {},
   "source": [
    "#### Look at the results and compare the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e2de1b",
   "metadata": {},
   "source": [
    "We list models by average validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f219b6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════════════════╤═══════════════╤════════════════════╤══════════════════╕\n",
      "│ Model                  │ Train Score   │ Validation Score   │   Train-val Diff │\n",
      "╞════════════════════════╪═══════════════╪════════════════════╪══════════════════╡\n",
      "│ RandomForestClassifier │ 1.00 ± 0.00   │ 0.86 ± 0.05        │       0.136251   │\n",
      "├────────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ Random Forest          │ 1.00 ± 0.00   │ 0.86 ± 0.05        │       0.138425   │\n",
      "├────────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ AdaBoost               │ 1.00 ± 0.00   │ 0.86 ± 0.04        │       0.143098   │\n",
      "├────────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ Neural Net             │ 1.00 ± 0.00   │ 0.82 ± 0.07        │       0.183455   │\n",
      "├────────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ Decision Tree          │ 1.00 ± 0.00   │ 0.80 ± 0.07        │       0.198024   │\n",
      "├────────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ Naive Bayes            │ 0.79 ± 0.02   │ 0.80 ± 0.04        │      -0.00402415 │\n",
      "├────────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ LogisticRegression     │ 0.98 ± 0.01   │ 0.79 ± 0.07        │       0.181274   │\n",
      "├────────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ RBF SVM                │ 1.00 ± 0.00   │ 0.79 ± 0.07        │       0.214336   │\n",
      "├────────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ Linear SVM             │ 1.00 ± 0.00   │ 0.77 ± 0.07        │       0.225152   │\n",
      "├────────────────────────┼───────────────┼────────────────────┼──────────────────┤\n",
      "│ Nearest Neighbors      │ 1.00 ± 0.00   │ 0.77 ± 0.07        │       0.230269   │\n",
      "╘════════════════════════╧═══════════════╧════════════════════╧══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "# Sort by validation mean\n",
    "results = sorted(results, key=lambda x: x[\"Val Mean\"], reverse=True)\n",
    "\n",
    "# Prepare table for tabulate (remove Val Mean from display)\n",
    "\n",
    "table = []\n",
    "for r in results:\n",
    "    train_val_diff = r[\"Train Mean\"] - r[\"Val Mean\"]\n",
    "    table.append(\n",
    "        [\n",
    "            r[\"Model\"],\n",
    "            f\"{r['Train Mean']:.2f} ± {r['Train Std']:.2f}\",\n",
    "            f\"{r['Val Mean']:.2f} ± {r['Val Std']:.2f}\",\n",
    "            train_val_diff,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "print(\n",
    "    tabulate(\n",
    "        table,\n",
    "        headers=[\"Model\", \"Train Score\", \"Validation Score\", \"Train-val Diff\"],\n",
    "        tablefmt=\"fancy_grid\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec7280a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea090fb2",
   "metadata": {},
   "source": [
    "Train a chosen model on the full training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab5a86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aff6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "549eae11",
   "metadata": {},
   "source": [
    "Evaluate the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706b9889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7006b0c9",
   "metadata": {},
   "source": [
    "(Fine-tune the chosen model's hyperparameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-radiomics-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
